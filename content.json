{"posts":[{"title":"JVM系列","text":"开个JVM系列的坑~ JVM体系结构JVM内存区域JVM垃圾收集器JVM类加载器","link":"/2022/01/01/2022-01-01_JVM%E7%B3%BB%E5%88%97/"},{"title":"JVM垃圾收集器详解","text":"JVM垃圾收集器笔记 前言如果说垃圾收集算法是内存回收的方法论，那么垃圾收集器则是内存回收的具体实现。 直到现在为止还没有最好的垃圾收集器出现，更加没有万能的垃圾收集器，我们能做的就是根据具体应用场景选择适合自己的垃圾收集器。如果有任何场景下都适用的完美收集器存在，那么我们的 HotSpot 虚拟机就不会实现那么多不同的垃圾收集器了。 此文章介绍新生代收集器包括Serial、ParNew、Parallel Scavenge，老年代收集器包括Serial Old、Parallel Old、CMS，还有用于回收整个Java堆的G1收集器。 Serial收集器Serial收集器是最基本、历史最悠久的垃圾收集器，它是一个单线程收集器，它的“单线程”的意义并不是只有一条线程去完成垃圾收集的工作，而是当它进行垃圾回收时，必须暂停其他所有的工作线程也就是”Stop The World”，直到收集结束。 Serial收集器主要作用于新生代，并采用标记-复制算法。 JVM的设计者当然知道“Stop The World”能带来不良的用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短，但是任然无法完全去除停顿。 当然Serial收集器也有它的优点，它简单而高效，在垃圾回收时，由于没有线程上下文切换的开销，自然可以获得很高的单线程收集效率。Serial 收集器对于运行在桌面Client 模式下的虚拟机来说是个不错的选择（桌面应用程序新生代内存小，停顿时间可以控制在十几、几十ms）。 ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾回收以外，其余行为和Serial收集器完全一样。 ParNew主要作用于新生代，并采用标记-复制算法。 它是许多运行在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器（真正意义上的并发收集器，后面会介绍到）配合工作。 Parallel Scavenge垃圾收集器HostSpot的年轻代除了拥有ParNew收集器是基于并行回收以外，Parallel Scavenge收集器同样也采用了复制算法、并行回收和“Stop The World”机制。 那么Parallel收集器的出现是否多此一举？ 和ParNew收集器不同，Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量，它也被称为吞吐量优先的垃圾收集器。 自适应调节策略也是Parallel Scavenge与ParNew一个重要区别。 高吞吐量则可以高效率的利用CPU的资源，尽快完成程序的运算任务，主要适合在后台运算不需要太多交互的任务。例如，那些执行批量处理、订单处理、工资支付、科学计算的应用程序。 Parallel收集器在JDK1.6时提供了用于执行老年代垃圾收集的Parallel Old收集器，用来代替来年代的Serial Old收集器。 Parallel Old收集器采用了标记-压缩算法，但同样也是基于并行回收和”Stop the world”机制。 在程序吞吐量优先的场景中，Parallel收集器和Parallel Old收集器的组合，在Server模式下的内存回收性能很不错。 在Java8中，默认是此垃圾收集器。 Serial Old收集器Serial 收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。 Parallel Old收集器Parallel Scavenge 收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。 CMS收集器在JDK1.5时期，HotSpot推出一款在强交互应用中几乎可认为有划时代意义的垃圾收集器：CMS（Concurrent-Mark-Sweep）收集器，这款收集器是HotSpot虚拟机中第一款真正意义上的并发收集器，它第一次实现了要垃圾收集线程与用户线程同时工作。 CMS收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，停顿时间越短就越适合与用户交互的程序，良好的响应速度可以提升用户的体验。 CMS的垃圾收集器算法采用标记-清除算法，并且也会“Stop-the-world”。 但是CMS作为老年代的收集器，却无法与JDK1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作，所以在JDK1.5中使用CMS来收集老年代时，新生代只能选择ParNew或者Serial收集器中的一个。 在G1出现之前，CMS使用还是非常广泛的。一直到现在，仍然还有很多系统使用CMS GC。 CMS优点 并发收集 低延迟 CMS缺点 会产生内存碎片，导致并发清除后，用户线程可用的空间不足。在无法分配大对象的情况下，不得不提前触发Full GC。 CMS收集器对CPU资源非常敏感。在并发阶段，它虽然不会导致用户停顿，但是会因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低。 CMS收集器无法处理浮动垃圾。可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。在并发标记阶段由于程序的工作线程和垃圾收集线程是同时运行或者交叉运行的，那么在并发标记阶段如果产生新的垃圾对象，CMS将无法对这些垃圾对象进行标记，最终会导致这些新产生的垃圾无法被及时回收，从而知道在下一次执行GC时释放这些之前内存空间。 CMS垃圾收集器参数 -XX:+UseConcMarkSweepGC：表明老年代使用CMS GC，同时年轻代触发对ParNew的使用。 -XX:CMSLnitiatingOccupanyFraction：设置堆内存使用率的阈值，一旦达到该阈值，便开始进行回收。 JDK5及以前版本的默认值为68，也就是说老年代的空间使用率达到68%时，会触发一次CMS回收。JDK6及以上版本默认值为92%。 如果内存增长缓慢可以设置一个稍大的值，大的阈值可以有效的减低CMS触发的频率，减少老年代回收的次数可以明显的改善程序的性能。反之，可以降低改阈值，反之频繁的触发Seral垃圾收集器。因此通过该选项可以有效的降低Full GC的执行次数。 G1收集器当前所面对的业务越来越庞大、复杂、用户量越来越多，所以不断的对GC进行优化，Garbage First垃圾收集器是在Java 7 update 4之后引入的一个新的垃圾回收器，是当前收集器技术发展的最前沿成果之一。 为了适应现在不断扩大的内存和不断增加的处理器数量，进一步降低暂停时间，同时兼顾良好的吞吐量。官方给G1设定的目标是在延迟可控的情况下获得尽可能高的吞吐量，所以才担起“全功能收集器”的重担与期望。 原理G1是一个并行回收器，它把堆内存分割为很多不相关的区域（物理上是不连续的）。使用不同的区域来代表Eden、S0、S1、Old等区域。 G1 GC有计划的避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及所需要的时间信息），在后台维护一个优先级列表，每次根据允许收集时间，优先回收价值最大的区域。 G1的优势 并发与并行 并行性：G1在回收期间，可以有多个GC同时工作，有效利用多核计算能力。 并发性：G1拥有与应用程序交替执行的能力，部分工作可以和应用程序同时执行，因此，一般来说，不会再整个回收阶段发生完全阻塞应用程序的情况。 分代收集 从分代上看其实G1还是属于分代型垃圾回收器，它会区分年轻代和老年代，年轻代依然有Eden区、Survivor区，但是从堆的结构上看，它不要求整个Eden区、年轻代或者老年代都是连续的，也不再坚持固定大小和固定数量。 将堆空间分为若干个区域，这些区域中包含逻辑上的年轻代和老年代。 和之前的各类垃圾回收器不同，它同时兼备年轻代和老年代，对比其他回收器，或者工作在年轻代，或者工作在老年代。 空间整合 CMS：“标记-清除”算法、内存碎片、若干次GC后进行一次碎片整理。 G1将内存划分为一个一个Region。内存的回收是以region作为基本单位的，Region之间是复制算法，但整体上可看作是“标记-压缩”算法，这两种算法都可以避免内存碎片。这种特性有利于程序长时间允许，分配大对象时不会因为无法找到连续的内存空间而提前触发下一次Full GC。尤其是当Java堆非常大的时候，G1的优势更加明显。 可预测的停顿时间模型 这是G1相对于CMS的另一大优势，G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间段内，消耗在垃圾收集上的时间不超过N毫秒。 由于分区的原因，可以先选取部分区域进行内存回收，这样缩小了回收的范围，因此对于全局停顿情况的发生也能得到较好的控制。 G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及所需要的时间信息），在后台维护一个优先级列表，每次根据允许的时间，优先回收价值最大的Region。保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。 相比于CMS GC，G1未必能做到CMS在最好情况下的延迟停顿，但是在最差的情况下要好很多。 G1缺点相较于CMS，G1还不具备全方位、压倒性优势。比如在用户程序运行过程中，G1无论是为了垃圾收集产生的内存占用还是程序运行时的额外负载都要比CMS要高。 从经验上来说，在小内存应用上CMS的表现大概率会优于G1，而G1在大内存应用上则发挥其优势。平衡点在6-8GB之间。 G1的参数设置G1使用场景 面向服务端应用，针对具有大内存，多处理器的机器。 最主要的应用时需要低延迟，并且具有大堆的应用程序的提供解决方案。 例如：在堆大小约6GB或者更大时，可预测的暂停时间可以低于0.5s。（G1通过每次只清理一部分而不是全部的Region的增量式清理来保证每次GC停顿时间不会过长） 用来替换JDK1.5中的CMS收集器。 在下列场景中G1可能比CMS更加适合 超过50%的Java堆被活动数据占用； 对象分配频率或年代提升频率变化很大； GC的停顿时间过长（长于0.5~1s） HotSpot垃圾收集器里，除了G1以外，其他垃圾收集器使用内置的JVM线程执行GC的多线程操作，而G1 GC可以采用应用线程承担后台运行的GC工作，即当JVM的GC线程处理速度慢时，系统会调用应用程序的线程去加速垃圾的回收。 G1垃圾回收器的主要环节 年轻代GC（Young GC） 老年代并发标记过程（Concurrent Marking） 混合回收（Mixed GC） 如果需要，Full GC还是继续存在。它针对GC的评估失败提供一种保护措施，即强力回收。 Remembered SetRegion中的对象可能被其他任意Region中对象所引用，那么如果我们对一个Region进行Minor GC时，需要判断此Region的对象是否存活，那么是否需要进行整个堆扫描才能保证结果的准确率呢？其实不仅仅是G1垃圾收集器有此问题，其他的垃圾收集器也有此问题，只是G1垃圾收集器此问题更加突出（因为G1相对来说有更多的Region），如果进行整个堆的扫描的话，肯定会降低Minor GC的效率。 其实无论是G1还是其他分代收集器，都是通过Remembered Set来避免全局扫描，每一个Region都有一个对应的Remembered Set，每次Reference类型数据写操作时，都会产生一个Write Barrier（写屏障）暂时中断的操作。然后检查要写入的引用指向的对象是否和该Reference类型数据在不同的Region，如果不同，则通过CardTable把相关引用信息记录到引用指向对象所在Region对应的Remembered Set中。当进行垃圾收集时，在GC根节点的枚举范围加入Remembered Set，就可以保证不进行全局扫描，并且也不会有遗漏。 G1垃圾收集器回收过程G1垃圾收集器优化建议从Oracle官方透漏出来的信息可知，回收阶段其实本来也想设计成与用户程序一起并发指向，但是具体的实现可能比较复杂，考虑到G1只是回收一部分Region，停顿时间是用户可控制的，所以并不迫切去实现。选择把此特性放到了G1之后的低延迟垃圾收集器（ZGC）中。 年轻代的大小 避免使用-Xmn或-XX:NewRatio等相关参数显示设置年轻代大小。 固定年轻代的大小不合理的话导致暂停时间的目标可能就达不到，所以要JVM动态去调整年轻代的大小。 暂停时间设置的不要太过于严苛 G1 GC的吞吐量目标是90%的应用程序时间和10%的垃圾回收时间 评估G1 GC的吞吐量时，暂停的时间目标太过严苛，表示你愿意承受更多垃圾回收的开销，而这些会直接影响到吞吐量。 Region中还有一块特殊的区域，专门用来存储大对象。G1认为只要大小超过了一个Region容量一半的对象即可判定为大对象。每个Region的大小可能通过参数-XX：G1HeapRegionSize设定，取值范围1MB~32MB，而对于那些超过了整个Region容量的超级大对象，将会被存放在N个连续的Region之中，G1的大多数行为都把Humongous Region作为老年代的一部分来看待。 ZGCG1垃圾收集器通过部分区域回收的处理形式，解决了传统垃圾收集器中的全堆扫描所带来的性能问题，极大的改善在堆内存较大情况下的停顿时间，但是随着硬件性能的发展，G1回收器也同样受到了极大的性能限制。 所以Oracle为OpenJDK开源了一款ZGC垃圾回收器，ZGC是一款可伸缩、低延迟、并发垃圾回收器，ZGC的出现旨在实现以下目标： 停顿时间不超过10ms 停顿时间不随heap大小或存活对象大小增大而增大 可以处理几百M到几T的内存大小 ZGC是一款基于Region布局，但是不设置分代，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-压缩算法，以低延迟为首要目标的一款垃圾收集器。 ZGC几乎在所有地方都并发指向，除了初始化标记是STW的，所以停顿时间就耗费在初始标记上，实际上这部分时间是非常少的。 ZGC性能对比：","link":"/2022/01/29/2022-02-02_JVM%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E8%AF%A6%E8%A7%A3/"},{"title":"并发编程系列之ThreadLocal详解","text":"ThreadLocal详解 前言ThreadLocal的主要价值在于线程隔离，ThreadLocal中的数据只属于当前线程，其本地值对别的线程是不可见的，在多线程环境下，可以防止自己的变量被其他线程篡改。 实现原理","link":"/2022/01/29/2022-02-15_ThreadLocal%E8%AF%A6%E8%A7%A3/"},{"title":"并发编程系列","text":"开个并发编程系列的坑~ 并发编程之基础知识并发编程之ThreadLocal并发编程之阻塞队列","link":"/2023/02/23/2022-06-01_%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%B3%BB%E5%88%97/"},{"title":"Nacos源码相关","text":"Nacos源码相关分析 背景此Nacos笔记基于Nacos版本2.1.0 (Apr 29, 2022)。 编译Nacos源码 从同性交友网站上将Nacos导入IDEA 首先IDEA需要安装Protobuf Support插件（protobuf是一种数据交换格式，又称PB编码，由Google开源），安装后通过protobuf编译将proto生成java文件 在nacos目录下执行mvn -Prelease-nacos -Dmaven.test.skip=true clean install -U 在console模块中找到Nacos启动类新增VM options：-Dnacos.standalone=true单机版启动Nacos 此方式启动模式是单机版启动并且使用的是内置数据库，对于初学Nacos已经足以。 Nacos服务注册原理Nacos在2.0版本之前都是通过HTTP的方式去注册服务，在2.0版本新增Grpc的方式。 Nacos集成SpringCloudAlibaba服务注册原理入口V1版本服务注册原理——ClientV1版本服务注册原理——Serverspring-cloud-sarter-alibaba-nacos-discovery初始化Grpc连接流程spring-cloud-starter-alibaba-nacos-discovery通过com.alibaba.cloud.nacos.discovery.NacosWatch实现org.springframework.context.SmartLifecycle接口来初始化启动、停止Nacos组件。 123456789101112131415161718192021222324252627282930313233343536public class NacosWatch implements ApplicationEventPublisherAware, SmartLifecycle, DisposableBean { @Override public void start() { if (this.running.compareAndSet(false, true)) { EventListener eventListener = listenerMap.computeIfAbsent(buildKey(), event -&gt; new EventListener() { @Override public void onEvent(Event event) { if (event instanceof NamingEvent) { List&lt;Instance&gt; instances = ((NamingEvent) event) .getInstances(); Optional&lt;Instance&gt; instanceOptional = selectCurrentInstance( instances); instanceOptional.ifPresent(currentInstance -&gt; { resetIfNeeded(currentInstance); }); } } }); // 初始化NacosService NamingService namingService = nacosServiceManager .getNamingService(properties.getNacosProperties()); try { namingService.subscribe(properties.getService(), properties.getGroup(), Arrays.asList(properties.getClusterName()), eventListener); } catch (Exception e) { log.error(&quot;namingService subscribe failed, properties:{}&quot;, properties, e); } this.watchFuture = this.taskScheduler.scheduleWithFixedDelay( this::nacosServicesWatch, this.properties.getWatchDelay()); } }} NacosServiceManager是对NamingService进行管理的类，委托调用Nacos的api去创建NamingService 12345678910111213141516171819202122232425262728293031public class NacosServiceManager { public NamingService getNamingService(Properties properties) { // 如果namingService为空，则创建NamingService if (Objects.isNull(this.namingService)) { buildNamingService(properties); } return namingService; } private NamingService buildNamingService(Properties properties) { if (Objects.isNull(namingService)) { synchronized (NacosServiceManager.class) { if (Objects.isNull(namingService)) { // 创建namingService namingService = createNewNamingService(properties); } } } return namingService; } private NamingService createNewNamingService(Properties properties) { try { // 调用com.alibaba.nacos.api.NacosFactory#createNamingService(java.util.Properties)创建namingService return createNamingService(properties); } catch (NacosException e) { throw new RuntimeException(e); } }} Nacos关于Grpc的封装在Nacos2.0版本之后，Nacos支持了Grpc的通讯，如果有同学对于Grpc不了解，请先行了解Grpc。 Server整体概览： BaseRpcServer：定义了基本的服务启动以及关闭的接口。 BaseGrpcServer：实现了基本的Server模块的功能。 GrpcClusterServer：用于集群中节点的交互。 GrpcSdkServer：用于客户端和服务端的交互。 Client整体概览： RpcClient在Client端，它的整体层次和Server端是类似的，不同的是RpcServer单单定义接口，但是RpcClient不仅定义了接口，还提供了诸多的实现，例如: 消息发送 服务器列表改变，重新连接下一个服务器 …… 123456789101112131415public abstract class RpcClient implements Closeable { // 连接以及断开连接事件的阻塞队列 protected BlockingQueue&lt;ConnectionEvent&gt; eventLinkedBlockingQueue = new LinkedBlockingQueue&lt;&gt;(); // rpcClient的启动状态 protected volatile AtomicReference&lt;RpcClientStatus&gt; rpcClientStatus = new AtomicReference&lt;&gt;( RpcClientStatus.WAIT_INIT); // 重新连接信号的阻塞队列 private final BlockingQueue&lt;ReconnectContext&gt; reconnectionSignal = new ArrayBlockingQueue&lt;&gt;(1); // 服务可用列表变化，判断当前的连接的服务是否在服务可用列表中，如果不在则放入reconnectionSignal中，开始重新连接 public void onServerListChange() {...} // 将rpcClient启动状态置为STARTING // 初始化一个线程池处理eventLinkedBlockingQueue中的事件,通知对于的listener // 初始化一个线程池处理reconnectionSignal中的重新连接的信号 public final void start() throws NacosException { ... }} GrpcClient在RpcClient中定义了基本客户端与远端服务器通讯功能的抽象，而具体的通讯实现则由下面的具体实现来负责。 GrpcClient负责与远程服务器建立连接，创建一个GrpcConnection的对象，并初始化Grpc一元请求的stub以及双向流的stub，并且将他们以及初始化的Channel注入到GrpcConnection中，随后发送一个连接建立的请求，在服务端注册自己的连接。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public abstract class GrpcClient extends RpcClient { @Override public Connection connectToServer(ServerInfo serverInfo) { try { // 如果grpcExecutor为空，则初始化 if (grpcExecutor == null) { this.grpcExecutor = createGrpcExecutor(serverInfo.getServerIp()); } // 获取暴漏的端口 int port = serverInfo.getServerPort() + rpcPortOffset(); // 初始化一元请求调用的stub RequestGrpc.RequestFutureStub newChannelStubTemp = createNewChannelStub(serverInfo.getServerIp(), port); if (newChannelStubTemp != null) { // 检查stub是否有效，如果无效直接shuntDown channel Response response = serverCheck(serverInfo.getServerIp(), port, newChannelStubTemp); if (response == null || !(response instanceof ServerCheckResponse)) { shuntDownChannel((ManagedChannel) newChannelStubTemp.getChannel()); return null; } // 初始化双向流stub BiRequestStreamGrpc.BiRequestStreamStub biRequestStreamStub = BiRequestStreamGrpc .newStub(newChannelStubTemp.getChannel()); // 初始化grpcConn GrpcConnection grpcConn = new GrpcConnection(serverInfo, grpcExecutor); // 将响应的response中的connectId设置到grpcConn中 grpcConn.setConnectionId(((ServerCheckResponse) response).getConnectionId()); // create stream request and bind connection event to this connection. // 创建双向流并且将双向流绑定到grpcConn StreamObserver&lt;Payload&gt; payloadStreamObserver = bindRequestStream(biRequestStreamStub, grpcConn); // stream observer to send response to server // 设置双向流到grpcConn中 grpcConn.setPayloadStreamObserver(payloadStreamObserver); // 设置单向流到grpcConn中 grpcConn.setGrpcFutureServiceStub(newChannelStubTemp); // 设置channel到grpcConn中 grpcConn.setChannel((ManagedChannel) newChannelStubTemp.getChannel()); // send a setup request. // 向服务器发送设置双向流请求 ConnectionSetupRequest conSetupRequest = new ConnectionSetupRequest(); conSetupRequest.setClientVersion(VersionUtils.getFullClientVersion()); conSetupRequest.setLabels(super.getLabels()); conSetupRequest.setAbilities(super.clientAbilities); conSetupRequest.setTenant(super.getTenant()); grpcConn.sendRequest(conSetupRequest); // wait to register connection setup // TODO stone-98 应该是等待服务端设置 Thread.sleep(100L); return grpcConn; } return null; } catch (Exception e) { LOGGER.error(&quot;[{}]Fail to connect to server!,error={}&quot;, GrpcClient.this.getName(), e); } return null; }} GrpcConnect整体概览： Requester：定义了基本的请求接口 Connection：继承了Requester接口，在Requester接口的基础上扩展了connectionId、isAbandon字段 GrpcConnection：对Connection进行了实现 V2版本服务注册原理——ClientV2版本服务注册原理——ServerNacos相关包的作用使用Nacos分别需要导入如下两个包: 12345678&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;&lt;/dependency&gt; spring-cloud-starter-alibaba-nacos-discovery：该项目通过自动配置以及其他 Spring 编程模型的习惯用法为 Spring Boot 应用程序在服务注册与发现方面提供和 Nacos 的无缝集成。 spring-cloud-starter-alibaba-nacos-config：Nacos 提供用于存储配置和其他元数据的 key/value 存储，为分布式系统中的外部化配置提供服务器端和客户端支持。 服务注册原理分析注册注册的入口是org.springframework.cloud.client.serviceregistry.AbstractAutoServiceRegistration#bind监听org.springframework.boot.web.context.WebServerInitializedEvent事件，当WebServer初始化完毕之后发生回调bind（）方法。 分析关键类AbstractAutoServiceRegistartion(由于篇幅原因，仅分析大概流程，不详细讲解每个方法)： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public abstract class AbstractAutoServiceRegistration&lt;R extends Registration&gt; implements AutoServiceRegistration, ApplicationContextAware { private ApplicationContext context; private Environment environment; private final ServiceRegistry&lt;R&gt; serviceRegistry; private AutoServiceRegistrationProperties properties; @EventListener(WebServerInitializedEvent.class) public void bind(WebServerInitializedEvent event) { ApplicationContext context = event.getApplicationContext(); // TODO 为什么要这样处理？ if (context instanceof ConfigurableWebServerApplicationContext) { if (&quot;management&quot;.equals( ((ConfigurableWebServerApplicationContext) context).getServerNamespace())) { return; } } this.port.compareAndSet(0, event.getWebServer().getPort()); this.start(); } public void start() { // 如果未开启服务注册，直接处理完成 if (!isEnabled()) { if (logger.isDebugEnabled()) { logger.debug(&quot;Discovery Lifecycle disabled. Not starting&quot;); } return; } // only initialize if nonSecurePort is greater than 0 and it isn't already running // because of containerPortInitializer below if (!this.running.get()) { // 依托serviceRegistry实现注册 register(); // TODO？ if (shouldRegisterManagement()) { registerManagement(); } // 自身注册之后发布事件 this.context.publishEvent(new InstanceRegisteredEvent&lt;&gt;(this, getConfiguration())); // 修改运行状态 this.running.compareAndSet(false, true); } } public void stop() {}} AbstractAutoServiceRegistration中有两个属性AutoServiceRegistrationProperties、ServiceRegistry，我们从字面基本上能猜测出，AbstractAutoServiceRegistration通过AutoServiceRegistrationProperties的属性依托ServiceRegistry从而实现自动注册，所以真正实现自动注册的应该是ServiceRegistry中。 我们回到bind()方法也是就是我们的入口，它进行上下文的namespace判断之后，初始化我们启动的端口之后调用start()方法。 start()的处理逻辑，首先判断我们是否开启服务注册，否则直接跳过，然后依托serviceRegistry完成注册之后，发布注册之后的事件。 12345678910111213141516171819202122232425262728293031323334public class NacosServiceRegistry implements ServiceRegistry&lt;Registration&gt; { ... private final NacosDiscoveryProperties nacosDiscoveryProperties; private final NamingService namingService; ... @Override public void register(Registration registration) { if (StringUtils.isEmpty(registration.getServiceId())) { log.warn(&quot;No service to register for nacos client...&quot;); return; } String serviceId = registration.getServiceId(); Instance instance = new Instance(); instance.setIp(registration.getHost()); instance.setPort(registration.getPort()); instance.setWeight(nacosDiscoveryProperties.getWeight()); instance.setClusterName(nacosDiscoveryProperties.getClusterName()); instance.setMetadata(registration.getMetadata()); try { namingService.registerInstance(serviceId, instance); log.info(&quot;nacos registry, {} {}:{} register finished&quot;, serviceId, instance.getIp(), instance.getPort()); } catch (Exception e) { log.error(&quot;nacos registry, {} register failed...{},&quot;, serviceId, registration.toString(), e); } }} 注意到NacosServoceRegistry中有两个属性： nacosDiscoveryProperties：nacos自动发现相关属性 namingService：用于客户端注册实例或者查询实例 1234567891011121314151617181920212223242526272829303132333435public class NacosNamingService implements NamingService { ... @Override public void registerInstance(String serviceName, Instance instance) throws NacosException { registerInstance(serviceName, Constants.DEFAULT_GROUP, instance); } ... @Override public void registerInstance(String serviceName, String groupName, Instance instance) throws NacosException { // nacos 1.0版本新增的ephemeral字段，它表示注册的实例是临时的还是持久的。 // 如果是临时的，则不会再Nacos服务端持久化存储，需要用心跳的方式保活，如果一段事件没有上报心跳，则会被服务端摘除。 // 持久化实例则会被Nacos服务端持久化，如果此时客户端已下线，这个实例也不会从客户端剔除，只会将健康状态设为不健康。 // 上面说了两种模式的不同和处理上的区别，那么Nacos为什么设计两种模式，它们是为了应对什么样的场景而存在呢？ // 对于临时实例，健康检查失败，则直接可以从列表中删除。这种特性就比较适合那些需要应对流量突增的场景，服务可以进行弹性扩容。当流量过去之后，服务停掉即可自动注销了。 // 对于持久化实例，健康检查失败，会被标记成不健康状态。它的好处是运维可以实时看到实例的健康状态，便于后续的警告、扩容等一些列措施。 // https://developer.aliyun.com/article/845113 // 如果是临时节点，则需要利用心跳信息进行保活 if (instance.isEphemeral()) { BeatInfo beatInfo = new BeatInfo(); beatInfo.setServiceName(NamingUtils.getGroupedName(serviceName, groupName)); beatInfo.setIp(instance.getIp()); beatInfo.setPort(instance.getPort()); beatInfo.setCluster(instance.getClusterName()); beatInfo.setWeight(instance.getWeight()); beatInfo.setMetadata(instance.getMetadata()); beatInfo.setScheduled(false); long instanceInterval = instance.getInstanceHeartBeatInterval(); beatInfo.setPeriod(instanceInterval == 0 ? DEFAULT_HEART_BEAT_INTERVAL : instanceInterval); // 定时发送心跳 beatReactor.addBeatInfo(NamingUtils.getGroupedName(serviceName, groupName), beatInfo); } // 服务zhu'ce serverProxy.registerService(NamingUtils.getGroupedName(serviceName, groupName), groupName, instance); }} 服务端12345678910111213141516171819202122// 实例相关的操作@RestController@RequestMapping(UtilsAndCommons.NACOS_NAMING_CONTEXT + UtilsAndCommons.NACOS_NAMING_INSTANCE_CONTEXT)public class InstanceController { // 注册实例 @CanDistro @PostMapping @Secured(action = ActionTypes.WRITE) public String register(HttpServletRequest request) throws Exception { final String namespaceId = WebUtils .optional(request, CommonParams.NAMESPACE_ID, Constants.DEFAULT_NAMESPACE_ID); final String serviceName = WebUtils.required(request, CommonParams.SERVICE_NAME); NamingUtils.checkServiceNameFormat(serviceName); // 构建实例 final Instance instance = HttpRequestInstanceBuilder.newBuilder() .setDefaultInstanceEphemeral(switchDomain.isDefaultInstanceEphemeral()).setRequest(request).build(); // 分别对应着两个版本，v1和v2（实现了通过grpc进行通讯）版本，通过配置选取对应的实现进行注册实例 getInstanceOperator().registerInstance(namespaceId, serviceName, instance); return &quot;ok&quot;; }} v1版本的实现： 12345678910@Componentpublic class InstanceOperatorServiceImpl implements InstanceOperator { @Override public void registerInstance(String namespaceId, String serviceName, Instance instance) throws NacosException { // 从v2版本的实例转换到v1版本 com.alibaba.nacos.naming.core.Instance coreInstance = parseInstance(instance); // 注册实例 serviceManager.registerInstance(namespaceId, serviceName, coreInstance); }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@Componentpublic class ServiceManager implements RecordListener&lt;Service&gt; { // 实例的缓存信息 结构：Map(namespace, Map(group::serviceName, Service)). private final Map&lt;String, Map&lt;String, Service&gt;&gt; serviceMap = new ConcurrentHashMap&lt;&gt;(); // 注册实例 public void registerInstance(String namespaceId, String serviceName, Instance instance) throws NacosException { // 如果实例不存在，则初始化服务对象并把它放入缓存中 createEmptyService(namespaceId, serviceName, instance.isEphemeral()); Service service = getService(namespaceId, serviceName); checkServiceIsNull(service, namespaceId, serviceName); addInstance(namespaceId, serviceName, instance.isEphemeral(), instance); } public void createEmptyService(String namespaceId, String serviceName, boolean local) throws NacosException { createServiceIfAbsent(namespaceId, serviceName, local, null); } public void createServiceIfAbsent(String namespaceId, String serviceName, boolean local, Cluster cluster) throws NacosException { Service service = getService(namespaceId, serviceName); // 该服务未被初始化 if (service == null) { Loggers.SRV_LOG.info(&quot;creating empty service {}:{}&quot;, namespaceId, serviceName); service = new Service(); service.setName(serviceName); service.setNamespaceId(namespaceId); service.setGroupName(NamingUtils.getGroupName(serviceName)); // now validate the service. if failed, exception will be thrown service.setLastModifiedMillis(System.currentTimeMillis()); service.recalculateChecksum(); if (cluster != null) { cluster.setService(service); service.getClusterMap().put(cluster.getName(), cluster); } service.validate(); // 1、将实例放置缓存中 // 2、启动检查该服务下实例心跳的线程 // 3、给该服务新增监听器 putServiceAndInit(service); // 如果该实例不是临时实例，则需要新增服务信息到Nacos集群中 if (!local) { addOrReplaceService(service); } } } public Service getService(String namespaceId, String serviceName) { Map&lt;String, Service&gt; service = this.serviceMap.get(namespaceId); if (service == null) { return null; } return service.get(serviceName); }} 服务实例的监听机制对于Nacos的服务的实例都有对应的监听机制，当服务的实例发生变化时，例如：新增、删除实例，都触发对应的动作。 监听机制注册当服务注册时，有如下代码： 1234consistencyService .listen(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), true), service);consistencyService .listen(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), false), service); 此代码分别给服务注册了临时和持久服务对应的监听机制。 监听机制的触发以Distro协议为例，具体的逻辑在com.alibaba.nacos.naming.consistency.ephemeral.distro.DistroConsistencyServiceImpl中 123456789101112@DependsOn(&quot;ProtocolManager&quot;)@org.springframework.stereotype.Service(&quot;distroConsistencyService&quot;)public class DistroConsistencyServiceImpl implements EphemeralConsistencyService, DistroDataProcessor { ... private volatile Notifier notifier = new Notifier(); ... @PostConstruct public void init() { GlobalExecutor.submitDistroNotifyTask(notifier); } ...} 通过@PostConstruct触发通知任务。 服务实例变化之后的处理上述说到，当服务实例发生变化后，分别触发com.alibaba.nacos.naming.core.Service#onChange和com.alibaba.nacos.naming.core.Service#onDelete方法，这里讲解他们具体做了什么处理。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697@JsonInclude(Include.NON_NULL)public class Service extends com.alibaba.nacos.api.naming.pojo.Service implements Record, RecordListener&lt;Instances&gt; { @Override public void onChange(String key, Instances value) throws Exception { Loggers.SRV_LOG.info(&quot;[NACOS-RAFT] datum is changed, key: {}, value: {}&quot;, key, value); for (Instance instance : value.getInstanceList()) { // 校验实例不能为空 if (instance == null) { // Reject this abnormal instance list: throw new RuntimeException(&quot;got null instance &quot; + key); } // 权重的取值范围0.01&lt;权重&lt;10000 if (instance.getWeight() &gt; 10000.0D) { instance.setWeight(10000.0D); } if (instance.getWeight() &lt; 0.01D &amp;&amp; instance.getWeight() &gt; 0.0D) { instance.setWeight(0.01D); } } // 更新实例信息 updateIPs(value.getInstanceList(), KeyBuilder.matchEphemeralInstanceListKey(key)); // 重新计算checksum recalculateChecksum(); } @Override public void onDelete(String key) throws Exception { boolean isEphemeral = KeyBuilder.matchEphemeralInstanceListKey(key); for (Cluster each : clusterMap.values()) { each.updateIps(Collections.emptyList(), isEphemeral); } } public void updateIPs(Collection&lt;Instance&gt; instances, boolean ephemeral) { // 初始化Map&lt;clusterName, List&lt;Instance&gt;&gt; Map&lt;String, List&lt;Instance&gt;&gt; ipMap = new HashMap&lt;&gt;(clusterMap.size()); for (String clusterName : clusterMap.keySet()) { ipMap.put(clusterName, new ArrayList&lt;&gt;()); } // 遍历所有实例，将实例加入ipMap中 for (Instance instance : instances) { try { if (instance == null) { Loggers.SRV_LOG.error(&quot;[NACOS-DOM] received malformed ip: null&quot;); continue; } // 如果集群名称为空设置默认集群名称 if (StringUtils.isEmpty(instance.getClusterName())) { instance.setClusterName(UtilsAndCommons.DEFAULT_CLUSTER_NAME); } // 如果现有集群名称中不包含此集群名称则需要新建 if (!clusterMap.containsKey(instance.getClusterName())) { Loggers.SRV_LOG.warn( &quot;cluster: {} not found, ip: {}, will create new cluster with default configuration.&quot;, instance.getClusterName(), instance.toJson()); Cluster cluster = new Cluster(instance.getClusterName(), this); cluster.init(); getClusterMap().put(instance.getClusterName(), cluster); } ipMap.putIfAbsent(instance.getClusterName(), new LinkedList&lt;&gt;()); ipMap.get(instance.getClusterName()).add(instance); } catch (Exception e) { Loggers.SRV_LOG.error(&quot;[NACOS-DOM] failed to process ip: &quot; + instance, e); } } for (Map.Entry&lt;String, List&lt;Instance&gt;&gt; entry : ipMap.entrySet()) { //make every ip mine List&lt;Instance&gt; entryIPs = entry.getValue(); // 更新Cluster clusterMap.get(entry.getKey()).updateIps(entryIPs, ephemeral); } // 修改最近更新时间 setLastModifiedMillis(System.currentTimeMillis()); // 发布服务改变时间 getPushService().serviceChanged(this); // 执行双写服务 ApplicationUtils.getBean(DoubleWriteEventListener.class).doubleWriteToV2(this, ephemeral); StringBuilder stringBuilder = new StringBuilder(); for (Instance instance : allIPs()) { stringBuilder.append(instance.toIpAddr()).append('_').append(instance.isHealthy()).append(','); } // 打野所有实例 Loggers.EVT_LOG.info(&quot;[IP-UPDATED] namespace: {}, service: {}, ips: {}&quot;, getNamespaceId(), getName(), stringBuilder.toString()); }} 心跳机制Nacos的心跳机制和临时实例和持久实例的特性息息相关，所以我这里通过临时实例和持久化实例作为维度进行分析。 临时实例：临时实例只是临时注册在注册中心上，当服务下线或服务不可用时会被注册中心剔除，临时实例会与注册中心保持心跳，当服务端在指定时间没有接收到客户端的心跳信息，则会把实例状态置为不健康，然后在一段时间之后将它从注册中心剔除。 持久实例：永久实例会永久注册在注册中心，除非对它进行删除操作才能将它剔除，并且对于永久实例它可能并不知道注册中心的存在，不会向注册中心上报心跳，而是注册中心主动对他进行探活。 临时实例客户端心跳机制在客户端启动时，在发起服务注册的逻辑中，有如下代码: 1234567891011public class NacosNamingService implements NamingService { public void registerInstance(String serviceName, String groupName, Instance instance) throws NacosException { String groupedServiceName = NamingUtils.getGroupedName(serviceName, groupName); // 是否临时实例，临时实例则需要客户端主动推送心跳，而持久实例则通过服务端主动探测 if (instance.isEphemeral()) { BeatInfo beatInfo = this.beatReactor.buildBeatInfo(groupedServiceName, instance); this.beatReactor.addBeatInfo(groupedServiceName, beatInfo); } this.serverProxy.registerService(groupedServiceName, groupName, instance); }} 在上述代码中，如果注册的时临时实例，则客户端开启线程主动给注册中心上报心跳信息。 12345678910111213141516public void addBeatInfo(String serviceName, BeatInfo beatInfo) { LogUtils.NAMING_LOGGER.info(&quot;[BEAT] adding beat: {} to beat map.&quot;, beatInfo); // 通过服务名称、ip、port构建唯一key String key = this.buildKey(serviceName, beatInfo.getIp(), beatInfo.getPort()); // 如果已经注册该实例则先停止已经存在的实例 BeatInfo existBeat = null; if ((existBeat = (BeatInfo)this.dom2Beat.remove(key)) != null) { existBeat.setStopped(true); } this.dom2Beat.put(key, beatInfo); // 心跳线程开始调度 this.executorService.schedule(new BeatReactor.BeatTask(beatInfo), beatInfo.getPeriod(), TimeUnit.MILLISECONDS); // 设置metrics MetricsMonitor.getDom2BeatSizeMonitor().set((double)this.dom2Beat.size()); } 心跳任务代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class BeatTask implements Runnable { BeatInfo beatInfo; public BeatTask(BeatInfo beatInfo) { this.beatInfo = beatInfo; } public void run() { // 如果停止则直接结束，并且不开始下一次的调度 if (!this.beatInfo.isStopped()) { // 获取心跳间隔 long nextTime = this.beatInfo.getPeriod(); try { JsonNode result = BeatReactor.this.serverProxy.sendBeat(this.beatInfo, BeatReactor.this.lightBeatEnabled); long interval = result.get(&quot;clientBeatInterval&quot;).asLong(); boolean lightBeatEnabled = false; if (result.has(&quot;lightBeatEnabled&quot;)) { lightBeatEnabled = result.get(&quot;lightBeatEnabled&quot;).asBoolean(); } // 标记心跳已经开启 BeatReactor.this.lightBeatEnabled = lightBeatEnabled; // 如果服务端返回的间隔时间不为空，则以服务端返回的为准 if (interval &gt; 0L) { nextTime = interval; } int code = 10200; if (result.has(&quot;code&quot;)) { code = result.get(&quot;code&quot;).asInt(); } // 如果返回值==20404代表资源没找到，则开始新的一轮注册 if (code == 20404) { Instance instance = new Instance(); instance.setPort(this.beatInfo.getPort()); instance.setIp(this.beatInfo.getIp()); instance.setWeight(this.beatInfo.getWeight()); instance.setMetadata(this.beatInfo.getMetadata()); instance.setClusterName(this.beatInfo.getCluster()); instance.setServiceName(this.beatInfo.getServiceName()); instance.setInstanceId(instance.getInstanceId()); instance.setEphemeral(true); try { BeatReactor.this.serverProxy.registerService(this.beatInfo.getServiceName(), NamingUtils.getGroupName(this.beatInfo.getServiceName()), instance); } catch (Exception var10) { } } } catch (NacosException var11) { LogUtils.NAMING_LOGGER.error(&quot;[CLIENT-BEAT] failed to send beat: {}, code: {}, msg: {}&quot;, new Object[]{JacksonUtils.toJson(this.beatInfo), var11.getErrCode(), var11.getErrMsg()}); } // 开始下一次的心跳发起 BeatReactor.this.executorService.schedule(BeatReactor.this.new BeatTask(this.beatInfo), nextTime, TimeUnit.MILLISECONDS); } } } 临时实例服务端心跳机制1234567891011121314@RestController@RequestMapping(UtilsAndCommons.NACOS_NAMING_CONTEXT + UtilsAndCommons.NACOS_NAMING_INSTANCE_CONTEXT)public class InstanceController { @CanDistro @PutMapping(&quot;/beat&quot;) @Secured(action = ActionTypes.WRITE) public ObjectNode beat(HttpServletRequest request) throws Exception { ... int resultCode = getInstanceOperator() .handleBeat(namespaceId, serviceName, ip, port, clusterName, clientBeat, builder); ... return result; }} chuli 123456789101112131415161718192021222324252627282930313233@Override public int handleBeat(String namespaceId, String serviceName, String ip, int port, String cluster, RsInfo clientBeat, BeatInfoInstanceBuilder builder) throws NacosException { // 转换实体 com.alibaba.nacos.naming.core.Instance instance = serviceManager .getInstance(namespaceId, serviceName, cluster, ip, port); if (instance == null) { // 如果实例为空并且客户端发送的心跳也为空，则返回RESOURCE_NOT_FOUND if (clientBeat == null) { return NamingResponseCode.RESOURCE_NOT_FOUND; } // 如果客户端的心跳不为空，则重新注册 Loggers.SRV_LOG.warn(&quot;[CLIENT-BEAT] The instance has been removed for health mechanism, &quot; + &quot;perform data compensation operations, beat: {}, serviceName: {}&quot;, clientBeat, serviceName); instance = parseInstance(builder.setBeatInfo(clientBeat).setServiceName(serviceName).build()); serviceManager.registerInstance(namespaceId, serviceName, instance); } Service service = serviceManager.getService(namespaceId, serviceName); serviceManager.checkServiceIsNull(service, namespaceId, serviceName); // 如果客户端的心跳为空，则创建心跳 if (clientBeat == null) { clientBeat = new RsInfo(); clientBeat.setIp(ip); clientBeat.setPort(port); clientBeat.setCluster(cluster); } // 对心跳进行处理 service.processClientBeat(clientBeat); return NamingResponseCode.OK; } 处理逻辑 123456789101112131415161718192021222324252627282930313233343536public class ClientBeatProcessor implements BeatProcessor { @Override public void run() { Service service = this.service; if (Loggers.EVT_LOG.isDebugEnabled()) { Loggers.EVT_LOG.debug(&quot;[CLIENT-BEAT] processing beat: {}&quot;, rsInfo.toString()); } String ip = rsInfo.getIp(); String clusterName = rsInfo.getCluster(); int port = rsInfo.getPort(); // 通过集群名称获取此集群 Cluster cluster = service.getClusterMap().get(clusterName); List&lt;Instance&gt; instances = cluster.allIPs(true); // 对集群中所有实例进行处理 for (Instance instance : instances) { if (instance.getIp().equals(ip) &amp;&amp; instance.getPort() == port) { if (Loggers.EVT_LOG.isDebugEnabled()) { Loggers.EVT_LOG.debug(&quot;[CLIENT-BEAT] refresh beat: {}&quot;, rsInfo.toString()); } // 更新实例最后心跳时间 instance.setLastBeat(System.currentTimeMillis()); // 如果实例没有被标记，并且目前处于不健康状态，则更新实例的健康状态，并且发布实例状态改变事件 if (!instance.isMarked() &amp;&amp; !instance.isHealthy()) { instance.setHealthy(true); Loggers.EVT_LOG .info(&quot;service: {} {POS} {IP-ENABLED} valid: {}:{}@{}, region: {}, msg: client beat ok&quot;, cluster.getService().getName(), ip, port, cluster.getName(), UtilsAndCommons.LOCALHOST_SITE); // 对订阅此服务的客户端发送udp事件通知 getPushService().serviceChanged(service); } } } }} 持久化实例的检查机制持久化实例的检查机制是服务成功注册之后，然后通过定时任务类似的机制，由服务端主动向客户端发起探测。 123456789101112public class Cluster extends com.alibaba.nacos.api.naming.pojo.Cluster implements Cloneable { // 集群的初始化方法，开启健康检查任务 public void init() { if (inited) { return; } checkTask = new HealthCheckTask(this); HealthCheckReactor.scheduleCheck(checkTask); inited = true; }} 健康检查的核心逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class HealthCheckTask implements Runnable { @Override public void run() { try { // 如果使用了2.0+grpc的功能，则不进入 // If upgrade to 2.0.X stop health check with v1 if (ApplicationUtils.getBean(UpgradeJudgement.class).isUseGrpcFeatures()) { return; } if (distroMapper.responsible(cluster.getService().getName()) &amp;&amp; switchDomain .isHealthCheckEnabled(cluster.getService().getName())) { healthCheckProcessor.process(this); if (Loggers.EVT_LOG.isDebugEnabled()) { Loggers.EVT_LOG .debug(&quot;[HEALTH-CHECK] schedule health check task: {}&quot;, cluster.getService().getName()); } } } catch (Throwable e) { Loggers.SRV_LOG .error(&quot;[HEALTH-CHECK] error while process health check for {}:{}&quot;, cluster.getService().getName(), cluster.getName(), e); } finally { if (!cancelled) { HealthCheckReactor.scheduleCheck(this); // worst == 0 means never checked if (this.getCheckRtWorst() &gt; 0 &amp;&amp; switchDomain.isHealthCheckEnabled(cluster.getService().getName()) &amp;&amp; distroMapper.responsible(cluster.getService().getName())) { // TLog doesn't support float so we must convert it into long long diff = ((this.getCheckRtLast() - this.getCheckRtLastLast()) * 10000) / this.getCheckRtLastLast(); this.setCheckRtLastLast(this.getCheckRtLast()); Cluster cluster = this.getCluster(); if (Loggers.CHECK_RT.isDebugEnabled()) { Loggers.CHECK_RT.debug(&quot;{}:{}@{}-&gt;normalized: {}, worst: {}, best: {}, last: {}, diff: {}&quot;, cluster.getService().getName(), cluster.getName(), cluster.getHealthChecker().getType(), this.getCheckRtNormalized(), this.getCheckRtWorst(), this.getCheckRtBest(), this.getCheckRtLast(), diff); } } } } }} V2的健康检查机制健康检查的拦截链机制Nacos服务端在处理健康检查和心跳机制的时候是采用拦截链来执行的，拦截链内部有多个拦截器，通过获取不同的拦截器链实例，在实例内部指定具体的拦截器类型来组成一组拦截器。这里使用了拦截器模式和模板模式来组织代码。拦截器模式体现在整体拦截机制的实现，模板模式主要体现在对拦截器链的抽象实现上。 拦截链的核心类图 核心类： Interceptable：定义了该拦截链处理的对象基类 void passIntercept()：该对象没有被拦截器拦截，则执行该方法中具体的业务逻辑 void afterIntercept()：该对象在被拦截链拦截之后，则执行该方法中具体的业务逻辑 NacosNamingInterceptor：定义一个拦截器的基本功能，同时限定了传入的拦截对象类型必须为Interceptable以及Interceptable的子类 boolean isInterceptType(Class&lt;?&gt; type)：判断拦截器是否支持处理这个类型 boolean intercept(T object)：判断是否执行拦截操作 int order()：拦截器的优先级，数字越低优先级越高 NacosNamingInterceptorChain：定义了拦截器链对象应该具有的基本行为 void addInterceptor(NacosNamingInterceptor interceptor)：添加拦截器 void doInterceptor(T object)：执行拦截器 AbstractNamingInterceptorChain：抽象的拦截链，定义了拦截链的基本工作流程 public void addInterceptor(NacosNamingInterceptor interceptor)：向interceptors属性中新增拦截器 public void doInterceptor(T object)：通过interceptors对传入的Interceptable的子类执行拦截操作，拦截成功后调用com.alibaba.nacos.naming.interceptor.Interceptable#afterIntercept，否则调用com.alibaba.nacos.naming.interceptor.Interceptable#passIntercept AbstractNamingInterceptorChain具体的源码解析如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public abstract class AbstractNamingInterceptorChain&lt;T extends Interceptable&gt; implements NacosNamingInterceptorChain&lt;T&gt; { // 存储多个拦截器 private final List&lt;NacosNamingInterceptor&lt;T&gt;&gt; interceptors; // protected限制只有当前包和子类才能够对它进行初始化 protected AbstractNamingInterceptorChain(Class&lt;? extends NacosNamingInterceptor&lt;T&gt;&gt; clazz) { // 初始化拦截链 this.interceptors = new LinkedList&lt;&gt;(); // 使用SPI模式加载指定的拦截器类型 interceptors.addAll(NacosServiceLoader.load(clazz)); // 对拦截器的顺序进行排序 interceptors.sort(Comparator.comparingInt(NacosNamingInterceptor::order)); } /** * Get all interceptors. * 获取全部的拦截器 * * @return interceptors list */ protected List&lt;NacosNamingInterceptor&lt;T&gt;&gt; getInterceptors() { return interceptors; } /** * 新增拦截器 * @param interceptor interceptor */ @Override public void addInterceptor(NacosNamingInterceptor&lt;T&gt; interceptor) { interceptors.add(interceptor); interceptors.sort(Comparator.comparingInt(NacosNamingInterceptor::order)); } /** * 执行拦截器 * @param object be interceptor object */ @Override public void doInterceptor(T object) { // 因为内部的拦截器已经排序过了，所以直接遍历 for (NacosNamingInterceptor&lt;T&gt; each : interceptors) { // 若当前拦截的对象不是当前拦截器所要处理的类型则调过 if (!each.isInterceptType(object.getClass())) { continue; } // 执行拦截操作成功之后，继续执行拦截后操作 if (each.intercept(object)) { object.afterIntercept(); return; } } // 未拦截的操作 object.passIntercept(); }} 至此总结下拦截链的工作逻辑： ​ AbstractNamingInterceptorChain可以通过SPI机制或手动的方式添加具体的拦截器，然后调用AbstractNamingInterceptorChain.doInterceptor()方法并且传入Interceptable，拦截链则对传入Interceptable执行拦截。 当拦截成功则调用com.alibaba.nacos.naming.interceptor.Interceptable#afterIntercept 当未被拦截则调用com.alibaba.nacos.naming.interceptor.Interceptable#passIntercept 具体的业务逻辑则在afterIntercept和passIntercept方法中。 初始化流程12345678910public void init() { // 临时实例检查客户端的心跳 if (ephemeral) { beatCheckTask = new ClientBeatCheckTaskV2(this); HealthCheckReactor.scheduleCheck(beatCheckTask); } else { // 持久实例 healthCheckTaskV2 = new HealthCheckTaskV2(this); HealthCheckReactor.scheduleCheck(healthCheckTaskV2); }} 健康检查整体类图 在Nacos中，Task一共有多种类别，例如： NacosTask HealthCheckTask NacosHealthCheckTask BeatCheckTask … 在Nacos中一切操作皆为Task，他们都是Runnable的实现，可以传递给线程池执行，这也是高性能的一种有效方式。 NacosHealthCheckTask12345678910111213141516171819202122/** * Nacos health check task. * Nacos健康检查任务 * * @author xiweng.yy */public interface NacosHealthCheckTask extends Interceptable, Runnable { /** * Get task id. * 获取任务ID * * @return task id. */ String getTaskId(); /** * Do health check. * 去执行健康检查 */ void doHealthCheck();} 负责执行健康检查的任务是的核心基类是NacosHealthCheckTask。 继承Interceptable表示NacosHealthCheckTask的实现是拦截链可以处理的对象 继承Runnable表示NacosHealthCheckTask的实现可以作为Runnable的实现传递给线程池进行执行 NacosHealthCheckTask分别有两种具体实现： ClientBeatCheckTaskV2：处理心跳相关的逻辑 HealthCheckTaskV2：处理各种连接状态 ClientBeatCheckTaskV2ClientBeatCheckTaskV2负责处理心跳相关的逻辑。 1 HealthCheckTaskV2Nacos配置中心原理将K8s中的configMap同步到Nacos的配置中心背景社区规划将nacos做成k8s的数据管控中心。 将k8s中的configMap同步到Nacos的配置中间，是社区规划的重要一步。 拉取k8s数据的方式TODO nacos中存储configMap的方式 简单的存储展示 提供一个基于内存的存储方式 基于内存要考虑Server端数据的一致性 提供持久化的存储方式 建立新的表进行存储 服用 sdk中需要注入configMap的信息 附录Nacos的事件机制Nacos的服务注册和服务变更以及配置变更等等功能都是通过事件来进行通知的，理解Nacos的事件机制可以对Nacos的业务流程有更加深入的理解。 事件事件的抽象定义1234567891011121314151617181920212223242526272829public abstract class Event implements Serializable { private static final long serialVersionUID = -3731383194964997493L; private static final AtomicLong SEQUENCE = new AtomicLong(0); private final long sequence = SEQUENCE.getAndIncrement(); /** * 事件的序号，用于判断事件的顺序 */ public long sequence() { return sequence; } /** * 事件的作用域 */ public String scope() { return null; } /** * 是否为插件的事件 */ public boolean isPluginEvent() { return false; }} 慢事件的定义继承于Event，由于所有的事件的发布都共享一个队列，所以命名为慢事件。 1234567public abstract class SlowEvent extends Event { @Override public long sequence() { return 0; }} 订阅者单事件订阅者多事件订阅者1、集群名称在Nacos中，支持集群配置，集群是对指定微服务的一种虚拟分类，从而实现异地多活，就近调用。 在配置信息中指定集群名称，如下： 123456spring: cloud: nacos: discovery: # 北京机房集群，如不进行指定，则使用默认集群名称 cluster-name: BJ 2、标记服务下线","link":"/2022/09/18/2022-09-18_Nacos%E6%BA%90%E7%A0%81%E7%9B%B8%E5%85%B3/"},{"title":"2023年新的开始","text":"元旦快乐~ 随笔记 2023年新年快乐!新的一年来了，虽说心里终究放不下，但是人总要往前走，对吗？ 即使年年不见，也要岁岁平安。","link":"/2023/01/01/2023-01-01_2023%E5%B9%B4%E6%96%B0%E7%9A%84%E5%BC%80%E5%A7%8B/"},{"title":"CentOS 7设置静态IP","text":"CentOS 7设置静态IP操作记录 修改/etc/sysconfig/network-scripts/ifcfg-ens33文件，参考如下: 12345678910111213141516171819TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=static # 设置静态IP策略DEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33UUID=721209c9-b80e-4840-acaf-1be104332321DEVICE=ens33ONBOOT=yes # 激活网卡IPADDR=192.168.0.211 # 设置静态IPGATEWAY=192.168.0.1 # 设置网关DNS1=8.8.8.8 # 设置DNSNETMASK=255.255.255.0 # 设置zi","link":"/2023/01/03/2023-01-03_CentOS%207%E8%AE%BE%E7%BD%AE%E9%9D%99%E6%80%81IP/"},{"title":"新的一年新的里程","text":"… 跑步记录… 2023年开始了，我翻了翻Keep的跑步记录，发现我已经不知不觉跑了一整年，跑量也到了600公里，对于喜欢的事情，希望自己能够继续坚持下去。 共勉~~~","link":"/2023/01/01/2023-01-01_%E6%96%B0%E7%9A%84%E4%B8%80%E5%B9%B4%E6%96%B0%E7%9A%84%E9%87%8C%E7%A8%8B/"},{"title":"JVM垃圾回收详解","text":"JVM垃圾回收笔记 内存分配和回收原则对象优先在 Eden 区分配大多数情况下，对象在新生代中 Eden 区分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC。GC 期间虚拟机如果发现Survivor 空间也不足，所以只好通过 分配担保机制 把新生代的对象提前转移到老年代中去，老年代上的空间足够的话，所以不会出现 Full GC。执行 Minor GC 后，后面分配的对象如果能够存在 Eden 区的话，还是会在 Eden 区分配内存。","link":"/2023/01/29/2022-02-01_JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E8%AF%A6%E8%A7%A3/"},{"title":"Kubernetes ConfigMap与Nacos同步的初版方案","text":"关于Kubernetes ConfigMap与Nacos同步的初版方案的设计 背景Nacos配置中心正在和K8S的ConfigMap打通，未来需要实现对于K8S数据的管控、审批、变更通知功能。 社区Issue支持从K8S的ConfigMap中，实时同步配置数据到Nacos的配置中心 同步方式方案选择——两种方案对比同步任务放到Nacos主进程中在Nacos主模块中新增两个事件监听器: 第一个：当有配置变更事件时，触发一个通知，发布至K8S的ConfigMap； 第二个：监听K8S的配置变化事件，有变化时发布至Nacos的配置中心。 发起数据变更 定期对账 单独开启一个进程负责同步任务 单独进程负责监听K8S侧的数据，并发布到Nacos的配置中心中； 监听Nacos的配置变化事件，有变化时发布到K8S上。 发起数据变更 定期对账 两种方案对比 方式\\比较点 用户使用成本 后期接入配置变更审批功能 社区关注程度 Nacos更加臃肿 Nacos主进程中 一键部署 方便，直接集成在nacos的主进程控制台中 用户会看到Nacos主进程中出现了K8S模块，运营宣传成本低 单独进程负责同步 还需要再nacos-sync的那个管控界面加入审批功能 如果新增一个项目在nacos-group下，绝大多数开源用户不会关注，需要额外投入运营成本 下述描述的是第一种同步方式的实现方案。 哪台节点负责这项监听+写入的工作？——三种写入方式对比Nacos是以集群部署的，需要明确监听K8S侧数据+拉取+写入DB是哪台节点的责任。以下提供三种划分责任节点的方式。 方式一：选择一台机器来监听K8S侧，并写入DB 对所有健康节点的address进行排序，排名第一的节点负责去监听、并同步ConfigMap数据，写入DB； 当发生节点列表变更（MembersChangeEvent事件）时，重新排序。 优点：省性能。缺点： 如果每台机器上的机器列表排序不一致，则会出现责任节点不明确的问题；需要额外限定一种统一的排序方式； 如果发生某台节点的频繁上下线，会发生责任节点的频繁转移。 方式二：冗余写入–每台Nacos机器都负责监听K8S侧+写入DB该方式认为：监听ConfigMap是每一台机器的责任，当ConfigMap上的数据发生变化的时候，每一台机器都要去同步一遍。 优点：能够保证监听任务的冗余备份，一台挂掉，其他机器还可以工作，且没有某台机器频繁上下线引入的责任变更问题。 方式三：用DistroMapper来划分写入范围，每台节点负责一部分配置 缺点：Config复用了Distro的代码，依赖关系会变复杂。 ConfigMap到Nacos的数据结构映射关系从kubernetes-&gt;nacos中的configMap同步，两者相关字段的映射关系如下： nacos字段 值 data_id ${kubernetes.configMap.metadata.name} group_id K8S_GROUP centent ${kubernetes.configMap完整yaml} md5 自动生成 gmt_create 当前时间 gmt_modified 当前时间 src_user nacos src_ip ${kubernetes api server ip} tenant_id ${kubernetes.configMap.metadata.namespace} type yaml 开关设计 系统属性-总开关：nacos.k8s.configMap.enable为true，默认为false 系统属性-是否责任节点：当前节点如果被选择为负责kubernetes-&gt;nacos的configMap的同步节点，则写入一个nacos.k8s.configMap.responsible=true的环境变量 K8S侧配置：K8S是否允许该Pod拉取的相关配置 当三个开关条件都能满足时，则运行kubernetes-&gt;nacos的configMap数据同步。 数据流转的流程图 初始化Config Map流程（1-2） Nacos调用kubernetes Java Client的List&amp;Watch对应的方法 获取到ConfigMap数据调用PersistService持久化ConfigMap数据 实时同步Config Map流程（3-4） 此时Nacos已经Watch ConfigMap 当发生ConfigMap相关的变化时，回调ResourceEventHandlerImpl中对应的方法 然后调用PersistService持久化ConfigMap 简单代码实现config模块新建com.alibaba.nacos.config.server.service.kubernetes包，新建KubernetesConfigMapSyncService类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283@Componentpublic class KubernetesConfigMapSyncService { private PersistService persistService; private ApiClient apiClient; private boolean isRunning; public KubernetesConfigMapSyncService(PersistService persistService) { this.persistService = persistService; boolean enable = Boolean.parseBoolean(System.getProperty(&quot;nacos.k8s.configMap.enable&quot;)); // If sync is turned on, continue execution. if (!enable) { // print log return; } // Calculate whether you are responsible. enable = true; // If the current node is responsible, it will continue to execute. if (!enable){ // print log return; } try { this.apiClient = ClientBuilder.cluster().build(); } catch (IOException e) { // print log isRunning = false; } if (enable){ watchConfigMap(); isRunning = true; } } private void watchConfigMap() { SharedInformerFactory factory = new SharedInformerFactory(apiClient); CoreV1Api coreV1Api = new CoreV1Api(); SharedIndexInformer&lt;V1ConfigMap&gt; nodeInformer = factory.sharedIndexInformerFor( (CallGeneratorParams params) -&gt; { // **NOTE**: // The following &quot;CallGeneratorParams&quot; lambda merely generates a stateless // HTTPs requests, the effective apiClient is the one specified when constructing // the informer-factory. return coreV1Api.listConfigMapForAllNamespacesCall(true, null, null, null, null, null, null, null, params.timeoutSeconds, params.watch, null); }, V1ConfigMap.class, V1ConfigMapList.class); nodeInformer.addEventHandler(new ResourceEventHandler&lt;V1ConfigMap&gt;() { @Override public void onAdd(V1ConfigMap obj) { // print log persistService.addConfigInfo4(...); } @Override public void onUpdate(V1ConfigMap oldObj, V1ConfigMap newObj) { // print log String content = convertToYaml(newObj); persistService.updateConfigInfo4(...); // todo 修改 } @Override public void onDelete(V1ConfigMap obj, boolean deletedFinalStateUnknown) { // print log persistService.removeConfigInfo(...); } private String convertToYaml(Object kubernetesResource){ return Yaml.dump(kubernetesResource); } }); // Synchronize initialization data to config } public boolean isRunning() { return isRunning; }}","link":"/2023/01/02/2023-01-02_Kubernetes%20ConfigMap%E4%B8%8ENacos%E5%90%8C%E6%AD%A5%E7%9A%84%E5%88%9D%E7%89%88%E6%96%B9%E6%A1%88/"},{"title":"证书","text":"证书相关知识的学习笔记 证书链在Alice和Bob的证书实验中，Alice的证书是采用我们创建的根证书签发的。在实际上真正的证书机构是不会使用根证书来直接签发用户证书的。 因为根证书非常重要，如果根证书的密钥泄露，会影响该根证书签发的所有用户，导致严重的安全风险。 中间证书为了避免上述提到的根证书的安全风险，衍生出中间证书的概念，证书机构采用根证书签发中间证书，然后使用中间证书来签发用户证书。 这样就算中间证书发生泄漏，影响的用户范围也小一些。 因此证书分为三种： 根证书 中间证书 用户证书 证书链上述说到证书分为三种，其中中间证书可以有多层，这样的证书的层级结构叫做证书链。 证书链的工作流程生成流程 证书机构生成自签名根证书 证书机构采用根证书的私钥对中间证书进行签名 证书机构使用中间证书对应的私钥签名用户证书 用户采用用户证书对应的私钥签名用户数据 证书使用和验证流程 采用中间证书的公钥验证用户证书的签名 采用根证书公钥验证中间证书的签名 采用用户证书的公钥来验证数据中的签名 证书链中证书关系如图所示，每一个下级证书中都有它上级证书的DN（Distinguished Name），在进行验证时每一级都会通过该DN找到上级证书，并使用上级证书中的Public key来验证本机证书的签名，如果有多个中间层级，则会重复该过程直到根证书，由于根证书已经内置在系统内部，属于系统信任的证书，所以验证到根证书时表示验证完成，这样就形成了一条从上到下的链状信任关系。 实践下面我们通过openssl来实践一个三层的证书链。 生成根证书和对应的密钥 123456789101112131415161718# openssl req -newkey rsa:2048 -nodes -keyout rootCA.key -x509 -days 365 -out rootCA.crtGenerating a 2048 bit RSA private key..................................+++..............................................................................+++writing new private key to 'rootCA.key'-----You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:HunanLocality Name (eg, city) [Default City]:ChangshaOrganization Name (eg, company) [Default Company Ltd]:Test ROO^C 生成中间证书的私钥和CSR(Certificate Signing Request) 123456789101112131415161718192021222324252627282930313233343536373839404142434445# openssl req -newkey rsa:2048 -nodes -keyout rootCA.key -x509 -days 365 -out rootCA.crtGenerating a 2048 bit RSA private key.................+++.................................+++writing new private key to 'rootCA.key'-----You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:HunanLocality Name (eg, city) [Default City]:ChangshaOrganization Name (eg, company) [Default Company Ltd]:Test root CAOrganizational Unit Name (eg, section) []:Common Name (eg, your name or your server's hostname) []:Test Root CAEmail Address []:670569467@qq.com# openssl req -new -nodes -keyout intermediate.key -out intermediate.csrGenerating a 2048 bit RSA private key..........................................................................+++.............................................+++writing new private key to 'intermediate.key'-----You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:HunanLocality Name (eg, city) [Default City]:ChangshaOrganization Name (eg, company) [Default Company Ltd]:Test Intermediate CAOrganizational Unit Name (eg, section) []:Common Name (eg, your name or your server's hostname) []:Test Intermediate CAEmail Address []:670569467@qq.comPlease enter the following 'extra' attributesto be sent with your certificate requestA challenge password []:An optional company name []: 中间证书需要在证书的basicConstraints中设置CA:true标签，以标明该证书属于证书机构的证书，可以用于签发和验证用户证书。而openssl x509命令不能设置basicConstraints命令，因此我们需要采用openssl ca命令，该命令实现了一个简单的证书机构。 123456789101112131415161718192021222324252627[ ca ]default_ca = intermediate_ca[ intermediate_ca ]dir = .private_key = $dir/rootCA.keycertificate = $dir/rootCA.crtnew_certs_dir = $dir/serial = $dir/crt.srldatabase = $dir/db/indexdefault_md = sha256policy = policy_anyemail_in_dn = no[ policy_any ]domainComponent = optionalcountryName = optionalstateOrProvinceName = optionallocalityName = optionalorganizationName = optionalorganizationalUnitName = optionalcommonName = optionalemailAddress = optional[ ca_ext ]keyUsage = critical,keyCertSign,cRLSign# 注意这里设置了CA:true，表明使用该配置生成的证书是CA证书，可以用于签发用户证书basicConstraints = critical,CA:truesubjectKeyIdentifier = hashauthorityKeyIdentifier = keyid:always 由于openssl ca命令实现了一个简单的证书机构，会使用一个文本数据库来记录生成的证书，我们需要生成该数据库索引文件。 12mkdir dbtouch db/index 使用intermediateCA.conf生成中间证书。 123456789101112131415161718# openssl ca -config intermediateCA.conf -days 365 -create_serial -in intermediate.csr -out intermediate.crt -extensions ca_ext -notextUsing configuration from intermediateCA.confCheck that the request matches the signatureSignature okThe Subject's Distinguished Name is as followscountryName :PRINTABLE:'CN'stateOrProvinceName :ASN.1 12:'Hunan'localityName :ASN.1 12:'Changsha'organizationName :ASN.1 12:'Test Intermediate CA'commonName :ASN.1 12:'Test Intermediate CA'Certificate is to be certified until Oct 1 04:18:27 2023 GMT (365 days)Sign the certificate? [y/n]:y1 out of 1 certificate requests certified, commit? [y/n]yWrite out database with 1 new entriesData Base Updated 生成Alice的私钥和CSR 12345678910111213141516171819202122232425# openssl req -new -nodes -keyout Alice.key -out Alice.csrGenerating a 2048 bit RSA private key..................+++.........................................................+++writing new private key to 'Alice.key'-----You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter '.', the field will be left blank.-----Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:HunanLocality Name (eg, city) [Default City]:ChangshaOrganization Name (eg, company) [Default Company Ltd]:LtdOrganizational Unit Name (eg, section) []:Common Name (eg, your name or your server's hostname) []:AliceEmail Address []:Please enter the following 'extra' attributesto be sent with your certificate requestA challenge password []:An optional company name []: 生成Alice的用户证书。 1234# openssl x509 -req -in Alice.csr -CA intermediate.crt -CAkey intermediate.key -CAcreateserial -out Alice.crtSignature oksubject=/C=CN/ST=Hunan/L=Changsha/O=Ltd/CN=AliceGetting CA Private Key 对Alice的用户证书进行验证，验证时需要同时指明根证书和中间证书。 123# openssl verify -CAfile rootCA.crt -untrusted intermediate.crt Alice.crtAlice.crt: OK 我们可以把根证书和中间证书的内容一起放到一个证书链文件中，然后使用该证书链文件来验证用户证书。 123# cat rootCA.crt intermediate.crt &gt; chain.crt# openssl verify -CAfile chain.crt Alice.crtAlice.crt: OK 在真实场景下，根证书自身就是可信的。我们将根证书导入到操作系统中来模拟该情况。(不同操作系统导入根证书操作不同！) 12#sudo cp rootCA.crt /etc/ca-certificates/trust-source/anchors/#sudo trust extract-compat 然后在openssl命令行中只指明中间证书，就可以验证Alice的用户证书。 12#openssl verify -CAfile intermediate.crt Alice.crtAlice.crt: OK 交叉认证两个CA的根证书所签发的用户证书之间应该怎么实现互信呢？我们来看下图这个例子： 在上图中，CA1和CA2是自签名证书，CA1颁发了User1证书，CA2颁发了User2证书，如何实现User1被CA2信任？ 图中使用CA2-SK对CA1进行重新签名，生成新的证书CA1&quot;。 由于User1用户证书是使用CA1的私钥进行签名，而CA1和CA1&quot;拥有相同公钥，所以CA1&quot;和User1形成互信关系，而CA1&quot;是由CA2颁发的，所以CA1&quot;和CA2也存在互信关系，从而实现User1到CA2的信任。 这样User1就处在了两条合法的证书链上： User 1 Certificate -&gt;CA1 Self-signed Certificate User 1 Certificate -&gt; CA1 Certificate Issued by CA2 -&gt; CA2 Self-signed Certificate 这两条链都是合法的，都可以对User1的证书进行验证。同理，也可以用CA1为CA2签发一个中间证书，使CA2颁发的用户证书也处于两条合法的证书链上。这种方式被称为交叉认证，通过交叉认证，可以为两个CA颁布的证书在两个CA之间建立互信关系。 通过这种方式还可以实现CA的根证书更新，在进行根证书更新时，CA生成一对新的秘钥对和根证书，然后用新的私钥为老的公钥签名生成一个中间证书，并用老的私钥为新的公钥签名生成一个中间证书。这样，无论是新的根证书还是老的根证书颁发的证书在更新期间都可以正常使用，以实现CA新老根证书的平滑过渡。","link":"/2023/01/03/2023-01-03_%E8%AF%81%E4%B9%A6/"},{"title":"通过PID检索对应的容器","text":"通过PID找出对应的容器笔记 通过PID找出对应的容器首先通过pwdx查询pid的工作目录，如果返回/，则代表该进程由容器启动。 再通过 123456789101112$ cat /proc/23325/cgroup11:perf_event:/docker/3991c20d97ed61e63992f1b6b045885ce04d1fbe078d4d8d9cb8010a90bb8a0710:memory:/docker/3991c20d97ed61e63992f1b6b045885ce04d1fbe078d4d8d9cb8010a90bb8a079:hugetlb:/docker/3991c20d97ed61e63992f1b6b045885ce04d1fbe078d4d8d9cb8010a90bb8a078:blkio:/docker/3991c20d97ed61e63992f1b6b045885ce04d1fbe078d4d8d9cb8010a90bb8a077:cpuset:/docker/3991c20d97ed61e63992f1b6b045885ce04d1fbe078d4d8d9cb8010a90bb8a076:net_prio,net_cls:/docker/3991c20d97ed61e63992f1b6b045885ce04d1fbe078d4d8d9cb8010a90bb8a075:freezer:/docker/3991c20d97ed61e63992f1b6b045885ce04d1fbe078d4d8d9cb8010a90bb8a074:devices:/docker/3991c20d97ed61e63992f1b6b045885ce04d1fbe078d4d8d9cb8010a90bb8a073:cpuacct,cpu:/docker/3991c20d97ed61e63992f1b6b045885ce04d1fbe078d4d8d9cb8010a90bb8a072:pids:/docker/3991c20d97ed61e63992f1b6b045885ce04d1fbe078d4d8d9cb8010a90bb8a071:name=systemd:/docker/3991c20d97ed61e63992f1b6b045885ce04d1fbe078d4d8d9cb8010a90bb8a07 取容器ID的前12位，再通过命令 1$ docker ps | grep &lt;containId&gt; 就能找到对应的容器。","link":"/2023/01/03/2023-01-03_%E9%80%9A%E8%BF%87PID%E6%A3%80%E7%B4%A2%E5%AF%B9%E5%BA%94%E7%9A%84%E5%AE%B9%E5%99%A8/"},{"title":"Kubernetes集成NFS","text":"Kubernetes集成NFS学习笔记 NFS介绍NFS是Network File System的缩写，也就是网络文件系统，由Sun公司开发，于1984年向外公布。 它允许网络中的计算机之间共享资源，通过网络可以远程读写NFS服务器上的文件，就像访问本地文件一般。 集成部署NFS服务123456789101112131415161718# 安装$ yum -y install rpcbind nfs-utils# 创建共享目录，并且赋予权限$ mkdir /nfs -p &amp;&amp; chmod -R 777 /nfs# 编辑NFS配置，配置运行访问nfs的网段（这里允许所有IP进行访问）# rw:访问到此目录的服务器都具备读写权限# sync:数据同步写入内存和硬盘# no_all_squash：所有用户对根目录具备完全管理访问权限# no_subtree_check：不检查父目录的权限$ echo &quot;/nfs *(rw,sync,no_all_squash,no_subtree_check)&quot; &gt;&gt; /etc/exports # 载入配置$ exportfs -rv# 启动$ systemctl start rpcbind nfs# 通过showmount命令查看NFS共享情况$ showmount -e 192.168.0.211Export list for 192.168.0.211:/nfs * Node节点安装nfs-utils1$ yum -y install rpcbind nfs-utils Node节点查看NFS的共享情况1234# 通过showmount命令查看NFS共享情况$ showmount -e 192.168.0.211Export list for 192.168.0.211:/nfs * 部署RBAC12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758$ vim rbac.yamlkind: ClusterRoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: nfs-client-provisioner-runnerrules:- apiGroups: [&quot;&quot;] resources: [&quot;persistentvolumes&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;]- apiGroups: [&quot;&quot;] resources: [&quot;persistentvolumeclaims&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;]- apiGroups: [&quot;&quot;] resources: [&quot;endpoints&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]- apiGroups: [&quot;storage.k8s.io&quot;] resources: [&quot;storageclasses&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]- apiGroups: [&quot;&quot;] resources: [&quot;events&quot;] verbs: [&quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]---kind: ClusterRoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: run-nfs-client-provisionersubjects:- kind: ServiceAccount name: nfs-client-provisioner namespace: defaultroleRef: kind: ClusterRole name: nfs-client-provisioner-runner apiGroup: rbac.authorization.k8s.io---kind: RoleapiVersion: rbac.authorization.k8s.io/v1metadata: name: leader-locking-nfs-client-provisionerrules:- apiGroups: [&quot;&quot;] resources: [&quot;endpoints&quot;] verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]---kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1metadata: name: leader-locking-nfs-client-provisionersubjects:- kind: ServiceAccount name: nfs-client-provisioner # replace with namespace where provisioner is deployed namespace: defaultroleRef: kind: Role name: leader-locking-nfs-client-provisioner apiGroup: rbac.authorization.k8s.io$ kubectl create -f rbac.yaml 部署Deployment123456789101112131415161718192021222324252627282930313233343536373839404142$ vim deployment.yamlapiVersion: v1kind: ServiceAccountmetadata: name: nfs-client-provisioner---kind: DeploymentapiVersion: apps/v1metadata: name: nfs-client-provisionerspec: replicas: 1 strategy: type: Recreate selector: matchLabels: app: nfs-client-provisioner template: metadata: labels: app: nfs-client-provisioner spec: serviceAccount: nfs-client-provisioner containers: - name: nfs-client-provisioner image: quay.io/external_storage/nfs-client-provisioner:latest volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: fuseim.pri/ifs - name: NFS_SERVER value: 192.168.0.211 - name: NFS_PATH value: /nfs volumes: - name: nfs-client-root nfs: server: 192.168.0.211 path: /nfs$ kubectl create -f deployment.yaml 部署nfs-client-provisioner并且指定NFS服务器地址，并且绑定NFS路径。 nfs-client-provisioner是一个Kubernetes的简易NFS的外部provisioner，本身不提供NFS，需要现有的NFS服务器提供存储，利用NFS Server给Kubernetes作为持久存储的后端。 部署StorageClass1234567891011$ vim class.yamlapiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: managed-nfs-storageprovisioner: fuseim.pri/ifsparameters: archiveOnDelete: &quot;false&quot;$ kubectl create -f class.yaml# 设置默认的storageClass为managed-nfs-storage$ kubectl patch storageclass managed-nfs-storage -p '{&quot;metadata&quot;: {&quot;annotations&quot;:{&quot;storageclass.kubernetes.io/is-default-class&quot;:&quot;false&quot;}}}' 创建StorageClass绑定NFS存储方式，并且设置此StorageClass为默认。 创建PVC123456789101112$ vim nfs-sc-pvc.yamlapiVersion: v1kind: PersistentVolumeClaimmetadata: name: nfs-sc-pvcspec: storageClassName: managed-nfs-storage # 不指定则使用默认的SC，直接使用 accessModes: - ReadWriteOnce resources: requests: storage: 1Gi PVC直接绑定StorageClass，它会自动创建对应的PV。 创建Pod123456789101112131415161718192021$ vim nfs-sc-pod.yamlkind: PodapiVersion: v1metadata: name: nfs-sc-podspec: containers: - name: test-pod image: nginx ports: - name: web containerPort: 80 volumeMounts: - name: nfs mountPath: &quot;/usr/share/nginx/html&quot; restartPolicy: &quot;Never&quot; volumes: - name: nfs persistentVolumeClaim: claimName: nfs-sc-pvc$ kubectl apply -f nfs-sc-pod.yaml 部署一个运行Nginx容器的Pod，并且暴漏80端口，将nginx的html目录挂载到NFS服务器上。 测试NFS服务器端写入文件1$ echo &quot;hello world&quot; &gt; index.html 访问NFS服务器端写入的html123456$ kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnfs-client-provisioner-74d569d687-wkp88 1/1 Running 0 5h50m 10.244.2.58 k8s-node2 &lt;none&gt; &lt;none&gt;nfs-sc-pod 1/1 Running 0 3m18s 10.244.1.23 k8s-node1 &lt;none&gt; &lt;none&gt;$ curl 10.244.1.23hello world 实验成功~","link":"/2023/01/07/2023-01-07_Kubernetes%E9%9B%86%E6%88%90NFS/"},{"title":"通过命令下载github上面的某一个文件","text":"通过命令下载github上面的某一个文件技术笔记 以部署ingress-nginx为例，deploy.yaml的链接为： https://github.com/kubernetes/ingress-nginx/blob/controller-v1.4.0/deploy/static/provider/cloud/deploy.yaml 我们将github.com替换成raw.githubusercontent.com并且去除blob： https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.4.0/deploy/static/provider/cloud/deploy.yaml 并且执行命令: 1wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.4.0/deploy/static/provider/cloud/deploy.yaml kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.4.0/deploy/static/provider/cloud/deploy.yaml","link":"/2023/01/03/2023-01-03_%E9%80%9A%E8%BF%87%E5%91%BD%E4%BB%A4%E4%B8%8B%E8%BD%BDgithub%E4%B8%8A%E9%9D%A2%E7%9A%84%E6%9F%90%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6/"},{"title":"Nacos支持监听namespace下的所有配置","text":"Nacos支持监听namespace下的所有配置文档 背景现有功能目前最新版本Nacos只能支持监听单个配置，通过namespace、group、dataId唯一确定一个配置文件进行监听。 新特性Nacos需要类型于kubernetes通过namespace监听此namespace下的所有单类资源的功能。也就是说Nacos需要通过namespace监听所有的配置项，当此namespace下的配置项发生变更时，通知SDK。 改造点 实现AbstractListener，定义一个NamespaceConfigChangeListener，用于namespace下的配置发生变化时进行回调。 抽象出AbstractCacheData。 基于AbstractCacheData实现SingleCacheData，单个SingleCacheData对应单个配置文件，作用于单个监听配置文件。 基于AbstractCacheData实现BatchCacheData，单个BatchCacheData对应多个匹配文件，作用于批量监听配置文件。 ConfigService&amp;ClientWorker新增addBatchListener方法，并且NacosConfigService对ConfigService的addBatchListener方法进行实现，然后修改之前所有监听单配置的方式。例如： NacosConfigService#addListener：向ClientWorker#cacheMap新增元素，元素类型为SingleCacheData，然后通知配置监听。 NacosConfigService#addBatchListener：向ClientWorker#cacheMap新增元素，元素类型为BatchCacheData，然后通知配置监听。 单个配置的监听与批量配置的监听都用ConfigBatchListenRequest进行复用。 ConfigBatchListenRequest新增configBatchListenContext用于存储批量监听的上下文。 12345678910111213public class ConfigBatchListenRequest extends AbstractConfigRequest { // 用于单个监听 private List&lt;ConfigListenContext&gt; configListenContexts = new ArrayList&lt;&gt;(); // 用户批量监听 private List&lt;ConfigBatchListenContext&gt; configBatchListenContexts = new ArrayList&lt;&gt;(); // 批量监听上下文 public static class ConfigBatchListenContext { // namespace String tenant; // &lt;groupKey, md5&gt; Map&lt;String,String&gt; md5ByGroupKeyMaps; }} ClientWorker#buildConfigRequest构建request时，对CacheData进行类型判断构建ConfigBatchListenRequest（分别填充configListenContexts和configBatchListenContexts属性）。 ConfigChangeBatchListenRequestHandler#handle分别对ConfigBatchListenRequest#configBatchListenContext与ConfigBatchListenRequest#configListenContexts进行处理。 ConfigChangeListenContext新增tenantIdContext。 1234public class ConfigChangeListenContext { // 存储tenant与connectId的映射，用于配置改变时通知指定sdk private ConcurrentHashMap&lt;String, HashSet&lt;String&gt;&gt; tenantIdContext = new ConcurrentHashMap&lt;&gt;();} ConfigCacheService新增CACHE_BY_TENANT属性，新增batchGetUpdatedDataKey方法。 12345678910public class ConfigCacheService { // 用于存储tenant与CacheItem的映射关系，发布配置时维护进去，后续可以直接通过tenant获取CacheItem private static final ConcurrentHashMap&lt;String, List&lt;CacheItem&gt;&gt; CACHE_BY_TENANT = new ConcurrentHashMap&lt;&gt;(); public static List&lt;String&gt; batchGetUpdatedDataKey(String groupKey, Map&lt;String, String&gt; md5Map) { // 从CACHE_BY_TENANT获取此tenantId对应的CacheItem，并且过滤已经变化的配置，解析成groupKey格式进行返回 return null; } } SDK端处理ConfigBatchListenRequest的响应，获取响应的配置上下文依次进行处理，分别以单个监听配置的响应和批量监听配置的响应依次进行处理。 单个listenConfig的响应： 通过dataId、group、tenant获取最新的配置，更新ClientWork#caheMap 通知listener 批量listenConfig的响应： 通过响应获取最新的配置更新到BatchCacheData中，并且通知NamespacePropertiesListener 改造后业务流程","link":"/2023/01/04/2023-01-04_Nacos%E6%94%AF%E6%8C%81%E7%9B%91%E5%90%ACNamespace%E4%B8%8B%E7%9A%84%E6%89%80%E6%9C%89%E9%85%8D%E7%BD%AE/"},{"title":"JVM的体系结构","text":"JVM学习笔记 JVM介绍JVM（Java Virtual Machine，Java 虚拟机）顾名思义就是用来执行 Java 程序的“虚拟主机”。它实际的工作是将编译生成的.class 文件（字节码）翻译成底层操作系统可以运行的机器码并且进行调用执行，Java虚拟机是一台执行Java字节码的虚拟计算机，它拥有独立的运行机制，其运行的Java字节码也未必由Java语言编译而成，多语言可以共享Java虚拟机带来的跨平台性、优秀的垃圾回器，以及可靠的即时编译器。 JVM有如下特点： 一次编译，到处运行 自动内存管理 自动垃圾回收 JRE&amp;JDK&amp;JVM的关系 JRE：JRE是Java的运行环境，包含了JVM、Java基础类库。是Java程序运行的必要环境。 JDK：JDK是Java开发工具包，提供给专业人员进行使用的，JDK包含JRE，同时包含了编译Java源码的编译器javac，还包含很多程序调试以及分析工具，例如：jconsole、jvisualvm等… 如果你只需要运行Java程序，安装JRE足以，但是如果你想编写Java程序，还是安装JDK更合适。 关于JVM、JRE、JDK的包含关系如下图： 关于JDK的整体图，如下所示： JVM是跨平台的虚拟机 通过这张图，我们可以把JVM理解为一个抽象类，其中他的抽象方法就是通过Java字节码让操作系统执行指定的行为。 简易概括：JVM 上承开发语言，下接操作系统，中间通过Java字节码传输，基于这个抽象类，有多种JVM的具体实现。 通过JVM这层抽象层对不同操作系统的实现，例如Windows版JVM实现，Linux版JVM实现、MAC版JVM实现，从而实现”write once, run anywhere”，所谓的跨平台。 JVM是跨语言的平台 随着Java7的正式发布，Java虚拟机的设计者们通过JSR-292规范基本实现在Java虚拟机平台上运行非Java语言编写的程序。 不同的编译器，通过将不同的语言编译出相同格式的Class字节码，从而让JVM进行解释运行。 Java虚拟机根本不关心运行在其内部的程序到底是使用何种编程语言编写的，它只关心“字节码”文件。也就是说Java虚拟机拥有语言无关性，并不会单纯地与Java语言“终身绑定”，只要其他编程语言的编译结果满足并包含Java虚拟机的内部指令集、符号表以及其他的辅助信息，它就是一个有效的字节码文件，就能够被虚拟机所识别并装载运行。 JVM通过上述几点从而实现跨语言。 JVM的架构模型（感觉这个不适合出现再这里，以后估计要移到合适的位置）Java编译器输入的指令流基本上是一种基于栈的指令集架构，另外一种指令集架构则是基于寄存器的指令集架构。 这两种架构之间的区别： 基于栈式架构的特点 设计和实现更简单，适用于资源受限的系统 避开了寄存器的分配难题：使用零地址指令方式分配 指令流中的指令大部分是零地址指令，其执行过程依赖于操作栈。指令集更小，编译器容易实现 不需要硬件支持，可移植性更好，更好实现跨平台 基于寄存器架构的特点 典型的应用是x86的二进制指令集：比如传统的PC以及Android的Davlik虚拟机 指令集架构则完全依赖硬件，可移植性差 性能优秀和执行更高效 花费更少的指令去完成一项操作 在大部分情况下，基于寄存器架构的指令集往往都以一地址指令、二地址指令和三地址指令为主，而基于栈式架构的指令集却是以零地址指令为主 举例运行程序： 123public static void main(String[] args) throws NacosException { int i = 2 + 3;} 基于栈的计算流程（以Java虚拟机为例） 12345678iconst_2 //常量2入栈istore_1iconst_3 // 常量3入栈istore_2iload_1iload_2iadd //常量2/3出栈，执行相加istore_0 // 结果5入栈 而基于寄存器的计算流程 12mov eax,2 //将eax寄存器的值设为1add eax,3 //使eax寄存器的值加3 总结由于跨平台性的设计，Java的指令都是根据栈来设计的。不同平台CPU架构不同，所以不能设计为基于寄存器的。优点是跨平台，指令集小，编译器容易实现，缺点是性能下降，实现同样的功能需要更多的指令。 JAVA&amp;JVM发展过程 1990年，在Sun计算机公司中，由Patrick Naughton、MikeSheridan及James Gosling领导的小组Green Team，开发出的新的程序语言，命名为oak，后期命名为Java； 1995年，Sun正式发布Java和HotJava产品，Java首次公开亮相； 1996年1月23日，Sun Microsystems发布了JDK 1.0； 1998年，JDK1.2版本发布。同时，sun发布了JSP/Servlet、EJB规范，以及将Java分成了J2EE、J2SE和J2ME。这表明了Java开始向企业、桌面应用和移动设备应用3大领域挺进； 2000年，JDK1.3发布，Java HotSpot Virtual Machine正式发布，成为Java的默认虚拟机； 2002年，JDK1.4发布，古老的Classic虚拟机退出历史舞台； 2003年年底，Java平台的Scala正式发布，同年Groovy也加入了Java阵营； 2004年，JDK1.5发布。同时JDK1.5改名为JavaSE5.0； 2006年，JDK6发布。同年，Java开源并建立了OpenJDK。顺理成章，Hotspot虚拟机也成为了openJDK中的默认虚拟机； 2007年，Java平台迎来了新伙伴Clojure； 2008年，Oracle收购了BEA，得到了JRockit虚拟机； 2009年，Twitter宣布把后台大部分程序从Ruby迁移到Scala，这是Java平台的又一次大规模应用； 2010年，Oracle收购了Sun，获得Java商标和最真价值的HotSpot虚拟机。此时，Oracle拥有市场占用率最高的两款虚拟机HotSpot和JRockit，并计划在未来对它们进行整合：HotRockit； 2011年，JDK7发布。在JDK1.7u4中，正式启用了新的垃圾回收器G1； 2017年，JDK9发布。将G1设置为默认Gc，替代CMS； 同年，IBM的J9开源，形成了现在的Open J9社区； 2018年，Android的Java侵权案判决，Google赔偿Oracle计88亿美元； 同年，Oracle宣告JavaEE成为历史名词JDBC、JMS、Servlet赠予Eclipse基金会； 同年，JDK11发布，LTS版本的JDK，发布革命性的ZGC，调整JDK授权许可； 2019年，JDK12发布，加入RedHat领导开发的shenandoah GC； JVM目前状况Java现在已经是应用最为广泛的软件开发平台之一。随着Java以及Java社区的不断壮大Java 也早已不再是简简单单的一门计算机语言了，它更是一个平台、一种文化、一个社区。 作为一个平台，Java虚拟机扮演着举足轻重的作用 Groovy、Scala、JRuby、Kotlin等都是Java平台的一部分 作为一种文化，Java几乎成为了“开源”的代名词。 第三方开源软件和框架。如Tomcat、Struts，MyBatis，Spring等。 就连JDK和JVM自身也有不少开源的实现，如OpenJDK、Harmony。 作为一个社区，Java拥有全世界最多的技术拥护者和开源社区支持，有数不清的论坛和资料。从桌面应用软件、嵌入式开发到企业级应用、后台服务器、中间件，都可以看到Java的身影。其应用形式之复杂、参与人数之众多也令人咋舌。 JVM多语言混合编程的发展趋势 Java平台上的多语言混合编程正成为主流，通过特定领域的语言去解决特定领域的问题是当前软件开发应对日趋复杂的项目需求的一个方向。 试想一下，在一个项目之中，并行处理用Clojure语言编写，展示层使用JRuby/Rails，中间层则是Java，每个应用层都将使用不同的编程语言来完成，而且，接口对每一层的开发者都是透明的，各种语言之间的交互不存在任何困难，就像使用自己语言的原生API一样方便，因为它们最终都运行在一个虚拟机之上。 对这些运行于Java虚拟机之上、Java之外的语言，来自系统级的、底层的支持正在迅速增强，以JSR-292为核心的一系列项目和功能改进（如Da Vinci Machine项目、Nashorn引擎、InvokeDynamic指令、java.lang.invoke包等），推动Java虚拟机从“Java语言的虚拟机”向 “多语言虚拟机”的方向发展。 JVM相关参考读物官网JVM虚拟机规范 《深入理解JVM虚拟机》 《自己动手写Java虚拟机》 参考B站视频 博客 JVM–理解介绍","link":"/2023/01/15/2023-01-15_JVM%E7%9A%84%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"},{"title":"JVM的内存区域详解","text":"JVM的内存区域笔记 前言对于Java程序员来说，在虚拟机自动内存管理机制下，不需要像C/C++程序员为每一个new的操作去写对应的delete/free操作，不容易出现内存泄漏和内存溢出问题，正是因为Java程序员把内存控制权交给JVM，一旦出现内存泄漏和内存溢出等问题，如果不熟悉JVM，那么排查将是一个艰巨的任务。 运行时数据区域Java 虚拟机在执行 Java 程序的过程中会把它管理的内存划分成若干个不同的数据区域。JDK 1.8之后 和之前的版本略有不同。 程序计数器程序计数器是一块很小的内存空间，我们可以把它看作当前线程所执行的字节码指令的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转等功能都需要依赖这个计数器来完成。 另外，为了线程切换后能恢复到正确的执行位置，每条线程都拥有一个独立的程序计数器，各线程之间互不影响，独立存储，我们称这类内存区域为”线程私有“的内存。 从上述文字中，我们可以得知： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来时，就能知道当前线程执行的位置。 注意：程序计数器是唯一一个不会出现OutOfMemoryError的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。 虚拟机栈与程序计数器一样，Java虚拟机栈也是线程私有的，它的生命周期和线程相同。 栈是JVM运行时数据区域的一个核心区域，除了Native方法调用是通过本地方法栈实现的，其他所有的方法调用都是通过JVM虚拟机栈进行实现的。 栈由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法返回地址。 局部变量表： 局部变量表用于存放方法参数和方法内部定义的局部变量。 每个局部变量槽可以保存一个数据类型，例如整数、浮点数、引用等。 它的最大容量在编译时确定。 操作数栈： 操作数栈是一个后入先出（LIFO）的栈结构。 主要作为方法调用的中转站，用于存放方法执行过程中产生的中间变量。 动态链接： 每个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用。 这个引用的目的是为了支持当前方法的代码能够实现动态链接。 举个例子，当一个方法调用了另外的其他方法时，通过常量池中指向方法的符号引用来表示，动态链接的作用就是将这些符号引用转换为调用方法的直接引用。 方法返回地址： 方法返回地址用于恢复调用当前方法的方法的执行状态。 当方法正常退出时，返回给方法调用者的返回地址。 当方法异常退出时，由异常处理器表确定的返回地址。 总之，栈帧是虚拟机运行时数据区中虚拟机栈的栈元素，存储了方法的局部变量表、操作数栈、动态链接和方法返回地址等信息。每个方法从调用到执行完成都对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 动态链接是一个在编程语言和虚拟机中的概念，让我用更简单的方式来解释一下。 符号引用： 当我们在代码中调用一个方法时，我们使用的是方法的名称（例如，myMethod()）。 这个方法名称在编译时被称为符号引用。它只是一个标识符，不包含实际的方法地址。 直接引用： 在程序运行时，虚拟机需要将这个符号引用转换为实际的方法地址，以便执行方法。 这个实际的方法地址被称为直接引用。 这个转换过程就是动态链接。 动态链接的作用： 当我们调用一个方法时，虚拟机会在运行时查找该方法的实际地址。 它会根据符号引用中的信息，找到对应的类、方法名、参数类型等。 然后，它将符号引用转换为直接引用，以便正确地执行方法。 举个例子，假设我们有一个类 MyClass，其中有一个方法 myMethod()。在代码中，我们写下了 MyClass.myMethod() 来调用这个方法。在编译时，这个调用被表示为符号引用。但是在运行时，虚拟机会查找 MyClass 类，找到 myMethod() 的实际地址，然后执行它。 总之，动态链接的目的是在运行时将符号引用转换为实际的方法地址，以支持方法调用过程中的动态连接。 本地方法栈本地方法栈的作用和虚拟机栈的作用类似，唯一的区别就是虚拟机栈作用于Java方法，而本地方法栈作用于Native方法。它同样也会发生OutOfMemoryError和StackOverFlowError。 但是注意其实&lt;&lt;JVM虚拟机规范&gt;&gt;对本地方法的实现并没有强制的规定，甚至HotSpot VM直接将本地方法栈和虚拟机栈合二为一。 堆堆是用于存储对象的一块内存区域，几乎所有的对象和数组都在堆上面进行分配。 有一种特殊情况，即逃逸分析技术，它可以影响对象的分配位置。 逃逸分析： 逃逸分析是一种优化技术，用于确定对象的生命周期是否逃逸出方法。 如果经过逃逸分析后发现，一个对象并没有逃逸出方法，那么就可能被优化成在栈上分配。 栈上分配意味着对象不在堆上分配内存，而是直接在线程的栈空间上分配。 栈上分配： 当对象不逃逸出方法时，虚拟机可以将其分配到栈上。 这样无需在堆上分配内存，也无须进行垃圾回收。 栈上分配通常发生在局部变量、临时对象等情况下。 总之，虽然大部分对象仍在堆中分配，但逃逸分析技术使得一些对象可以在栈上分配，从而提高了性能和资源利用率。 方法区方法区与堆一样是各个线程共享的内存区域，主要用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译后的代码缓存等数据。虽然&lt;&lt;JVM虚拟机规范&gt;&gt;中把方法区描述为一个堆的一个逻辑部分，但是它还有一个别名叫做”非堆”，目的就是与堆区分开。 在 JDK 6 时，HotSpot 开发团队就开始考虑放弃永久代，逐步改为使用本地内存来实现方法区。到了JDK 7的 HotSpot，已经将原本放在永久代的字符串常量池、静态变量等移到堆中。而在 JDK 8 中，终于完全废弃了永久代的概念，改用元空间来代替。元空间将JDK 7中永久代剩余的内容（主要是类型信息）全部移到本地内存中。 永久代和元空间： 永久代和元空间都是 HotSpot 虚拟机对《Java 虚拟机规范》中方法区的实现。 在JDK 1.8之前，HotSpot 使用永久代来实现方法区，但这样会导致 JVM 调优比较困难，且容易发生 OutOfMemoryError（OOM）的问题。(不好估算方法区所需要的大小) JDK 1.8 及之后，使用的是元空间存放在本地内存中的方式来替代永久代，降低了 OOM 发生的可能性。 运行时常量池当Class文件编译后，Class文件中将会存在常量池，这部分内容将会在类加载完成时转化为运行时常量池。 在JDK 7中将原本在永久代的运行时常量池移到堆中。 运行时常量池是 JVM 中的一块内存区域，用于存储类文件中的常量数据以及符号引用。 在编译阶段，Java 类文件中的常量将会被分析和存储到运行时常量池中。 运行时常量池可以看作是一张表，在程序运行时通过常量的索引值直接或间接地引用这些常量。 运行时常量池相对于类文件常量池的另一个重要特征是具备动态性。Java 语言并不要求常量一定只有在编译期才能产生。也就是说，并非预置在类文件中常量池的内容才能进入方法区的运行时常量池。在运行期间，我们也可以将新的常量放入池中。这种特性被开发人员广泛利用，其中一个常见的例子就是 String 类的 intern() 方法。 String 类的 intern() 方法 intern() 方法用于将字符串添加到运行时常量池中。 如果字符串常量池中已经存在相同内容的字符串，intern() 方法会返回对已有字符串的引用。 如果字符串常量池中不存在相同内容的字符串，intern() 方法会将该字符串添加到常量池并返回对它的引用。 直接内存直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是《Java虚拟机规范》中定义的内存区域。但是这部分内存也被频繁地使用，而且也可能导致 OutOfMemoryError 异常出现，所以我们放到这里一起讲解。 在 JDK 1.4 中新加入了 NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的 I/O 方式，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆里面的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆中来回复制数据。 显然，本机直接内存的分配不会受到 Java 堆大小的限制，但是，既然是内存，则肯定还是会受到本机总内存（包括物理内存、SWAP 分区或者分页文件）大小以及处理器寻址空间的限制。一般服务器管理员配置虚拟机参数时，会根据实际内存去设置 -Xmx 等参数信息，但经常忽略掉直接内存，使得各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制），从而导致动态扩展时出现 OutOfMemoryError 异常。 Java堆TODO 方法区方法区是各个线程共享的内存区域，用于存储被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。 虽然&lt;&lt;Java虚拟机规范&gt;&gt;中把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做”非堆”，目的就是与Java堆区分开来。 说到方法区，必须得提一下“永久代”这个概念，在JDK1.8之前，许多Java程序员更愿意把方法区叫做”永久代“，本质上这两者不是一个概念，只是说当时HotSpot采用永久代实现了方法区而已。 为什么废除永久代？ 主要是需要融合HotSpot VM和JRockit VM。 PermGen很难调整，永久代得回收成绩很难令人满意。 PermGen使用多大得方法区，难以确定。 永久代经常发生内存泄露问题。 运行时常量池运行时常量池时方法区的一部分，Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池表，用于存放编译期生成的各种字面量和符号引用，这部分内容就将放在类加载后存放到方法去的运行时常量池中。 注意Java语言不要求常量只有编译期才能产生，也就是说，在运行期间可以将新的常量放入常量池，例如String类的intern方法。 既然运行时常量池是方法区的一部分，自然也受到方法区内存的限制，当常量池无法再申请到更多的内存时会抛出OutOfMemoryError异常。 直接内存直接内存并不是虚拟机运行时数据区的一部分，也不是&lt;&lt;Java虚拟机规范&gt;&gt;中定义的内存区域。 但是这部分内存也被频繁使用，而且有可能导致OutOfMemoryError异常，所以我们放到这里一起讲解。 再JDK1.4中新加入NIO，引入一种基于Channel与Buffer的IO方式，可以直接使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作，这样能在一些场景中显著的提高性能，。。。 本机内存不会受到堆大小的限制，但是还是会受到本机内存的限制，所以也会导致OutOfMemoryError。 再JDK","link":"/2023/01/16/2023-01-16_JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E8%AF%A6%E8%A7%A3/"},{"title":"JVM的类加载子系统","text":"类加载器类加载器子系统作用 类加载器子系统负责从文件系统或者网络中加载Class文件，class文件在文件开头有特定的文件标识。 ClassLoader只负责class文件的加载，至于它是否可以运行，则由Execution Engine决定。 加载的类信息存放于一块称为方法区的内存空间。除了类的信息外，方法区中还会存放运行时常量池信息，可能还包括字符串字面量和数字常量（这部分常量信息是Class文件中常量池部分的内存映射） ClassLoader角色的作用 Car class file存在于本地硬盘上，可以理解为设计师画在纸上的模板，而最终这个模板在执行的时候是要加载到JVM当中来根据这个文件实例化出n个一模一样的实例。 class file加载到JVM中，被称为DNA元数据模板，放在方法区。 在.class文件-&gt;JVM-&gt;最终成为元数据模板，此过程就要一个运输工具（类装载器Class Loader），扮演一个快递员的角色。 类加载过程注意这里的加载过程是一个宏观上的概念！ 12345public class HelloLoader { public static void main(String[] args) { System.out.println(&quot;Hello World!&quot;); }} 用流程图表示上述示例代码： 类的加载过程加载阶段 通过一个类的全限定名获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口 加载class文件的方式: 从本地系统中直接加载 通过网络获取，典型场景：Web Applet 从zip压缩包中读取，成为日后jar、war格式的基础 运行时计算生成，使用最多的是：动态代理技术 由其他文件生成，典型场景：JSP应用 从专有数据库中提取.class文件，比较少见 从加密文件中获取，典型的防Class文件被反编译的保护措施 链接阶段验证（Verify） 目的确保Class文件的字节流中包含的信息符合当前虚拟机的要求，保证被加载类的正确性，不会危害虚拟机的自身安全 准备（Prepare） 为类变量分配内存并且设置该类变量的默认初始值，即零值。 不包含final修饰的static，因为final在编译期间就分配了，准备阶段会显式初始化。 不会为实例变量分配初始化，类变量会分配在方法区，而实例变量则是分配到堆中。 解析（Resolve） 将常量池内的符号引用转化为直接引用 符号引用：一组符号来描述所引用的目标，符号引用的字面量形式明确定义在《java虚拟机规范》的Class文件格式中。 直接引用：直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 事实上，解析操作往往会伴随着JVM在执行完初始化之后再执行。？ 解析动作主要是针对类或接口、字段、类方法、接口方法、方法类型等。对应常量池中的CONSTANT_Class_info，CONSTANT_Fieldref_info、CONSTANT_Methodref_info等。 初始化阶段 初始化阶段就是执行类构造器方法的过程。 此方法不需定义，是javac编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并而来。 构造器方法中指令按语句在源文件中出现的顺序执行。 若该类具有父类，JVM会保证子类的()执行前，父类的()已经执行完毕。 虚拟机必须保证一个类的()方法在多线程下被同步加锁。 类加载器的分类JVM支持两种类型的类加载器，分别为引导类加载器和自定义加载器。从一般的看法来看，自定义类加载器通常指的是程序中由开发人员自定义的一类类加载器，但是《Java虚拟机规范》中却定义为将所有派生于ClassLoader的类加载器都划分为自定义类加载器。 无论类加载器如何划分，在程序中我们常见的类加载器始终只有三个，如下图所示： 虚拟机自带的类加载器Bootstrap ClassLoader 这个类加载使用C/C++语言实现的，嵌套在JVM内部。 它用来加载Java的核心库（JAVA_HOME/jre/lib/rt.jar、resources.jar或sun.boot.class.path路径下的内容），用于提供JVM自身需要的类。 并不继承自ava.lang.ClassLoader，没有父加载器。 加载扩展类（sun.misc.Launcher$ExtClassLoader）和应用程序类加载器（sun.misc.Launcher$AppClassLoader），并指定为他们的父类加载器。 出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类。 Extension ClassLoader Java语言编写，由sun.misc.Launcher$ExtClassLoader实现。 派生于ClassLoader类。 父类加载器为启动类加载器。 从java.ext.dirs系统属性所指定的目录中加载类库，或从JDK的安装目录的jre/1ib/ext子目录（扩展目录）下加载类库。如果用户创建的JAR放在此目录下，也会自动由扩展类加载器加载。 App ClassLoader java语言编写，由sun.misc.LaunchersAppClassLoader实现。 派生于ClassLoader类。 父类加载器为扩展类加载器。 它负责加载环境变量classpath或系统属性java.class.path指定路径下的类库。 该类加载是程序中默认的类加载器，一般来说，Java应用的类都是由它来完成加载。 通过ClassLoader#getSystemclassLoader() 方法可以获取到该类加载器。 用户自定义类加载器在Java的日常应用程序开发中，类的加载几乎是由上述3种类加载器相互配合执行的，在必要时，我们还可以自定义类加载器，来定制类的加载方式。 自定义类加载器的作用 隔离加载类（例如Tomcat要同时部署多个Web应用程序，例如每个都有com.xxx.User类型，但是他们的具体类型是不一样的，所以Tomcat要对它进行隔离，能够加载多个User对象。） 修改类加载的方式 扩展加载源 防止源码泄漏（用于字节码文件进行加密的场景） 用户自定义加载器的步骤 开发人员可以通过继承抽象类ava.lang.ClassLoader类的方式，实现自己的类加载器，以满足一些特殊的需求 在JDK1.2之前，在自定义类加载器时，总会去继承ClassLoader类并重写loadClass() 方法，从而实现自定义的类加载类，但是在JDK1.2之后已不再建议用户去覆盖loadclass() 方法，而是建议把自定义的类加载逻辑写在findClass()方法中。 在编写自定义类加载器时，如果没有太过于复杂的需求，可以直接继承URLClassLoader类，这样就可以避免自己去编写findClass() 方法及其获取字节码流的方式，使自定义类加载器编写更加简洁。 ClassLoader使用说明对于ClassLoader的相关API，可以通过Oracle官方API文档进行了解。 sun.misc.Launcher 它是一个Java虚拟机的入口应用。ExtClassLoader和AppClassLoader都定义在Launcher中。 相关ClassLoader的继承结构如图所示： 相关验证Demo对上述三种ClassLoader进行相关的验证。源码链接 具体实现如下图所示： 123456789101112131415161718192021222324252627282930public class ClassLoaderTest01 { public static void main(String[] args) { // 获取系统类加载器 ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader(); // 输出sun.misc.Launcher$AppClassLoader@18b4aac2 System.out.println(systemClassLoader); // 通过系统类加载器获取它上层的扩展类加载器 ClassLoader extClassLoader = systemClassLoader.getParent(); // 输出sun.misc.Launcher$ExtClassLoader@4554617c System.out.println(extClassLoader); // 获取扩展类加载器的上层启动类加载器，由输出可知启动类加载器获取不到，所以输出为null ClassLoader boostrapClassLoader = extClassLoader.getParent(); // 输出null System.out.println(boostrapClassLoader); // 对于用户自定义类的类加载器，从输出结果得知使用系统默认的AppClassLoader进行加载 ClassLoader classLoader = ClassLoaderTest01.class.getClassLoader(); // 输出sun.misc.Launcher$AppClassLoader@18b4aac2 System.out.println(classLoader); // 由输出为null得知，String类使BootstrapClassLoader进行加载 ClassLoader stringClassLoader = String.class.getClassLoader(); // 输出null System.out.println(stringClassLoader); }} 对系统的默认类加载器是AppClassLoader进行验证 验证三种ClassLoader的结构 123456789101112131415161718192021222324public class ClassLoaderTest02 { public static void main(String[] args) { System.out.println(&quot;打印BootstrapClassLoader加载的路径：&quot;); URL[] urLs = Launcher.getBootstrapClassPath().getURLs(); for (URL urL : urLs) { System.out.println(urL.toExternalForm()); } // 从上述路径中随意找一个Class获取它的类加载器，看是否符合我们的猜想。 ClassLoader bootstrapClassLoader = Provider.class.getClassLoader(); // 从输出结果得知，Provider的类加载器为BootstrapClassLoader System.out.println(bootstrapClassLoader); System.out.println(&quot;打印ExtClassLoader加载的路径：&quot;); String extDirs = System.getProperty(&quot;java.ext.dirs&quot;); for (String path : extDirs.split(&quot;;&quot;)) { System.out.println(path); } // 从上述路径中随意找一个Class获取它的类加载器，看是否符合我们的猜想。 ClassLoader extClassLoader = CurveDB.class.getClassLoader(); // 从输出结果得知，符合我们的验证 System.out.println(extClassLoader); } } 验证BootstrapClassLoader加载的Class 验证ExtClassLoaderr加载的类 双亲委派机制JVM加载Class的模式是按需加载，也是就是当JVM要使用到这个类的时候，才会对他进行加载，而且加载某个类时会采用双亲委派机制。 双亲委派机制的工作原理 如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行； 如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器； 如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式 双亲委派机制工作流程如下图所示： 举例说明： 首先通过bootstrap loader加载rt.jar中的spi接口，然后spi接口调用具体实现类的方法，再通过上下文加载器(默认为AppClassLoader)加载具体的第三方Class（jdbc.jar）。 双亲委派机制的优点 避免类的重复加载 保护程序安全，防止核心API被篡改（例如JVM自带的API，不能被自定义的类进行覆盖） 如何判断两个Class是否相同在JVM中判断两个Class相同时，必须满足以下条件： 全限类名相同 这两个类的Classloader必须一致 对类加载器的引用JVM必须知道一个类型是由启动加载器加载的还是由用户类加载器加载的（使用用户自定义的类加载器加载的类，会将类信息保存在方法区，方法区还记录了当前类使用的Classloader，启动类加载器本身就是null，所以就不需要进行记录了）。如果一个类型是由用户类加载器加载的，那么JVM会将这个类加载器的一个引用作为类型信息的一部分保存在方法区中。当解析一个类型到另一个类型的引用的时候，JVM需要保证这两个类型的类加载器是相同的（TODO 这里不是很懂）。 类的主动使用和被动使用(TODO 这里不是很懂)Java程序对类的使用方式分为：主动使用和被动使用。主动使用，又分为七种情况： 创建类的实例 访问某个类或接口的静态变量，或者对该静态变量赋值 调用类的静态方法 反射（比如：Class.forName（”com.atguigu.Test”）） 初始化一个类的子类 Java虚拟机启动时被标明为启动类的类 JDK 7 开始提供的动态语言支持：java.lang.invoke.MethodHandle实例的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic句柄对应的类没有初始化，则初始化 除了以上七种情况，其他使用Java类的方式都被看作是对类的被动使用，都不会导致类的初始化。 其他工具IDEA字节码学习查看神器jclasslib bytecode viewer介绍 Oracle JDK8 API官方文档","link":"/2023/01/17/2023-01-17_JVM%E7%9A%84%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E5%AD%90%E7%B3%BB%E7%BB%9F/"},{"title":"分布式事务解决方案之Seata","text":"Seata学习笔记 SeataSeata是什么？Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。 Seata中的三种角色TC - 事务协调者维护全局和分支事务的状态，驱动全局事务提交或回滚。 TM - 事务管理器定义全局事务的范围：开始全局事务、提交或回滚全局事务。 RM - 资源管理器管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 其中TC为单独部署的Server，TM和RM嵌入到Client端。 分布式事务的生命周期 TM请求TC开启一个全局事务。TC生成一个XID作为全局事务的编号。 XID在RPC中传播给每一个调用链的服务。 每个RM拿到XID后向TC发起一个分支事务，TC返回一个代表这个分支事务的XID。 RM完成本地分支的业务，提交本地分支，并且报告给TC。 全局事务调用链处理完毕，TM根据有无异常向TC发起全局事务的提交或者回滚。 分布式解决方案2PC即两阶段提交协议，是将整个事务流程分为两个阶段。 准备阶段：事务协调者给每个参与者发送Prepare消息，每个数据库参与者在本地执行事务，并写本地的Redo/Undo日志，此时事务没有提交。 Undo log：记录修改前的数据，用于数据库回滚。 Redo log：记录修改后的数据，用于提交事务后写入数据的文件。 提交阶段：如果事务管理器收到了参与者的执行失败或者超时消息时，直接给每个参与者发送回滚消息，否则发送提交消息，参与者根据事务管理器指令进行提交或者回滚操作。并且释放事务处理过程中使用的资源。 Seata AT模式一阶段在一阶段中，Seata会拦截”业务SQL”，首先解析SQL语义，找到要更新的业务数据，在数据更新前，保存“undo log”，然后执行“业务SQL”更新数据，更新之后保存“redo log”，最后生成锁，这些操作都是在本地数据库事务内完成，这样保证了一阶段的原子性。 二阶段如果一阶段中有本地事务没有通过，那么则执行全局回滚，否则执行全局提交，回滚用到的就是一阶段记录的“undo log”，通过回滚记录生成反向更新SQL并执行，已完成分支事务的回滚，事务完成后释放所有资源并且删除所有日志。 TCC模式实际上Seata的AT模式基本能满足我们分布式事务80%的场景，但是如果分布式事务处理如果涉及Mysql、Oracle、PostgreSQL之外的数据库以及中间件或跨语言需要手动控制整个二阶段提交过程的需求，则需要结合TCC模式，TCC模式也支持与AT模式混合使用。 一个分布式的全局事务，整体是两阶段提交（Try-[Comfire/Canel]）的模型，在Seata中，AT模式和TCC模式事实上都是两阶段提交的具体实现。TCC模式概括来说就是手工版的AT模式。 AT模式和CT模式的区别： AT模式需要依赖本地ACID事务与关系型数据库的支持 它对两个阶段的处理逻辑都是自定义的方式，所以它不依赖undo_log以及底层数据资源事务的支持，这种方式相对的也更加的有侵入性。 ATT模式的两阶段流程： 一阶段prepare：调用自定义的prepare逻辑 二阶段commit：调用自定义commit逻辑 二阶段rollback：调用自定义rollback逻辑","link":"/2023/01/09/2023-01-09_%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E4%B9%8BSeata/"},{"title":"Redis知识点总结","text":"Redis的网络模型这个问题需要考虑是从哪些维度来看，如果从全局来看Redis肯定是多线程的，早在Redis 4.0就引入了多线程去处理异步任务，例如删除大Key、flushall等命令。我们说Redis的单线程一般说的是Redis的网络模型，在Redis 6.0之前，Redis的网络模型都是一个标准的单线程Reactor模型的，在6.0版本Redis引入多线程网络模型。 在Redis6.0版本Redis的线程模型改为Muti-Reactor/Master-Workers模型，但是Redis的多线程网络模型并不是一个标准的Muti-Reactor/Master-Worker模型，最大的不同就是在标准的Multi-Reactor/Master-Workers模式下，Sub Reactors/Workers会完成网络读-&gt;数据解析-&gt;命令执行-&gt;网络写的整套流程。Main Reactor/Master只负责分派任务，而在Redis的多线程方案中，I/O线程任务仅仅是通过Socket读取客户端请求命令并解析，没有真正的去执命令，所有客户端命令最后还是要回到主线程中去执行，因此对多核的利用率并不算高，而且每次主线程都必须在分配完任务之后等待所有I/O线程完成任务之后才能继续执行其他逻辑。 Redis之所以需要如此设计它的多线程处理，主要是为了保持它的兼容性，因为以前Redis都是单线程的，所有的操作都是非线程安全的，现在引入多线程，如果按照标准的Multi-Reactor/Master-Workers模型进行实现，则所有的操作都必须重构成线程安全的，这个工作量无疑是巨大的。 所以，Redis目前的多线程方案更像是一个折中的选择，既保持了原系统的兼容性，又能一定程度上利用多核提升I/O性能。 Redis事务TODO Redis原子性Redis的事务和我们平常理解的关系型数据库的事务不同。我们知道数据库事务具有四大特性： 原子性 事务是最小的执行单位，不允许分割，要么全部执行成功，要么全部执行失败。 隔离性 事务直接是相互隔离的，多个事务并发执行并不互相干扰。 持久性 事务对数据库的操作是持久的。 一致性 执行事务前后，数据保持一致性。 我们可以把Redis中的事务简单理解成：Redis事务提供了一种将多个命令请求打包的功能，然后再按照打包的顺序执行所有命令，并且中途不会被打断。 Redis如何判断数据是否过期Redis通过一个过期字典（例如hash表）来保存数据过期的时间，过期字典的键指向Redis数据库中的某个Key值，过期字典的值是一个long long的整数，这个整数保存了key所指向的数据库键的过期时间。（毫秒精度的unix时间戳）。 过期数据的删除策略惰性删除取出key的时候才对数据进行过期检查，这样对cpu十分友好，但是会导致太多过期key没有被删除。 定期删除每隔一段时间去除一批key执行删除过期key操作，并且Redis底层会通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。 定期删除对内存更加友好，惰性删除对CPU更加友好，两者各有千秋，所以Redis采用的是定期删除+惰性删除。 但是仅仅通过给key设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉很多过期key，这样会导致大量的key堆积再内存中，导致Out of memory。 Redis通过内存淘汰机制处理该问题。 内存淘汰策略TODO 持久化RDB（Redis DataBase）Redis将fork一个子进程来进行持久化，在指定时间间隔内将内存中的数据写入磁盘（即快照），恢复时将快照文件直接读到内存中。 fork介绍fork一个与当前进程一样的子进程。 配置RDB文件配置12### rdb文件配置dbfilename dump.rdb RDB文件保存位置12### rdb 文件的保存路径可以修改。默认为 Redis 启动时命令行所在的目录下。dir ./ 当 redis 无法写入磁盘，关闭 redis 的写入操作12### 当 redis 无法写入磁盘，关闭 redis 的写入操作。stop-writes-on-bgsave-error yes 开启持久化文件压缩存储12### 持久化的文件是否进行压缩存储rdbcompression yes RDB文件完整性检查12### 开启RDB文件完整性检查rbdchecksum yes RDB文件写入策略12### 每秒写的次数 格式：save 秒 写操作次数save 60 10000 优点 适合大规模的数据恢复 对数据完整性和一致性要求不高 节省磁盘空间 恢复速度快 缺点 fork的时候，内存中的数据被clone了一份，数据膨胀2倍 虽然fork使用了写时拷贝技术，但是如果数据庞大时还是十分消耗性能 以一定时间周期进行备份，如果Redis意外down掉，则会丢失最后一次备份之后所有的数据 AOF（Append-only file）AOF以日志的形式来记录每个写操作（增量保存），将Redis执行过的所有写指令记录下来，只许追加文件但是不可以改写文件，Redis启动时会读取该文件重构数据，其实就是Redis重启会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。 AOF执行流程 客户端的写请求会被append追加到AOF缓冲区内。 AOF缓冲区根据AOF的缓冲策略（always，everysec，no）将操作同步到磁盘的AOF文件中。 AOF文件大小超过重写策略或者手动执行重写时，会对AOF文件进行重写，压缩AOF文件容量。 Redis重启时会重写加载AOF文件中的写操作达到数据恢复的目的。 AOF和RDB同时开启时，Redis默认读取AOF的数据。 配置AOF开启12### AOF默认不开启appendonly no AOF文件配置12### AOF文件名称appendfilename &quot;appendonly.aof&quot; AOF同步策略 appendfsync always:始终同步，每次 Redis 的写入都会立刻记入日志; appendfsync everysec:每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失; appendfsync no:Redis 不主动进行同步，把同步时机交给操作系统; 12### 配置AOF同步策略appendfsync everysec AOF重写当 AOF 文件的大小超过所设定的阈值时，Redis 就会启动 AOF 文件的内容压缩，只保留可以恢复数据的最小指令集。也可以使用命令 bgrewriteaof手动触发。 123no-appendfsunc-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 优点 备份机制更稳健，丢失数据概率更低； 可读的日志文本，通过操作 AOF 稳健，可以处理误操作； 缺点 比起 RDB 占用更多的磁盘空间； 恢复备份速度要慢； 每次读写都同步的话，有一定的性能压力； 存在个别 Bug，造成不能恢复 AOF与RDB选择官方推荐两个都启用。如果对数据不敏感，可以选单独用 RDB。不建议单独用 AOF，因为可能会出现 Bug。如果只是做纯内存缓存，可以都不用。 Redis主从复制Redis的主从复制，是将一台Redis服务器的数据复制到其他Redis服务器，前者称为Master，后者称为Slave，数据的复制是单向的，只能由Master到Slave。 作用 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复，实质上是一种服务的冗余。 负载均衡：在主从复制的基础上配合读写分离，可以由主节点提供写服务，由从节点提供读服务，分担服务器负载，尤其在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 高可用基石：除了上述作用以外，主从复制还是哨兵机制和集群能够实施的基础，因此说主从复制时Redis高可用的基础。 原理 在2.8版本之前只有全量复制，而2.8版本后有全量和增量复制。 全量复制：第一次进行复制时。 增量复制：只会把主从库网络断连期间主库收到的命令，同步给从库。 全量同步 当我们启动多个Redis实例的生活，他们相互之间就可以通过replicaof命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。 全量同步的三个阶段 第一阶段是主从库间建立连接、协商同步的过程 第二阶段主库将所有数据同步给从库 第三阶段主库把第二阶段执行过程中新收到的写命令再发送给从库 增量同步 在Redis 2.8版本引入了增量复制。 如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。 repl_backlog_buffer：从主库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量复制带来的性能开销，如果断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量复制，所以repl_backlog_buffer配置尽量大一点，可以降低主从断开后全量复制的概率。而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这里就用到了replication buffer。 参考：Redis多线程网络模型全面揭秘","link":"/2023/01/30/2023-01-30-Redis%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"},{"title":"Gitlab-CI&amp;CD搭建教程","text":"Gitlab-CI&amp;CD搭建教程笔记 前置操作由于远程SSH端口和Gitlab Clone端口冲突，所以将远程SSH端口重新映射为9998端口。 修改SSH端口 安装Gitlab1234567891011$ export GITLAB_HOME=/srv/gitlab$ sudo docker run --detach \\ --hostname gitlab.example.com \\ --publish 443:443 --publish 80:80 --publish 22:22 \\ --name gitlab \\ --restart always \\ --volume $GITLAB_HOME/config:/etc/gitlab \\ --volume $GITLAB_HOME/logs:/var/log/gitlab \\ --volume $GITLAB_HOME/data:/var/opt/gitlab \\ --shm-size 256m \\ gitlab/gitlab-ee:latest Gitlab的默认密码 gitlab-ce-14初装以后，把密码放在了一个临时文件中了/etc/gitlab/initial_root_password 这个文件将在首次执行reconfigure后24小时自动删除 安装&amp;启动Runner1234$ docker run -d --name gitlab-runner --restart always \\ -v /srv/gitlab-runner/config:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ gitlab/gitlab-runner:latest 注册Runner1234567891011121314151617181920212223$ docker run --rm -it -v /srv/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner registerRuntime platform arch=amd64 os=linux pid=7 revision=6d480948 version=15.7.1Running in system-mode. Enter the GitLab instance URL (for example, https://gitlab.com/):http://192.168.0.212/Enter the registration token:GR1348941Hk1xxJ88rfV94CMEzeE3Enter a description for the runner:[cff90c9af51c]: demo-cidiEnter tags for the runner (comma-separated):demoEnter optional maintenance note for the runner:This demo-runner is maintained by stone-98WARNING: Support for registration tokens and runner parameters in the 'register' command has been deprecated in GitLab Runner 15.6 and will be replaced with support for authentication tokens. For more information, see https://gitlab.com/gitlab-org/gitlab/-/issues/380872 Registering runner... succeeded runner=GR1348941Hk1xxJ88Enter an executor: parallels, ssh, docker+machine, docker-ssh+machine, custom, docker-ssh, virtualbox, instance, kubernetes, docker, shell:dockerEnter the default Docker image (for example, ruby:2.7):baldwinkm/jdk:8Runner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded! Configuration (with the authentication token) was saved in &quot;/etc/gitlab-runner/config.toml&quot; 根据Docker注册Gitlab-Runner的配置： 输入您Gitlab的URL（进入项目-&gt;设置-&gt;CI/CD-&gt;展开Runner-&gt;复制对应的URL）； 输入token（与上面URL在同一个位置，直接复制token）； 输入次Runner的描述； 输入次Runner的tag，此tag在后续使用中需要使用这个tag来指定gitlab-runner（Gitlab管理界面也可以进行修改）； 输入此Runner的维护信息； 输入此Runner的执行器； 输入默认的Docker镜像（默认的Docker Image，每次Gitlab-Runner会生成一个新的Docker镜像，Docker执行器就是在这个镜像的基础上，执行对应的命令）； 创建一个CICD测试项目新增.gitlab-ci.yml 123456789101112131415161718192021222324252627282930build-job: stage: build script: - echo &quot;Hello, $GITLAB_USER_LOGIN!&quot; tags: - demotest-job1: stage: test script: - echo &quot;This job tests something&quot; tags: - demotest-job2: stage: test script: - echo &quot;This job tests something, but takes more time than test-job1.&quot; - echo &quot;After the echo commands complete, it runs the sleep command for 20 seconds&quot; - echo &quot;which simulates a test that runs 20 seconds longer than test-job1&quot; - sleep 20 tags: - demodeploy-prod: stage: deploy script: - echo &quot;This job deploys something from the $CI_COMMIT_BRANCH branch.&quot; tags: - demo 推上去触发gitlab cicd Gitlab CI报错 原因是 runner 创建的 docker 容器没有 gitlab.example.com 的 hosts 记录，无法拉起 git 仓库。 解决方法是设置 runner 的配置文件 config.toml 添加 extra_hosts 配置： 1234567891011$ vi /srv/gitlab-runner/config/config.toml [runners.docker] extra_hosts = [&quot;gitlab.example.com:192.168.0.212&quot;] tls_verify = false image = &quot;baldwinkm/jdk:8&quot; privileged = false disable_entrypoint_overwrite = false oom_kill_disable = false disable_cache = false volumes = [&quot;/cache&quot;] shm_size = 0 重启 1docker restart gitlab-runner 重试流水线","link":"/2023/01/12/2023-01-12_Gitlab-CI&CD%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/"},{"title":"Reactor模型的多种模式","text":"这篇文章介绍下Reactor的几种模式 网络框架的设计离不开 I/O 线程模型，线程模型的优劣直接决定了系统的吞吐量、可扩展性、安全性等。目前主流的网络框架几乎都采用了 I/O 多路复用的方案。Reactor 模式作为其中的事件分发器，负责将读写事件分发给对应的读写事件处理者。 单线程Reactor模型 工作流程： 有连接请求，Reactor会通过dispatch把请求交给Acceptor进行处理； 当发生IO读写事件之后，又会通过dispatch将IO读写事件交给对应的Handler进行处理； 此时一个Reactor模型既负责处理连接请求，又负责处理读写请求，一般的来说处理连接请求是很快的，但是读写请求就要设计到具体的业务逻辑了，对于业务逻辑处理较慢的，此方式其实不是那么适用。 单线程Reactor模型编程简单，比较适用于每个请求都可以快速完成的场景，不能发挥多核CPU的优势。 多线程Reactor模型 工作流程： 当客户端发起请求后，Reactor会把任务交给acceptor处理 当客户端发起读写IO，Reactor会读取请求的数据 然后Reactor将数据交个Thread Pool进行处理 处理之后再由Reactor发送数据到客户端 从图中我们可以知道，acceptor、workHandler还是单线程，但是到process就开启多线程了。 单Reactor模型看起来很不错了，但是还是有一个缺点：一个Reactor即要负责连接请求，又要负责读写请求，连接请求相对来说是比较快的，而且一个客户端只要连接一次，但是会发生多次读写事件，如果可以有多个Reactor，启动一个Reactor负责处理连接事件，多个Reactor负责处理客户端的写事件，这样更加符合单一职责，所以主从Reactor模型诞生了。 多Reactor多线程设计 工作流程： 当有连接请求时，mainReactor将请求分发给acceptor进行处理 当发生读写请求时，通过subReactor对客户端的请求进行读写 然后再交给Thread Pool进行业务逻辑的处理 可以看到acceptor始终都只有一个main线程，而负责处理客户端读、写请求的时不同的线程。而且还是不同reactor和selector。","link":"/2023/01/30/2023-02-03_Reactor%E6%A8%A1%E5%9E%8B/"},{"title":"Zookeeper与Redis两种分布式锁的实现","text":"什么是分布式锁？在单机Java程序中来说，通常使用Lock相关类以及Synchronized关键字这类JDK自带的本地锁来控制一个JVM进程内的多个线程对本地共享资源的访问。但是在分布式部署场景下，Lock相关类以及Synchronized这类关键字并不能满足需求。 分布式锁需要满足的条件 互斥：任意一个时刻，锁只能被一个线程持有。 高可用：锁服务是高可用的，就算客户端代码错误，锁也一定会被释放，不会影响其他线程对共享资源的访问 可重入：一个节点获取锁之后，还可以再次获取锁。 通常情况下，我们常用ZK和Redis实现分布式锁。 基于Redis实现的分布式锁在Redis中可以通过setnx命令设置分布式锁。 setnx语意：如果key不存在，则设置key的值。如果key已经存在则不做任何操作。 主要流程setnx设置锁-&gt;执行业务代码-&gt;del释放锁 设置过期时间为了避免以下场景： 应用程序遇到一些问题比如释放给锁的逻辑突然挂掉，可能会导致锁无法被释放，从而造成死锁。 所以给Key设置一个过期时间，来解决死锁问题。 1$ set lockkey un 问题在经过上述问题的处理后，Redis分布式锁是否就完全安全了呢？答案是”否“ 比如在Sentinel集群中，当Master宕机，重新选举一个Master，这种情况可能会出现客户端明明在老的Master获取成功了，但是正好这个时候Master宕机了，Sentinel重新选举一个Master，丢失了该锁的数据，又可以重新获取这个锁，这样就导致锁失效问题。 为了解决这个问题，后续有人发明了Redlock算法，他的流程比较复杂，为了使用Redlock，需要提供多个Redis示例，这些示例之间相互独立没有主从关系。同很多分布式算法一样，Redlock也使用[大多数机制]。 加锁时，它会向过半节点发送加锁命令，只要过半节点加锁成功，那么久认为加锁成功，释放锁时，需要向所有节点发送del指令，不过Redlock算法还需要考虑很多细节问题，并且它比单实例Redis的性能会下降一些。 目前Redission也没有内置Redlock算法。","link":"/2023/01/30/2023-01-31-Zookeeper%E4%B8%8ERedis%E4%B8%A4%E7%A7%8D%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"title":"JVM之堆空间","text":"堆的核心概念 一个JVM示例只存在一个堆内存，堆也是Java内存管理的核心区域。 Java堆区在JVM启动的时候即被创建，它的大小空间就被确定了。是JVM管理的最大一块内存空间。 堆内存的大小是可以调节的。 《Java虚拟机规范》规定，堆可以处于物理上不连续的内存空间中，但在逻辑上它应该是连续的。 所有线程共享Java堆，在这里还可以划分线程私有的缓冲区(TLAB)。（这个存在的意义是堆内存是共享的，会存在线程安全问题，如果每次操作堆都进行互斥，那么堆空间的性能会很差，所以在这里划分出一个线程私有的缓冲区也就是TLAB） 《Java虚拟机规范》中对Java堆的描述：几乎所有的对象实例以及数组都应当在运行时分配在堆上。 在方法结束后，堆的对象并不会马上被移除，当在垃圾回收的时候才会被移除。 堆是GC执行垃圾回收的重点区域。 设置堆内存大小与OOM Eden Minor GC &amp;&amp; MajorGC &amp;&amp; FullGCJVM进行垃圾回收，大部分回收的是新生代。 针对Hotspot VM的实现，它里面的GC按照回收区域又分为两大类型： 部分收集：不是完整的收集整个JAVA堆的垃圾收集。 新生代收集：只是新生代的垃圾收集。 老年代收集：只是老年代的垃圾收集。 目前只有CMS GC会有单独收集老年代的行为。 注意：很多时候Major GC会和Full GC混淆使用，需要具体分辨是老年代回收还是整堆回收。 混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集。 目前，只有G1 GC有这种行为。 整堆收集：收集整个JAVA堆和方法区的垃圾收集。 堆空间的参数总结","link":"/2023/01/29/2023-01-29-JVM%E4%B9%8B%E5%A0%86%E7%A9%BA%E9%97%B4/"},{"title":"RabbitMQ知识总结","text":"TODO","link":"/2023/01/29/2023-02-15-RabbitMQ%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/"},{"title":"JVM性能调优","text":"性能监控监控点： GC频繁 CPU Load过高 OOM 内存泄漏 死锁 程序响应时间较长 性能分析一种侵入式收集运行性能数据的活动，它会影响应用的吞吐量或响应性。 性能分析是针对性能问题的答复结果，关注的范围通常比性能监控更加集中。 性能分析很少在生产环境下进行，通常是在质量评估、系统测试或者开发环境下进行，是性能监控之后的步骤。 性能调优一种为改善应用响应或吞吐量而更改参数、源代码、属性配置的活动，性能调优是在性能监控、性能分析之后的活动。 主要就是改善GC和Full GC出现的次数以及减少内存占用。 性能指标 停顿时间 吞吐量： 单元时间内完成的工作量 在GC中运行用户代码占总运行时间的比例（总运行时间：程序的运行时间+内存回收时间）吞吐量为1-1/（1+n）。-XX：GCTimeRatio=n 并发数：同一时刻对服务器有实际交互的请求数 内存占用：Java堆区所占用的内存大小 JDK自带的监控工具jps查看正在运行的Java进程，类似jps命令可以方便查看Java进程的启动类、传入参数和Java虚拟机参数等信息。 参数说明： -q：只输出进程ID -m：输出传入main方法的参数 -l：输出完整的包名，应用主类名，jar的完全路径名 -v：输出jvm参数 -V：输出通过flag文件传递到JVM中的参数 jstatjstat是一款轻量级小工具，主要利用JVM内建的指令对Java应用程序的资源和性能进行实时的命令行的监控，包括对Heap size和垃圾回收的监控。 Jstat命令详解 jinfojinfo它主要的作用就是实时查看和修改VM参数。 jinfo命令详解 jmapjmap是用多功能的命令。它可以生成Java程序dump文件，也可以查看堆内对象示例的统计信息、查看ClassLoader的信息以及finalizer队列。 jmap详解 https://www.cnblogs.com/sxdcgaq8080/p/11089664.html jstackjcmd图形化监控界面VisualVMMATmat主要是用来分析dump文件的。","link":"/2023/01/29/2023-02-22-JVM%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"title":"JVM垃圾回收","text":"为什么要进行GC？ 对于高级语言来说，不断的生产对象，不进行垃圾回收，迟早内存会消耗完。 GC除了清理无用的对象，也可以对内存碎片进行整理，空闲出连续的内存空间，以便JVM将整理出来的内存分配给新对象。 随着业务越来越庞大，没有GC就不能保证程序的正常允许，随着GC的增多，STW的时间也会增多，所以才不断的需要对GC进行优化。 垃圾回收的早期行为早期的语言，例如C、C++语言对内存的管理都是通过手动进行管理，通过对应的函数对内存进行管理，后期的高级语言例如Java、Golang、Ruby等语言都通过虚拟机对内存区域进行自动化的管理，这样可以要用户更专注于业务，但是如果遇到内存相关的问题，将会是一场灾难。 GC需要回收哪些垃圾？Java堆中存放着几乎所有的Java对象实例，在GC执行垃圾回收之前，首先需要区分出内存中哪些是存活的对象，哪些是死亡的对象。只有被标记为已经死亡的对象才会被回收。 下面一共两种标记算法： 引用计数算法对每个对象保存一个整型的引用计数器属性，用于记录对象被引用的的情况，当被任何对象进行引用时，引用计数器就加一，当引用失效时，引用计数器就减一，当这个对象的引用计数器为0时，这个对象则可以被垃圾回收器进行回收。 优点： 实现简单，判定效率高，回收没有延迟性。 缺点： 需要新增一个字段进行存储计数器，这样的做法增加了内存的开销。 每次赋值都需要更新计数器，增加了时间的开销。 无法处理循环引用的情况。 可达性分析算法可达性分析算法是以根对象集合（GC Roots）为起始点，按照从上至下的方式搜索被根对象集合所连接的对象是否可达。 使用可达性分析算法后，内存中存活的对象都被根对象集合直接或间接连接着，搜索所走过的路径称为引用链表。 如果目标对象没有任何引用链表相连接，则是不可达的，就意味着该对象已经死亡，可以标记为垃圾对象。 在可达性分析算法中，只有能够被根对象集合直接或者间接的对象才是存活对象。 作为GC Roots包括以下元素： 虚拟机栈中引用的对象 本地方法栈内JNI引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 所有被synchronized持有的对象 Java虚拟机内部的引用 反应Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。 注意：如果要使用可达性分析算法来判断内存是否可以回收，那么分析工作必须在一个能保障一致性的快照中进行。这点不满足的话分析结果的准确性就无法保证。这点也是GC进行时必须“Stop The World”的一个重要原因。即使是号称不会发生停顿的CMS收集器中，枚举根节点时也是必须要停顿的。 finalization机制使用MAT和JProfile进行分析垃圾清除垃圾收集器G1垃圾收集器是垃圾收集器技术发展历史上的里程碑式的成果，它开创了收集器面向局部收集的设计思路和基于Region的内存布局形式。 G1是一款主要面向服务端应用的垃圾收集器。HotSpot开发团队最初赋予它的期望是（在比较长期的）未来可以替换掉JDK 5中发布的CMS收集器。现在这个期望目标已经实现过半了，JDK 9发布之日，G1宣告取代Parallel Scavenge加Parallel Old组合，成为服务端模式下的默认垃圾收集器。 作为CMS收集器的替代者和继承人，设计者们希望做出一款能够建立起“停顿时间模型”（Pause Prediction Model）的收集器，停顿时间模型的意思是能够支持指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间大概率不超过N毫秒这样的目标，这几乎已经是实时Java（RTSJ）的中软实时垃圾收集器特征了。 垃圾收集算法垃圾收集器的实现设计大量的实现细节，在这里我们只讨论集中算法的思想以及发展过程，不探讨具体的实现细节。 标记清除算法最早出现的垃圾回收算法就是“标记清除算法”。具体思路就是：标记需要存活的对象，然后回收没有被标记的对象，反过来也是可行的。标记清除算法是最基础的算法，因为后续的收集算法大都都是以标记清除算法为基础进行实现的。 缺点: 执行效率不稳定，如果Java堆中大部分对象需要被回收，这时候必须要进行大量标记和清除的动作，导致标记和清除的执行效率过低。 内存碎片化问题，标记、清除之后会产生大量不连续的内存碎片，空间碎片过多可能会导致后续再运行中没有足够的连续的内存空间分配较大的对象而不得不触发另一次垃圾回收。 标记复制算法标记复制算法为了解决面对大量可回收对象时执行效率低的问题，将可用内存划分为大小相等的两块，每次只使用其中一块，当这一块的内存用完了，就将还存货的对象复制到另外一块上面，然后再把已经使用的内存空间一次清理掉。 优点： 对于多数对象都是可回收的情况，只需要复制少量的对象，每次分配都市针对整个半区进行内存回收，也不需要考虑有空间碎片的情况，只要移动堆顶指针，按顺序进行分配即可。这样实现简单，运行高效。 缺点： 如果内存中多数对象都是存活的，这种算法会产生大量内存复制的开销。 堆的可用空间缩小为原来的一半。 在1989年提出了“Appel式回收”，HotSpot虚拟机的Serial、ParNew等新生代收集器均采用了这种策略来设计新生代的内存布局。它将新生代分为一块较大的Eden和两块较小的Survivor区域，每次分配只会使用Eden和其中一块Survivor区域，发生垃圾收集时，将Eden和Survivor中仍然存活的对象一次性复制到另外一块Survivor空间上，然后直接清理掉Eden和已用过的那块Survivor空间。发生垃圾回收时，将Eden和Survivor中仍然存活的对象一次性复制到另外一块Survivor空间上，然后直接清理掉Eden和已用过的那块Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也即每次新生代中可用的内存是整个新生代容量的90%，当Survivor空间不足以容纳一次Minor GC之后存活的对象时，就需要依赖其他内存区域进行分配担保。 标记整理算法标记复制算法在对象存活率较高时就要进行较多的复制操作，效率会比较低下，所以在老年代一般不直接采用这种算法。 针对老年代的存亡特征，1974年提出一种“标记整理算法”，其中的标记过程仍然与“标记清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向内存的一端进行移动，然后直接清理掉边界以外的内存。 垃圾收集器实现细节TODO 垃圾收集器Parallel Scavenge垃圾收集器HostSpot的年轻代除了拥有ParNew收集器是基于并行回收以外，Parallel Scavenge收集器同样也采用了复制算法、并行回收和“Stop The World”机制。 那么Parallel收集器的出现是否多此一举？ 和ParNew收集器不同，Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量，它也被称为吞吐量优先的垃圾收集器。 自适应调节策略也是Parallel Scavenge与ParNew一个重要区别。 高吞吐量则可以高效率的利用CPU的资源，尽快完成程序的运算任务，主要适合在后台运算不需要太多交互的任务。例如，那些执行批量处理、订单处理、工资支付、科学计算的应用程序。 Parallel收集器在JDK1.6时提供了用于执行老年代垃圾收集的Parallel Old收集器，用来代替来年代的Serial Old收集器。 Parallel Old收集器采用了标记-压缩算法，但同样也是基于并行回收和”Stop the world”机制。 在程序吞吐量优先的场景中，Parallel收集器和Parallel Old收集器的租和，在Server模式下的内存回收性能很不错。 在Java8中，默认是此垃圾收集器。 CMS垃圾收集器在JDK1.5时期，HotSpot推出一款在强交互应用中几乎可认为有划时代意义的垃圾收集器：CMS（Concurrent-Mark-Sweep）收集器，这款收集器是HotSpot虚拟机中第一款真正意义上的并发收集器，它第一次实现了要垃圾收集线程与用户线程同时工作。 CMS收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，停顿时间越短就越适合与用户交互的程序，良好的响应速度可以提升用户的体验。 CMS的垃圾收集器算法采用标记-清除算法，并且也会“Stop-the-world”。 但是CMS作为老年代的收集器，却无法与JDK1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作，所以在JDK1.5中使用CMS来收集老年代时，新生代只能选择ParNew或者Serial收集器中的一个。 在G1出现之前，CMS使用还是非常广泛的。一直到现在，仍然还有很多系统使用CMS GC。 CMS优点 并发收集 低延迟 CMS缺点 会产生内存碎片，导致并发清除后，用户线程可用的空间不足。在无法分配大对象的情况下，不得不提前触发Full GC。 CMS收集器对CPU资源非常敏感。在并发阶段，它虽然不会导致用户停顿，但是会因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低。 CMS收集器无法处理浮动垃圾。可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。在并发标记阶段由于程序的工作线程和垃圾收集线程是同时运行或者交叉运行的，那么在并发标记阶段如果产生新的垃圾对象，CMS将无法对这些垃圾对象进行标记，最终会导致这些新产生的垃圾无法被及时回收，从而知道在下一次执行GC时释放这些之前内存空间。 CMS垃圾收集器参数 -XX:+UseConcMarkSweepGC：表明老年代使用CMS GC，同时年轻代触发对ParNew的使用。 -XX:CMSLnitiatingOccupanyFraction：设置堆内存使用率的阈值，一旦达到该阈值，便开始进行回收。 JDK5及以前版本的默认值为68，也就是说老年代的空间使用率达到68%时，会触发一次CMS回收。JDK6及以上版本默认值为92%。 如果内存增长缓慢可以设置一个稍大的值，大的阈值可以有效的减低CMS触发的频率，减少老年代回收的次数可以明显的改善程序的性能。反之，可以降低改阈值，反之频繁的触发Seral垃圾收集器。因此通过该选项可以有效的降低Full GC的执行次数。 垃圾收集器小结HotSpot有这么多垃圾回收器，那么Serial GC、Parallel GC、Concurrent Mark Sweep GC这三个GC有何区别呢？ 最小化使用内存和并行的开销：Serial GC； 最大化应用程序的吞吐量：Parallel GC； 最小化GC的中断或停顿时间：CMS GC； JDK后续版本中CMS的变化 Garbage First收集器当前所面对的业务越来越庞大、复杂、用户量越来越多，所以不断的对GC进行优化，Garbage First垃圾收集器是在Java 7 update 4之后引入的一个新的垃圾回收器，是当前收集器技术发展的最前沿成果之一。 为了适应现在不断扩大的内存和不断增加的处理器数量，进一步降低暂停时间，同时兼顾良好的吞吐量。官方给G1设定的目标是在延迟可控的情况下获得尽可能高的吞吐量，所以才担起“全功能收集器”的重担与期望。 GarbageFirst原理G1是一个并行回收器，它把堆内存分割为很多不相关的区域（物理上是不连续的）。使用不同的区域来代表Eden、S0、S1、Old等区域。 G1 GC有计划的避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及所需要的时间信息），在后台维护一个优先级列表，每次根据允许收集时间，优先回收价值最大的区域。 GarbageFirst的优势 并发与并行 并行性：G1在回收期间，可以有多个GC同时工作，有效利用多核计算能力。 并发性：G1拥有与应用程序交替执行的能力，部分工作可以和应用程序同时执行，因此，一般来说，不会再整个回收阶段发生完全阻塞应用程序的情况。 分代收集 从分代上看其实GarbageFirst还是属于分代型垃圾回收器，它会区分年轻代和老年代，年轻代依然有Eden区、Survivor区，但是从堆的结构上看，它不要求整个Eden区、年轻代或者老年代都是连续的，也不再坚持固定大小和固定数量。 将堆空间分为若干个区域，这些区域中包含逻辑上的年轻代和老年代。 和之前的各类垃圾回收器不同，它同时兼备年轻代和老年代，对比其他回收器，或者工作在年轻代，或者工作在老年代。 空间整合 CMS：“标记-清除”算法、内存碎片、若干次GC后进行一次碎片整理。 G1将内存划分为一个一个Region。内存的回收是以region作为基本单位的，Region之间是复制算法，但整体上可看作是“标记-压缩”算法，这两种算法都可以避免内存碎片。这种特性有利于程序长时间允许，分配大对象时不会因为无法找到连续的内存空间而提前触发下一次Full GC。尤其是当Java堆非常大的时候，G1的优势更加明显。 可预测的停顿时间模型 这是G1相对于CMS的另一大优势，G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间段内，消耗在垃圾收集上的时间不超过N毫秒。 由于分区的原因，可以先选取部分区域进行内存回收，这样缩小了回收的范围，因此对于全局停顿情况的发生也能得到较好的控制。 G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及所需要的时间信息），在后台维护一个优先级列表，每次根据允许的时间，优先回收价值最大的Region。保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。 相比于CMS GC，G1未必能做到CMS在最好情况下的延迟停顿，但是在最差的情况下要好很多。 GarbageFirst缺点相较于CMS，G1还不具备全方位、压倒性优势。比如在用户程序运行过程中，G1无论是为了垃圾收集产生的内存占用还是程序运行时的额外负载都要比CMS要高。 从经验上来说，在小内存应用上CMS的表现大概率会优于G1，而G1在大内存应用上则发挥其优势。平衡点在6-8GB之间。 GarbageFirst的参数设置GarbageFirst使用场景 面向服务端应用，针对具有大内存，多处理器的机器。 最主要的应用时需要低延迟，并且具有大堆的应用程序的提供解决方案。 例如：在堆大小约6GB或者更大时，可预测的暂停时间可以低于0.5s。（G1通过每次只清理一部分而不是全部的Region的增量式清理来保证每次GC停顿时间不会过长） 用来替换JDK1.5中的CMS收集器。 在下列场景中G1可能比CMS更加适合 超过50%的Java堆被活动数据占用； 对象分配频率或年代提升频率变化很大； GC的停顿时间过长（长于0.5~1s） HotSpot垃圾收集器里，除了G1以外，其他垃圾收集器使用内置的JVM线程执行GC的多线程操作，而G1 GC可以采用应用线程承担后台运行的GC工作，即当JVM的GC线程处理速度慢时，系统会调用应用程序的线程去加速垃圾的回收。 GrabageFirst垃圾回收器的主要环节 年轻代GC（Young GC） 老年代并发标记过程（Concurrent Marking） 混合回收（Mixed GC） 如果需要，Full GC还是继续存在。它针对GC的评估失败提供一种保护措施，即强力回收。 Remembered SetRegion中的对象可能被其他任意Region中对象所引用，那么如果我们对一个Region进行Minor GC时，需要判断此Region的对象是否存活，那么是否需要进行整个堆扫描才能保证结果的准确率呢？其实不仅仅是G1垃圾收集器有此问题，其他的垃圾收集器也有此问题，只是G1垃圾收集器此问题更加突出（因为G1相对来说有更多的Region），如果进行整个堆的扫描的话，肯定会降低Minor GC的效率。 其实无论是G1还是其他分代收集器，都是通过Remembered Set来避免全局扫描，每一个Region都有一个对应的Remembered Set，每次Reference类型数据写操作时，都会产生一个Write Barrier（写屏障）暂时中断的操作。然后检查要写入的引用指向的对象是否和该Reference类型数据在不同的Region，如果不同，则通过CardTable把相关引用信息记录到引用指向对象所在Region对应的Remembered Set中。当进行垃圾收集时，在GC根节点的枚举范围加入Remembered Set，就可以保证不进行全局扫描，并且也不会有遗漏。 G1垃圾收集器回收过程G1垃圾收集器优化建议从Oracle官方透漏出来的信息可知，回收阶段其实本来也想设计成与用户程序一起并发指向，但是具体的实现可能比较复杂，考虑到G1只是回收一部分Region，停顿时间是用户可控制的，所以并不迫切去实现。选择把此特性放到了G1之后的低延迟垃圾收集器（ZGC）中。 年轻代的大小 避免使用-Xmn或-XX:NewRatio等相关参数显示设置年轻代大小。 固定年轻代的大小不合理的话导致暂停时间的目标可能就达不到，所以要JVM动态去调整年轻代的大小。 暂停时间设置的不要太过于严苛 G1 GC的吞吐量目标是90%的应用程序时间和10%的垃圾回收时间 评估G1 GC的吞吐量时，暂停的时间目标太过严苛，表示你愿意承受更多垃圾回收的开销，而这些会直接影响到吞吐量。 Region中还有一块特殊的区域，专门用来存储大对象。G1认为只要大小超过了一个Region容量一半的对象即可判定为大对象。每个Region的大小可能通过参数-XX：G1HeapRegionSize设定，取值范围1MB~32MB，而对于那些超过了整个Region容量的超级大对象，将会被存放在N个连续的Region之中，G1的大多数行为都把Humongous Region作为老年代的一部分来看待。 ZGCG1垃圾收集器通过部分区域回收的处理形式，解决了传统垃圾收集器中的全堆扫描所带来的性能问题，极大的改善在堆内存较大情况下的停顿时间，但是随着硬件性能的发展，G1回收器也同样受到了极大的性能限制。 所以Oracle为OpenJDK开源了一款ZGC垃圾回收器，ZGC是一款可伸缩、低延迟、并发垃圾回收器，ZGC的出现旨在实现以下目标： 停顿时间不超过10ms 停顿时间不随heap大小或存活对象大小增大而增大 可以处理几百M到几T的内存大小 ZGC是一款基于Region布局，但是不设置分代，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-压缩算法，以低延迟为首要目标的一款垃圾收集器。 ZGC几乎在所有地方都并发指向，除了初始化标记是STW的，所以停顿时间就耗费在初始标记上，实际上这部分时间是非常少的。 ZGC性能对比：","link":"/2023/01/29/2023-02-17-JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"title":"JUC并发包","text":"前言Spring的事务管理、Hibernate的Session管理、logback中的MDC功能的实现都有ThreadLocal的影子。 ThreadLocal的用法示例123456789101112131415161718192021222324public class ThreadLocalTest { public static final ThreadLocal&lt;String&gt; HOLDER = new ThreadLocal&lt;&gt;(); public static void main(String[] args) throws Exception { ThreadLocalTest threadLocalTest = new ThreadLocalTest(); threadLocalTest.execute(); } public void execute() throws Exception{ // 主线程设置值 HOLDER.set(&quot;stone98&quot;); System.out.println(Thread.currentThread().getName() + &quot;线程ThreadLocal中的值：&quot; + HOLDER.get()); new Thread(() -&gt; { System.out.println(Thread.currentThread().getName() + &quot;线程ThreadLocal中的值：&quot; + HOLDER.get()); // 设置当前线程中的值 HOLDER.set(&quot;《stone98》&quot;); System.out.println(&quot;重新设置之后，&quot; + Thread.currentThread().getName() + &quot;线程ThreadLocal中的值：&quot; + HOLDER.get()); System.out.println(Thread.currentThread().getName() + &quot;线程执行结束&quot;); }).start(); // 等待所有线程执行结束 Thread.sleep(1000L); System.out.println(Thread.currentThread().getName() + &quot;线程ThreadLocal中的值：&quot; + HOLDER.get()); }} 示例中定义了一个static final的ThreadLocal变量HOLDER，在main方法中模拟通过两个线程来操作HOLDER中存储的值，先对HOLDER设置一个值，然后打印获取到的值，然后新起一个线程去修改HOLDER，然后分别在新线程和主线程两处获取对应的值。 打印结果如下： 12345main线程ThreadLocal中的值：stone98Thread-0线程ThreadLocal中的值：null重新设置之后，Thread-0线程ThreadLocal中的值：《stone98》Thread-0线程执行结束main线程ThreadLocal中的值：stone98 根据程序的输出结果，我们可以得知，主线程和Thread-0各自独享自己的变量存储。两个线程互不干扰。 ThreadLocal原理分析线程存储副本的位置位于Thread的threadlocals变量中，如下所示： 12345public class Thread implements Runnable { ... ThreadLocal.ThreadLocalMap threadLocals = null; ...} ThreadLocal.ThreadLocalMap是ThreadLocal维护的静态内部类，我们在使用ThreadLocal的get、set方法时，其实都是调用了ThreadLocalMap对应的get、set方法。 Thread中threadlocals变量的初始化通常是在首次调用ThreadLocal的get、set方法时进行初始化的。 123456789static class ThreadLocalMap { static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; } }} ThreadLocal的内存泄漏问题Java中的引用要了解ThreadLocal的内存泄漏问题，需要先了解Java中的引用。Java中通常存在以下类型的引用：强引用、弱引用、软引用、虚引用 强引用：通常new出来的对象就是强引用，只要引用存在，垃圾回收器将永远不会回收被引用的对象，哪怕内存不足的时候。 软引用：使用SoftReference修饰的对象被称为软引用，软引用指向的对象在内存中要溢出的时候将会被回收，如果回收只会，还没有足够的内存，则会抛出内存溢出异常。 弱引用：使用WeakReference修饰的对象被称为弱引用，只要发生垃圾回收，无论当前内存是否足够，都会回收掉只被弱引用关联的对象实例。 虚引用：虚引用是最弱的引用，在Java中使用PhantomReference进行定义。虚引用中唯一的作用就是用队列接收对象即将死亡的通知。每个Thread都维护一个ThreadLocal.ThreadLocalMap对象，Key是ThreadLocal本身，value是用户设置的值。 ThreadLocal.ThreadLocalMap的Entry是WeakReference的子类，也就是弱引用。 ThreadLocal内存泄漏的原因","link":"/2023/02/24/2023-02-24-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8BThreadLocal/"},{"title":"线上CPU100%、内存泄漏问题排查","text":"前言如果是在容器环境中排查问题，则可以通过Docker status命令，查看是哪个容器出现得问题。 在Docker容器中使用Docker status查看出来的Cpu列的具体值含义，下面链接进行了详细的解释： Docker：CPU我劝你善良！！ CPU100%处理查找cpu占用率最高的进程通过top -c列出所有的进程线程，通过shift + p使进程列表按照cpu使用率进行排序。 查找占用CPU最高的线程通过top -Hp {pid}，同样使用shift + p按照cpu使用率对线程列表进行排序。 可以看出PID=23126的线程消耗CPU最高，通过以下命令：将十进制转为十六进制 12$ printf '%x\\n' 231265a56 生成线程快照信息通过jstack生成PID的线程快照信息： 1$ jstack -l 23126 &gt; /usr/local/23126.stack 分析线程快照通过cat命令与线程ID进行分析线程信息 1$ cat 23126.stack | grep '5a56' -C 5 这样则可以定位问题~ 思路总结 找到CPU使用率最高的进程 找到该进程中CPU使用率最高的线程 利用jstack生成该进程下所有的线程快照 去快照中找到对应的线程，分析问题 内存泄漏案例1234567891011121314151617public class HeapOOM { static class OOMObject{ } /** * VM args：-Xms20m -Xms20m -XX:+HeapDumpOnOutOfMemoryError * @param args */ public static void main(String[] args) throws Throwable { List&lt;OOMObject&gt; oomObjects = new ArrayList&lt;OOMObject&gt;(); while (true) { Thread.sleep(1); oomObjects.add(new OOMObject()); } }} 1.找出内存占用最高的进程通过top -c列出所有的进程列表，通过M对内存进行排序，如下图所示： 2.利用jmap生成堆转储快照命令： jmap -dump:format=b,file={path} {pid} 1$ jmap -dump:format=b,file=heapdump.hprof 2527 3.利用MAT分析dump文件使用mat打开hprof文件 饼状图 可以看出java.lang.Thread持有30MB的内存，肯定有问题 直方图 可以比较清晰的看出，OOMObject占用了不少内存。 支配树 这就非常直观啦，ArrayList中的OOMObject对象占用了97%的大小 可以的内存泄漏报告 通过Leak Suspects也可以看出来。 总结 找到内存使用率最高的进程 利用jmap生成该进程的堆转储快照 利用mat查看快照分析问题","link":"/2023/02/25/2023-02-25-%EF%BF%BD%0ACPU100%25%01%EF%BF%BDX%EF%BF%BD%0F%EE%98%92%EF%BF%BD/"},{"title":"GC日志详解","text":"","link":"/2023/02/26/2023-02-26-GC%E6%97%A5%E5%BF%97%E8%AF%A6%E8%A7%A3/"},{"title":"并发编程系列之原子操作类","text":"Atomic系列原子类JUC包提供了一系列得原子性操作类，这些类都使用非阻塞算法CAS算法实现的，相比使用锁实现原子性操作这在性能上有很大得提升，不需要线程从用户态到内核态的切换，由于原子操作类得原理都大致相同，所以这里我以AtomicLong类的compareAndSet方法为例。 AtomicLong内部通过Unsafe进行实现，我们来看看下面的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class AtomicLong extends Number implements java.io.Serializable { private static final long serialVersionUID = 1927816293512124184L; // 通过unsafe.compareAndSwapLong进行更新 private static final Unsafe unsafe = Unsafe.getUnsafe(); // 存放value的偏移量 private static final long valueOffset; /** * 判断JVM是否支持Long类型的CAS操作 */ static final boolean VM_SUPPORTS_LONG_CAS = VMSupportsCS8(); // 是否支持Long类型的CAS操作 private static native boolean VMSupportsCS8(); static { try { valueOffset = unsafe.objectFieldOffset (AtomicLong.class.getDeclaredField(&quot;value&quot;)); } catch (Exception ex) { throw new Error(ex); } } // 当前值 private volatile long value; /** * 如果当前值==预期值，则以原子方式将值设置给定的更新值 */ public final boolean compareAndSet(long expect, long update) { return unsafe.compareAndSwapLong(this, valueOffset, expect, update); } /** * 获取当前vaule */ public final long get() { return value; } /** * 设置当前value */ public final void set(long newValue) { value = newValue; }} AtomicLong的CAS的实现是依托unsafe的相关方法进行实现，使用AtomicLong之前先要初始化value属性，获取到偏移量，然后再通过当前AtomicLong以及value的偏移量、预期值、目标值进行CAS更新操作。 Adder系列原子类Accumulator系列原理探究总结本篇文章介绍了并发包中的原子性操作类，这些类都是使用CAS算法进行实现，比使用锁实现原子性在性能上有较大提升，首先讲解了AtomicLong类的实现原理，后续讲解了JDK8中的LongAddr和LongAccumuator类的原理。","link":"/2023/03/01/2023-03-01-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%B3%BB%E5%88%97%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%B1%BB/"},{"title":"并发编程系列之基础知识","text":"并发与并行的区别并发：同一个时间段内多个任务同时都在执行。 并行：在单位时间内多个任务同时在执行。 线程安全问题多个线程访问共享内存出现脏数据或者其他不可预见结果的问题。 案例 t1 t2 t3 t4 线程A 从共享内存中读取count值到本线程 递增本线程中的count的值 写回到共享内存中 线程B 从共享内存中读取count值到本线程 递增本线程count的值 写回到共享内存中 假如当前count=0，在t1时刻线程A从共享内存中读取count的值到本线程，然后递增本线程中的count的值，在t2时刻，线程A还没有将count的值写入共享内存中时，线程B则读取count的值到本线程然后进行递增，到t4时刻再将count的值写入共享内存。 当出现这种情况时，线程B的递增操作就将线程A的递增操作覆盖了。当出现内存可见性问题，可以通过关键字synchronized进行同步。 线程中断关于线程中断，在Thread方法中有一个stop方法，stop方法可以快速、方便的终止一个线程，但是stop方法过于暴力，假设一个线程正在处理一个复杂的业务流程，处理到一半调用stop方法，那么对于这个业务数据的一致性是毁灭性的。所以如果要对线程进行中断不推荐使用stop方法。要我们来了解一下下面三个关于线程中断的相关源码。 12345678910111213141516171819202122232425262728293031public class Thread implements Runnable { // 判断是否被中断，并且不清除中断标识 public boolean isInterrupted() { return isInterrupted(false); } // 判断是否被中断 private native boolean isInterrupted(boolean ClearInterrupted); // 依托isInterrupted判断线程是否中断，并且清除中断标识 public static boolean interrupted() { return currentThread().isInterrupted(true); } // 给目标线程一个中断信号，线程被打上中断标记，当一个被打上中断标识的线程调用wait、join、sleep方法，那么该线程的中断标识会被清除， // 并且接收到一个InterruptedException。 public void interrupt() { if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) { Interruptible b = blocker; if (b != null) { interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; } } interrupt0(); }} 通过源码我们能很容易的理解Thread类暴漏的三个方法（isInterrupted、interrupted、interrupt）的作用， 下面来看几个线程中断的案例： 示例一：中断失败12345678910public static void test01() { Thread thread = new Thread(() -&gt; { while (true) { Thread.yield(); System.out.println(&quot;子线程运行中...&quot;); } }); thread.start(); thread.interrupt();} 请问示例1中的线程会被中断吗？答案：不会，因为虽然给线程发出了中断信号，但程序中并没有响应中断信号的逻辑，所以程序不会有任何反应。 示例二：中断成功12345678910111213Thread thread = new Thread(() -&gt; { while (true) { Thread.yield(); // 响应中断 if (Thread.currentThread().isInterrupted()) { System.out.println(&quot;Java技术栈线程被中断，程序退出。&quot;); return; } }});thread.start();thread.interrupt(); 我们给示例2加上了响应中断的逻辑，程序接收到中断信号打印出信息后返回退出。 实例三：中断失败1234567891011121314151617181920public static void test03() throws InterruptedException { Thread thread = new Thread(() -&gt; { while (true) { // 响应中断 if (Thread.currentThread().isInterrupted()) { System.out.println(&quot;线程被中断，程序退出。&quot;); return; } try { Thread.sleep(3000); } catch (InterruptedException e) { System.out.println(&quot;线程休眠被中断，程序退出。&quot;); } } }); thread.start(); Thread.sleep(2000); thread.interrupt();} 实例三：sleep方法被中断，并且输出“线程休眠被中断，程序退出。”，程序继续运行。 因为sleep会清除中断标识，并且抛出InterruptedException。但是不会影响程序的继续运行。 实例四：中断成功123456789101112131415161718192021public static void test04() throws InterruptedException { Thread thread = new Thread(() -&gt; { while (true) { // 响应中断 if (Thread.currentThread().isInterrupted()) { System.out.println(&quot;Java技术栈线程被中断，程序退出。&quot;); return; } try { Thread.sleep(3000); } catch (InterruptedException e) { System.out.println(&quot;Java技术栈线程休眠被中断，程序退出。&quot;); Thread.currentThread().interrupt(); } } }); thread.start(); Thread.sleep(2000); thread.interrupt();} 示例四全部信息输出并正常退出，只是在 sleep() 方法被中断并清除标记后手动重新中断当前线程，然后程序接收中断信号返回退出。 通过以上上个示例，相信我们对线程中断也有了更加深入的了解。 CASCAS即Compare and Swap，它是JDK提供的非阻塞原子性操作，它通过硬件保证了比较更新操作的原子性。JDK里面的Unsafe提供了一系列的compareAndSwap方法。 CAS的经典ABA问题加入线程I使用CAS要将初始值为a的变量X修改为b，那么线程I会首先去获取当前变量X的值，然后将X的值修改为b，当还没执行CAS操作之前，此时如果线程II将变量X从初始值a修改到了c，然后又从c修改为a，所以虽然线程I执行CAS时X的值是a，但是此时这个a已经不是线程I当初获取到的a了，这就是CAS经典的ABA问题。 ABA问题的原因就是变量的状态值产生了环状转换，例如JDK中的AtomicStampedReference就给每个变量的状态值都配备了一个时间戳，从而避免ABA问题的产生。 指令重排序Java内存模型允许编译器和处理器对指令重排序以提高运行性能，并且只会对不存在数据依赖性的指令重排序。在单线程下重排序可以保证最终执行的结果与程序顺序执行的结果一致，但是在多线程下就会存在问题。 下面看一个例子： 123int a = 1;// (1)int b = 2;// (2)int c = a + b;// (3) 在如上代码中，变量c的值依赖a和b的值，所以重排序后能够保证(3)的操作在（1）（2）之后，但是（1）（2）谁先执行就不一定了，这在单线程下不会存在问题，并且不会影响最终结果。 下面看多线程的一个例子： 12345678910111213141516171819202122232425262728293031323334public class InstructionReorderingDemo { private static int num = 0; private static boolean ready = false; public static void main(String[] args) throws InterruptedException { ReadThread rt = new ReadThread(); rt.start(); WriteThread wt = new WriteThread(); wt.start(); Thread.sleep(10); rt.interrupt(); System.out.println(&quot;main exit&quot;); } public static class ReadThread extends Thread { @Override public void run() { while (!Thread.currentThread().isInterrupted()) { if (ready) { System.out.println(num + num); } System.out.println(&quot;read thread...&quot;); } } } public static class WriteThread extends Thread { public void run() { num = 2; ready = true; System.out.println(&quot;writeThread set over...&quot;); } }} 如果上述代码在不考虑内存可见性的情况下也不一定会输出4，由于（1）（2）（3）（4）之间不存在依赖关系，所有写线程的代码（3）（4）可能会被重新排序，可能会先执行（4）再执行（3），再执行（4）后，读线程可能已经执行（1）操作了，这时候输出的结果就为0，而不是4。 而使用volatile修饰ready就可以避免重排序和内存可见性问题。 伪共享（未完成）为了解决计算机系统中主内存与CPU之间的运行速度差问题，所以在CPU与主内存之间添加一级或者多级高速缓冲存储器。 当CPU访问某个变量时，首先会去看CPU Cache内是否有该变量，有则直接从中获取，否则直接从主内存中去获取该变量，然后把该变量所在内存区域的一个Cache行大小的内存复制到Cache中，由于存放到Cache行的是内存块而不是单个变量，所以会把多个变量存放到一个Cache行中，当多个线程同时修改一个缓存行里面的多个变量时，由于同时只能有一个线程操作缓存行，所以相比将每个变量存放在一个缓存行，性能会有所下降，这就是伪共享。 锁的相关概念悲观锁与乐观锁悲观锁和乐观锁都是数据库中引入的名词，悲观锁的概念就是如果假设数据一定会出现线程安全问题，则类似synchronized等类似方式就符合乐观锁的概念。乐观锁的概念就是假设数据不一定会出现线程安全问题，类似CAS的处理方式就符合乐观锁的概念。 公平锁与非公平锁根据抢占锁的机制，锁可以分为公平锁和非公平锁，公平锁表示线程获取锁的顺序是按照请求锁的时间来决定的，也就是先到先得的方式。而公平锁则不一定。 比如ReentrantLock提供了公平和非公平锁的实现。 独占锁和共享锁独占锁顾名思义一个锁只能被单个线程持有，例如ReentrantLock，而共享锁可以被多个线程持有。例如ReadWriteLock。 可重入锁当一个线程获取一个被其他线程持有的独占锁时，会被阻塞。如果线程再次获取它自己已经获取的锁时，如果不被阻塞则说明该锁是可重入的。 自旋锁由于Java中的线程和操作系统的线程是一一对应的，当一个线程在获取锁失败后，会被切换到内核状态而被挂起，当该线程获取到锁时又需要将其切换到内核状态而唤醒该线程，而从用户态切换到内核态的开销时比较大的，在一定程度上其实能够影响并发性能。 自旋锁则是，当前线程在获取锁时，如果发现锁已经被其他线程占用，不会马上放弃CPU的使用进行阻塞自己，而是多次尝试获取。由此看来自旋锁其实就是使用CPU时间换取线程阻塞与调度的开销。 总结此文章主要讲述了并发编程的相关基础知识，为后续深入了解并发编程打下基础。","link":"/2023/02/28/2023-02-28-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"title":"并发编程系列之LockSupport","text":"LockSupport是JDK里面的一个工具类，主要作用用于挂起和唤醒线程，该工具类是创建锁和其他同步类的基础。 LockSupport类与每个使用它的线程都会关联一个许可证，它底层是依托Unsafe进行实现的。 LockSupport几个核心的方法： park()：如果调用park的线程已经拿到了许可证，则立马返回，否则将会被阻塞挂起。 unPark(Thread thread)：如果thread还没有持有许可证，则让thread持有。 parkNanos(long nanos)：如果当前线程已经持有许可证则立马返回，否则等待nanos毫秒返回。 park(Object blocker)：park方法还可以设置相关的对象，该对象会被记录到线程内部，例如我们调用时传入this，这样在打印线程堆栈排查问题时就能知道是哪个类被阻塞了，方便快速定义问题。 注意park的相关方法，不一定需要unPark才能返回，也可以通过线程中断（Thread#interrupt()）对park进行返回。但是park方法返回不会告诉你是因为何种原因进行返回，所以调用者自身要做好检查，防止出现预期之外的返回情况。 例如下面案例，我们想子线程被其他线程中断才继续执行，则要进行相关的判断机制： 123456789101112131415public class LockSupportDemo { public static void main(String[] args) throws InterruptedException { Thread t = new Thread(() -&gt; { System.out.println(&quot;begin park&quot;); while (!Thread.currentThread().isInterrupted()){ LockSupport.park(); } System.out.println(&quot;unpark&quot;); }); t.start(); Thread.sleep(1000); System.out.println(&quot;main thread begin unpark!&quot;); t.interrupt(); }}","link":"/2023/03/03/2023-03-03-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%B3%BB%E5%88%97%E4%B9%8BLockSupport/"},{"title":"并发编程系列之并发List源码解析","text":"介绍并发包中的并发List只有CopyOnWriteArrayList。CopyOnWriteArrayList是一个线程安全的ArrayList，对CopyOnWriteArrayList是一个线程安全的ArrayList，对它的操作都是在底层的一个复制数组上进行的，使用写时复制策略。 12345678public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable { // 修改array时，通过lock进行线程安全控制 final transient ReentrantLock lock = new ReentrantLock(); // 用于存储具体的元素 private transient volatile Object[] array;} 初始化CopyOnWriteArrayList的相关构造方法的初始化逻辑如下所示： 123456789101112131415161718192021222324252627282930313233343536public CopyOnWriteArrayList() { setArray(new Object[0]); } /** * Creates a list containing the elements of the specified * collection, in the order they are returned by the collection's * iterator. * * @param c the collection of initially held elements * @throws NullPointerException if the specified collection is null */ public CopyOnWriteArrayList(Collection&lt;? extends E&gt; c) { Object[] elements; if (c.getClass() == CopyOnWriteArrayList.class) elements = ((CopyOnWriteArrayList&lt;?&gt;)c).getArray(); else { elements = c.toArray(); // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elements.getClass() != Object[].class) elements = Arrays.copyOf(elements, elements.length, Object[].class); } setArray(elements); } /** * Creates a list holding a copy of the given array. * * @param toCopyIn the array (a copy of this array is used as the * internal array) * @throws NullPointerException if the specified array is null */ public CopyOnWriteArrayList(E[] toCopyIn) { setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class)); } 从代码中我们可以得知CopyOnWriteArrayList的初始化主要就是对array属性进行初始化。 添加元素1234567891011121314public boolean add(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; } finally { lock.unlock(); }} 通过ReentrantLock保证array属性写时的线程安全问题，然后通过Arrays.copyOf对原来的数组进行拷贝，从而生成新的数组对老的数组进行替换操作。 获取元素123456789101112private E get(Object[] a, int index) { return (E) a[index];}/** * {@inheritDoc} * * @throws IndexOutOfBoundsException {@inheritDoc} */public E get(int index) { return get(getArray(), index);} CopyOnWriteArrayList的相关获取方法都没有通过ReentrantLock进行同步，则容易产生写时复制的弱一致性问题。（感觉有点小问题~） 删除元素12345678910111213141516171819202122public E remove(int index) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; E oldValue = get(elements, index); int numMoved = len - index - 1; if (numMoved == 0) setArray(Arrays.copyOf(elements, len - 1)); else { Object[] newElements = new Object[len - 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index + 1, newElements, index, numMoved); setArray(newElements); } return oldValue; } finally { lock.unlock(); }} 删除元素其实和添加获取元素原理类似，都是通过获取独占锁保证操作期间其他线程不对array进行操作，然后获取数组中要被删除的元素，并把剩余的元素复制到新数组，之后使用新数组替换原来的数组，最后在返回前释放锁。 弱一致性的迭代器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public Iterator&lt;E&gt; iterator() { return new COWIterator&lt;E&gt;(getArray(), 0);}static final class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; { /** Snapshot of the array */ private final Object[] snapshot; /** Index of element to be returned by subsequent call to next. */ private int cursor; private COWIterator(Object[] elements, int initialCursor) { cursor = initialCursor; snapshot = elements; } public boolean hasNext() { return cursor &lt; snapshot.length; } public boolean hasPrevious() { return cursor &gt; 0; } @SuppressWarnings(&quot;unchecked&quot;) public E next() { if (! hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++]; } @SuppressWarnings(&quot;unchecked&quot;) public E previous() { if (! hasPrevious()) throw new NoSuchElementException(); return (E) snapshot[--cursor]; } public int nextIndex() { return cursor; } public int previousIndex() { return cursor-1; } /** * Not supported. Always throws UnsupportedOperationException. * @throws UnsupportedOperationException always; {@code remove} * is not supported by this iterator. */ public void remove() { throw new UnsupportedOperationException(); } /** * Not supported. Always throws UnsupportedOperationException. * @throws UnsupportedOperationException always; {@code set} * is not supported by this iterator. */ public void set(E e) { throw new UnsupportedOperationException(); } /** * Not supported. Always throws UnsupportedOperationException. * @throws UnsupportedOperationException always; {@code add} * is not supported by this iterator. */ public void add(E e) { throw new UnsupportedOperationException(); } @Override public void forEachRemaining(Consumer&lt;? super E&gt; action) { Objects.requireNonNull(action); Object[] elements = snapshot; final int size = elements.length; for (int i = cursor; i &lt; size; i++) { @SuppressWarnings(&quot;unchecked&quot;) E e = (E) elements[i]; action.accept(e); } cursor = size; }} 通过COWIterator的实现，我们可以得知在调用java.util.concurrent.CopyOnWriteArrayList#iterator方法时，就创建了array属性的快照传入COWIterator中，后续其他线程修改了CopyOnWiriteArrayList，array属性指向的是新的引用，但是COWiterator#snapshot指向的还是老数组的引用，所以其他线程对CopyOnWirteArrayList的修改对于迭代器是不可见的。 总结CopyOnWriteArrayList 使用写时复制的策略来保证 list 致性，而获取、修改、写入三步操作并不是原子性的，所以在增删改的过程中都使用了独占锁，来保证在某个时间只有一个线程能对 list 数组进行修改。另外CopyOnWirteArrayList提供了弱一致性的迭代器。","link":"/2023/03/02/2023-03-02-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%B3%BB%E5%88%97%E4%B9%8B%E5%B9%B6%E5%8F%91List%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"title":"并发编程系列之AQS源码刨析","text":"介绍在了解JAVA并发包时，AbstractQueuedSynchronizer（AQS）是实现ReentrantLock、CountDownLatch、Semaphore、FutureTask等类的基础，我们有必要深入了解AQS的实现原理。 关于AQS在源码中有十分详细的解释： 1234567891011121314Provides a framework for implementing blocking locks and relatedsynchronizers (semaphores, events, etc) that rely onfirst-in-first-out (FIFO) wait queues. This class is designed tobe a useful basis for most kinds of synchronizers that rely on asingle atomic {@code int} value to represent state. Subclassesmust define the protected methods that change this state, and whichdefine what that state means in terms of this object being acquiredor released. Given these, the other methods in this class carryout all queuing and blocking mechanics. Subclasses can maintainother state fields, but only the atomically updated {@code int}value manipulated using methods {@link #getState}, {@link#setState} and {@link #compareAndSetState} is tracked with respectto synchronization. 同步器是用来构建锁和其他同步组件的基础框架，它的实现主要依赖一个int成员变量来表示同步状态以及通过一个FIFO队列构成等待队列。它的子类必须重写AQS的几个protected修饰的用来改变同步状态的方法，其他方法主要是实现了排队和阻塞机制。状态的更新使用getState,setState以及compareAndSetState这三个方法。 AQS结构AQS内部维护了一个双向的FIFO，大体结构如图所示： AQS关键的属性以及内部类如图所示： AQS内部维护一个双向FIFO，下述为AQS的一些关键属性： AQS.head：FIFO的头节点，理解为当前持有锁的线程。 AQS.tail：FIFO的尾节点，每次新节点入队，都插入到队尾。 AQS.state：锁被持有的次数，0代表当前锁未被持有，1代表已被持有，该值也可以大于1，因为锁是可重入的，也就是可以被多次持有。 AQS的双向FIFO中每个节点都对应着AQS中的内部类Node，下述为Node的一些关键属性： Node.CANCELLED = 1：此线程取消了争抢这个锁 Node.SIGNAL = -1：当前node的后继节点对应的线程需要被唤醒 其他的waitStatus的取值常量暂时先不了解 Node.waitStatus：取值为上面的常量，当值大于0时，代表此线程取消了等待，例如ReentrantLock指定timeout抢占锁，直到超时都没有抢占成功，则该值置为Node.CANCELLED。 Node.prev：前驱节点的引用 Node.next：后继节点的引用 Node.thread：参与竞争锁的线程 AbstractQueuedSynchronizer定义的公共方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485 // 获取锁public final void acquire(int arg) { // 首先进行尝试获取锁（抽象方法，由子类进行实现），如果尝试获取锁成功，则直接返回，如果尝试获取锁失败，则调用addWaiter初始化一个Node节点加入队列，然后调用acquireQueued判断是否要中断 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); }private Node addWaiter(Node mode) { // 初始化一个Node Node node = new Node(Thread.currentThread(), mode); Node pred = tail; // 如果尾节点为空则代表队列未被初始化，则直接加入队列 if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } // 当尾节点不为空时，代表队列未被初始化，则调用enq方法初始化队列，并且将node加入队列 enq(node); return node; }// 将节点插入队列，必要时进行初始化private Node enq(final Node node) { for (;;) { Node t = tail; // 当队列未初始化时，创建一个节点，并且将head和tail指向创建的节点 if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { // 当节点已经初始化，则将节点加入队列，返回 node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } }// 释放锁 public final boolean release(int arg) { // 尝试释放锁 if (tryRelease(arg)) { Node h = head; // h != null也就是队列不为空，并且节点的状态不等于0 if (h != null &amp;&amp; h.waitStatus != 0) // 通知后续节点去获取锁 unparkSuccessor(h); return true; } return false; }// TODOprivate void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) { s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } if (s != null) LockSupport.unpark(s.thread); } ReentrantLock的加锁逻辑12345public class ReentrantLock implements Lock, java.io.Serializable { public void lock() { sync.lock(); } } reentrantLock.lock方法调用抽象类Sync的lock方法，这里我们以公平锁FairSync为例。 123final void lock() { acquire(1);} dsa 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public void lock() { // 调用Sync.lock，这里我们以FairSync为例，通过ReentrantLock的公平锁来看lock的流程 sync.lock(); } final void lock() { acquire(1);}public final void acquire(int arg) { // 首先进行尝试获取锁，如果尝试获取锁成功，则直接返回，如果尝试获取锁失败，则调用addWaiter初始化一个Node节点加入队列，然后调用acquireQueued判断是否要中断 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); }public final boolean hasQueuedPredecessors() { // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; // 第一种情况：队列未被初始化，则h==t==null，此hasQueuedPredecessors返回false，代表没有前置节点 // 第二种情况：队列已初始化，h!=t成立，h.next==null,则返回true，代表有前置节点 // 第三种情况：队列已初始化，h!=t成立，h.next != null,h.next.thread == Thread.currentThread()（虽然头节点有后置节点且不为空，但是头节点的后置节点的线程是当前线程），则返回true，代表没有前置节点 return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); }final boolean acquireQueued(final Node node, int arg) { // 获取锁是否成功 boolean failed = true; try { // 是否被中断 boolean interrupted = false; for (;;) { // 当前节点的前置节点 final Node p = node.predecessor(); // 如果当前节点的前置节点为头节点，则可以尝试进行获取锁。 // 如果尝试获取锁成功，则把当前节点设置为头节点 if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } }","link":"/2023/03/06/2023-03-06-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%B3%BB%E5%88%97%E4%B9%8BAQS%E6%BA%90%E7%A0%81%E5%88%A8%E6%9E%90/"},{"title":"SpringCloud系列之Ribbon原理","text":"","link":"/2023/02/26/2023-03-07-SpringCloud%E7%B3%BB%E5%88%97%E4%B9%8BRibbon%E5%8E%9F%E7%90%86/"},{"title":"SpringCloud系列之Ribbon原理刨析","text":"本文不深入讲解Ribbon的各个实现细节，而是通过案例入手大致分析它的流程。 Demo介绍Demo地址（欢迎大家的Star~~~） 此Demo分别有两个服务springcloud-ribbon-consumer和springcloud-ribbon-producer服务，springcloud-ribbon-consumer提供了一个用户注册接口，当用户注册时去调用springcloud-ribbon-producer的发送短信接口。 用户注册接口123456789101112131415@Slf4j@RestController@RequestMapping(&quot;user&quot;)public class UserController { @Autowired private RestTemplate restTemplate; @GetMapping(&quot;/register&quot;) public String register() { log.info(&quot;用户开始注册。&quot;); // 发送短信 return restTemplate.getForEntity(&quot;http://springcloud-ribbon-producer/message/send&quot;, String.class).getBody(); }} 发送短信接口12345678910@Slf4j@RestController@RequestMapping(&quot;message&quot;)public class MessageController { @RequestMapping(&quot;send&quot;) public String sendMessage(){ log.info(&quot;发送短信。&quot;); return &quot;send ok&quot;; }} 本案例注册中心使用Nacos，所以启动服务之前先启动本地Nacos 启动SpringCloudRibbonProducerExample.class 启动SpringCloudRibbonConsumerExample.class Ribbon流程 LoadBalancerAutoConfiguration自动装配，为RestTemplate注入LoadBalancerInterceptor 通过RestTemplate进行调用时，被LoadBalancerInterceptor拦截依托RibbonLoadBalancerClient进行处理 RibbonLoadBalancerClient通过ILoadBalancer组件依托IRule.choose选择对应的服务 通过LoadBalancerRequest发起具体的调用","link":"/2023/03/08/2023-03-08-SpringCloud%E7%B3%BB%E5%88%97%E4%B9%8BRibbon%E5%8E%9F%E7%90%86%E5%88%A8%E6%9E%90/"},{"title":"SpringCloud系列之OpenFeign原理刨析","text":"1234567891011121314151617181920212223242526272829303132333435## Feign、OpenFeign、Spring Cloud Feign、SpringCloud OpenFeign介绍Feign是SpringCloud组件中的一个轻量级RESTful的HTTP服务客户端，是SpringCloud中的第一代负载均衡客户端。SpringCloud OpenFeign在Feign的基础上支持了Spring MVC的注解，如@RequesMapping等等。是SpringCloud中的第二代负载均衡客户端。关于Feign、OpenFeign、Spring Cloud Feign关于它们的背景很多人不熟悉，我查了相关资料，下面的文章比较清晰的讲解了关于它们三个的背景。[Feign、OpenFeign、Spring Cloud Feign的区别](https://juejin.cn/post/7097124836496900127)总结一下：- **Feign** 最开始是 **Netflix** 公司开源是一个组件- **2016年，Netflix** 将 **Feign** 捐献给社区，并改名为 **OpenFeign**- **Spring Cloud Feign** 是对 **Feign** 的封装，以方便在 **Spring** 环境中使用 - `spring-cloud-starter-feign` 是 **Spring Cloud Feign** 的早期版本，现已不在维护 - `spring-cloud-starter-openfeign` 是目前正在使用中的 **Spring Cloud Feign**## Spring Cloud OpenFeign的使用## Spring Cloud OpenFeign源码分析### 注入流程在Spring Cloud OpenFeign的使用中，我们知道我们在启动类加上@EnableFeignClients就可以使用@Autowired将对应的Client注入并且可以像调用本地方法一样进行远程调用，我们打开@EnableFeignClients的源码看它是如何实现的。```java@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(FeignClientsRegistrar.class)public @interface EnableFeignClients { ...} 源码中@EnableFeignClients标注@Import并且引入了FeignClientsRegistrar，我们继续深入~ 12345678910111213class FeignClientsRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware, EnvironmentAware { ... @Override public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) { // 给@EnableFeignClients的全局默认配置（defaultConfiguration属性）创建BeanDefinition对象注入到IOC容器中 registerDefaultConfiguration(metadata, registry); // 给标注@FeignClient的类创建BeanDefinition对象注入到IOC容器中 registerFeignClients(metadata, registry); } ...} FeignClientsRegistrar类通过@Import+ImportBeanDefinitionRegistrar接口，实现registerBeanDefinitions方法，向IOC容器中注入相关BeanDefinition。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public void registerFeignClients(AnnotationMetadata metadata, BeanDefinitionRegistry registry) { LinkedHashSet&lt;BeanDefinition&gt; candidateComponents = new LinkedHashSet&lt;&gt;(); // 获取EnableFeignClient的相关属性 Map&lt;String, Object&gt; attrs = metadata .getAnnotationAttributes(EnableFeignClients.class.getName()); // 获取EnableFeignClient#clients的属性 final Class&lt;?&gt;[] clients = attrs == null ? null : (Class&lt;?&gt;[]) attrs.get(&quot;clients&quot;); // 如果未配置clients，则开始扫描FeignClient，否则使用clients if (clients == null || clients.length == 0) { ClassPathScanningCandidateComponentProvider scanner = getScanner(); scanner.setResourceLoader(this.resourceLoader); scanner.addIncludeFilter(new AnnotationTypeFilter(FeignClient.class)); Set&lt;String&gt; basePackages = getBasePackages(metadata); for (String basePackage : basePackages) { candidateComponents.addAll(scanner.findCandidateComponents(basePackage)); } } else { for (Class&lt;?&gt; clazz : clients) { candidateComponents.add(new AnnotatedGenericBeanDefinition(clazz)); } } for (BeanDefinition candidateComponent : candidateComponents) { if (candidateComponent instanceof AnnotatedBeanDefinition) { // verify annotated class is an interface // 得到@FeignClient注解的beanDefinition AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent; AnnotationMetadata annotationMetadata = beanDefinition.getMetadata(); Assert.isTrue(annotationMetadata.isInterface(), &quot;@FeignClient can only be specified on an interface&quot;); // 获取元数据属性 Map&lt;String, Object&gt; attributes = annotationMetadata .getAnnotationAttributes(FeignClient.class.getCanonicalName()); // 获取@FeignClient中配置的服务名称。 String name = getClientName(attributes); // 向IOC容器中注册@FeignClient的configuration属性类 registerClientConfiguration(registry, name, attributes.get(&quot;configuration&quot;)); // 向IOC容器中注册标注@FeignClient的类 registerFeignClient(registry, annotationMetadata, attributes); } }} 经过上述代码分析，其实大致梳理registerFeignClients方法，主要做了如下事情： 首先获取到EnableFeignClient相关属性 通过EnableFeignClient属性进行包扫描 将标注了@FeignClient的类扫描出来 委托registerFeignClient与registerClientConfiguration方法向IOC容器中进行注册 12345678910private void registerClientConfiguration(BeanDefinitionRegistry registry, Object name, Object configuration) { BeanDefinitionBuilder builder = BeanDefinitionBuilder .genericBeanDefinition(FeignClientSpecification.class); builder.addConstructorArgValue(name); builder.addConstructorArgValue(configuration); registry.registerBeanDefinition( name + &quot;.&quot; + FeignClientSpecification.class.getSimpleName(), builder.getBeanDefinition());} registerClientConfiguration方法，其实就是把FeignClient的configuration抽象成一个FeignClientSpecification对象，然后向容器中注册FeignClientSpecification。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private void registerFeignClient(BeanDefinitionRegistry registry, AnnotationMetadata annotationMetadata, Map&lt;String, Object&gt; attributes) { String className = annotationMetadata.getClassName(); Class clazz = ClassUtils.resolveClassName(className, null); ConfigurableBeanFactory beanFactory = registry instanceof ConfigurableBeanFactory ? (ConfigurableBeanFactory) registry : null; String contextId = getContextId(beanFactory, attributes); String name = getName(attributes); FeignClientFactoryBean factoryBean = new FeignClientFactoryBean(); factoryBean.setBeanFactory(beanFactory); factoryBean.setName(name); factoryBean.setContextId(contextId); factoryBean.setType(clazz); BeanDefinitionBuilder definition = BeanDefinitionBuilder .genericBeanDefinition(clazz, () -&gt; { factoryBean.setUrl(getUrl(beanFactory, attributes)); factoryBean.setPath(getPath(beanFactory, attributes)); factoryBean.setDecode404(Boolean .parseBoolean(String.valueOf(attributes.get(&quot;decode404&quot;)))); Object fallback = attributes.get(&quot;fallback&quot;); if (fallback != null) { factoryBean.setFallback(fallback instanceof Class ? (Class&lt;?&gt;) fallback : ClassUtils.resolveClassName(fallback.toString(), null)); } Object fallbackFactory = attributes.get(&quot;fallbackFactory&quot;); if (fallbackFactory != null) { factoryBean.setFallbackFactory(fallbackFactory instanceof Class ? (Class&lt;?&gt;) fallbackFactory : ClassUtils.resolveClassName(fallbackFactory.toString(), null)); } return factoryBean.getObject(); }); definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); definition.setLazyInit(true); validate(attributes); AbstractBeanDefinition beanDefinition = definition.getBeanDefinition(); beanDefinition.setAttribute(FactoryBean.OBJECT_TYPE_ATTRIBUTE, className); beanDefinition.setAttribute(&quot;feignClientsRegistrarFactoryBean&quot;, factoryBean); // has a default, won't be null boolean primary = (Boolean) attributes.get(&quot;primary&quot;); beanDefinition.setPrimary(primary); String[] qualifiers = getQualifiers(attributes); if (ObjectUtils.isEmpty(qualifiers)) { qualifiers = new String[] { contextId + &quot;FeignClient&quot; }; } BeanDefinitionHolder holder = new BeanDefinitionHolder(beanDefinition, className, qualifiers); BeanDefinitionReaderUtils.registerBeanDefinition(holder, registry); } 上述代码较多，但是逻辑较为简单，主要的逻辑： 创建一个BeanDefinitionBuilder 创建一个FeignClientFactoryBean并把从@FeignClient注解中解析到的属性都设置到FeignClientFactoryBean中 调用BeanDefinitionReaderUtils.registerBeanDefinition将FeignClientFactoryBean注册到IOC容器中 FeignClientFactoryBean解析从上述描述中，可得知最终注入到IOC中的是FeignClientFactoryBean，Spring会在类初始化时根据这个类来生成代理对象，主要逻辑在于FeignClientFactoryBean.getObject()方法中，源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class FeignClientFactoryBean implements FactoryBean&lt;Object&gt;, InitializingBean, ApplicationContextAware, BeanFactoryAware { @Override public Object getObject() { return getTarget(); } &lt;T&gt; T getTarget() { // 从容器中获取FeignContext FeignContext context = beanFactory != null ? beanFactory.getBean(FeignContext.class) : applicationContext.getBean(FeignContext.class); // 根据获取到的FeignContext构建出Feign.Builder Feign.Builder builder = feign(context); // @FeignClient未指定url属性 if (!StringUtils.hasText(url)) { if (LOG.isInfoEnabled()) { LOG.info(&quot;For '&quot; + name + &quot;' URL not provided. Will try picking an instance via load-balancing.&quot;); } if (!name.startsWith(&quot;http&quot;)) { url = &quot;http://&quot; + name; } else { url = name; } url += cleanPath(); // 生成代理和我们之前的代理一样，注解 @FeignClient 未指定 url 属性则返回一个带有负载均衡功能的客户端对象 return (T) loadBalance(builder, context, new HardCodedTarget&lt;&gt;(type, name, url)); } if (StringUtils.hasText(url) &amp;&amp; !url.startsWith(&quot;http&quot;)) { url = &quot;http://&quot; + url; } String url = this.url + cleanPath(); Client client = getOptional(context, Client.class); if (client != null) { if (client instanceof LoadBalancerFeignClient) { // not load balancing because we have a url, // but ribbon is on the classpath, so unwrap client = ((LoadBalancerFeignClient) client).getDelegate(); } if (client instanceof FeignBlockingLoadBalancerClient) { // not load balancing because we have a url, // but Spring Cloud LoadBalancer is on the classpath, so unwrap client = ((FeignBlockingLoadBalancerClient) client).getDelegate(); } if (client instanceof RetryableFeignBlockingLoadBalancerClient) { // not load balancing because we have a url, // but Spring Cloud LoadBalancer is on the classpath, so unwrap client = ((RetryableFeignBlockingLoadBalancerClient) client) .getDelegate(); } builder.client(client); } Targeter targeter = get(context, Targeter.class); return (T) targeter.target(this, builder, context, new HardCodedTarget&lt;&gt;(type, name, url)); }} 12345678910111213141516171819202122232425262728public class ReflectiveFeign extends Feign { public &lt;T&gt; T newInstance(Target&lt;T&gt; target) { Map&lt;String, MethodHandler&gt; nameToHandler = targetToHandlersByName.apply(target); Map&lt;Method, MethodHandler&gt; methodToHandler = new LinkedHashMap&lt;Method, MethodHandler&gt;(); List&lt;DefaultMethodHandler&gt; defaultMethodHandlers = new LinkedList&lt;DefaultMethodHandler&gt;(); for (Method method : target.type().getMethods()) { if (method.getDeclaringClass() == Object.class) { continue; } else if (Util.isDefault(method)) { DefaultMethodHandler handler = new DefaultMethodHandler(method); defaultMethodHandlers.add(handler); methodToHandler.put(method, handler); } else { methodToHandler.put(method, nameToHandler.get(Feign.configKey(target.type(), method))); } } // 创建动态代理 InvocationHandler handler = factory.create(target, methodToHandler); T proxy = (T) Proxy.newProxyInstance(target.type().getClassLoader(), new Class&lt;?&gt;[] {target.type()}, handler); for (DefaultMethodHandler defaultMethodHandler : defaultMethodHandlers) { defaultMethodHandler.bindTo(proxy); } return proxy; }} 远程通信实现在Spring启动过程中，把一切的准备工作准备就绪后，则可以开始执行远程调用。 在前面的分析中，我们知道OpenFeign最终返回的是一个ReflectiveFeign.FeignInvocationHandler对象。当客户端发起请求时，会被它进行拦截。 1234567891011121314151617181920static class FeignInvocationHandler implements InvocationHandler { public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 如果调用的是equals、hashCode、toString相关的方法，则不需要进行远程调用，可以通过Target的相关方法直接返回 if (&quot;equals&quot;.equals(method.getName())) { try { Object otherHandler = args.length &gt; 0 &amp;&amp; args[0] != null ? Proxy.getInvocationHandler(args[0]) : null; return equals(otherHandler); } catch (IllegalArgumentException e) { return false; } } else if (&quot;hashCode&quot;.equals(method.getName())) { return hashCode(); } else if (&quot;toString&quot;.equals(method.getName())) { return toString(); } // dispatch的value保存的是FeignInvocationHandler，所以直接会调用到SynchronousMethodHandler.invoke方法中 return dispatch.get(method).invoke(args); }} 上述代码基本上就是对Object的公用方法进行判断，如果是equals、hashCode、toString类型的公共方法则可以不发起远程调用直接调用Target相关方法进行返回就OK，否则依托SynchronousMethodHandler进行处理，下述是SynchronousMethodHandler的源码： 1234567891011121314151617181920212223242526272829303132final class SynchronousMethodHandler implements MethodHandler { public Object invoke(Object[] argv) throws Throwable { // 通过参数构建一个RequestTemplate RequestTemplate template = buildTemplateFromArgs.create(argv); // 获取配置项，连接超时时间、远程通信数据获取超时时间 Options options = findOptions(argv); // 获取重试策略 Retryer retryer = this.retryer.clone(); while (true) { try { // 执行请求并且解码 return executeAndDecode(template, options); } catch (RetryableException e) { try { // 如果允许重拾，则继续传播进行重试，否则抛出异常中断重试 retryer.continueOrPropagate(e); } catch (RetryableException th) { Throwable cause = th.getCause(); if (propagationPolicy == UNWRAP &amp;&amp; cause != null) { throw cause; } else { throw th; } } if (logLevel != Logger.Level.NONE) { logger.logRetry(metadata.configKey(), logLevel); } continue; } } }} 上述代码总结： 通过参数构建对应的RequestTemplate 获取相关的配置项 执行请求并且解码响应 请求失败进行重试机制处理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748Object executeAndDecode(RequestTemplate template, Options options) throws Throwable { // 将template转化为请求报文 Request request = targetRequest(template); if (logLevel != Logger.Level.NONE) { logger.logRequest(metadata.configKey(), logLevel, request); } Response response; long start = System.nanoTime(); try { // 发起请求，此时client是LoadBalanceFeignClient，需要先使用Ribbon对服务名称进行负载 response = client.execute(request, options); // ensure the request is set. TODO: remove in Feign 12 response = response.toBuilder() .request(request) .requestTemplate(template) .build(); } catch (IOException e) { if (logLevel != Logger.Level.NONE) { logger.logIOException(metadata.configKey(), logLevel, e, elapsedTime(start)); } throw errorExecuting(request, e); } long elapsedTime = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - start); // 如果设置了解码器，需要先对响应数据进行解码操作 if (decoder != null) return decoder.decode(response, metadata.returnType()); CompletableFuture&lt;Object&gt; resultFuture = new CompletableFuture&lt;&gt;(); // 莫有看懂这个异步的处理~~~ asyncResponseHandler.handleResponse(resultFuture, metadata.configKey(), response, metadata.returnType(), elapsedTime); try { if (!resultFuture.isDone()) throw new IllegalStateException(&quot;Response handling not done&quot;); return resultFuture.join(); } catch (CompletionException e) { Throwable cause = e.getCause(); if (cause != null) throw cause; throw e; } } 上述代码总结： 将RequestTemplate转化为Template 依托LoadBalanceFeignClient进行调用，这里的逻辑属于Ribbon的逻辑，这里不进行深入讲解 对响应进行解码 返回响应 参考https://segmentfault.com/a/1190000041389449### https://zhuanlan.zhihu.com/p/386599495","link":"/2023/03/08/2023-03-09-SpringCloud%E7%B3%BB%E5%88%97%E4%B9%8BOpenFeign%E5%8E%9F%E7%90%86%E5%88%A8%E6%9E%90/"},{"title":"像我这样的人","text":"像我这样优秀的人 本该灿烂过一生 怎么二十多年到头来 还在人海里浮沉 像我这样聪明的人 早就告别了单纯 怎么还是用了一段情 去换一身伤痕 像我这样迷茫的人 像我这样寻找的人 像我这样碌碌无为的人 你还见过多少人 像我这样庸俗的人 从不喜欢装深沉 怎么偶尔听到老歌时 忽然也晃了神 像我这样懦弱的人 凡是都要留几分 怎么曾经也会为了谁 想过奋不顾身 像我这样迷茫的人 像我这样寻找的人 像我这样碌碌无为的人 你还见过多少人 像我这样孤单的人 像我这样傻的人 像我这样不甘平凡的人 世界上有多少人 像我这样迷茫的人 像我这样寻找的人 像我这样碌碌无为的人 你还见过多少人 像我这样孤单的人 向我这样傻的人 像我这样不甘平凡的人 世界上有多少人 像我这样莫名其妙的人 会不会有人心疼","link":"/2023/03/09/2023-03-09-%E5%83%8F%E6%88%91%E8%BF%99%E6%A0%B7%E7%9A%84%E4%BA%BA/"},{"title":"并发编程系列之ReentrantReadWriteLock详解","text":"介绍解决线程安全问题使用ReentrantLock就可以，但是ReentrantLock是独占锁，在一个时刻只有一个线程可以获取该锁，然后在实际场景中如果有写少读多的场景，那么ReentrantLock并不是那么适用于该场景，所以ReentrantReadWriteLock就应运而生，采用读写分离的策略，多个读线程可以同时持有该锁。 源码解读ReentrantReadWriteLock整体结构1234567891011121314151617181920212223242526272829303132333435363738public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable { /** 读锁 */ private final ReentrantReadWriteLock.ReadLock readerLock; /** 写锁 */ private final ReentrantReadWriteLock.WriteLock writerLock; final Sync sync; /** 使用默认（非公平）的排序属性创建一个新的 ReentrantReadWriteLock */ public ReentrantReadWriteLock() { this(false); } /** 使用给定的公平策略创建一个新的 ReentrantReadWriteLock */ public ReentrantReadWriteLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); readerLock = new ReadLock(this); writerLock = new WriteLock(this); } /** 返回用于写入操作的锁 */ public ReentrantReadWriteLock.WriteLock writeLock() { return writerLock; } /** 返回用于读取操作的锁 */ public ReentrantReadWriteLock.ReadLock readLock() { return readerLock; } abstract static class Sync extends AbstractQueuedSynchronizer {} static final class NonfairSync extends Sync {} static final class FairSync extends Sync {} public static class ReadLock implements Lock, java.io.Serializable {} public static class WriteLock implements Lock, java.io.Serializable {}} ReentrantReadWriteLock中的Sync在AbstractQueuedSynchronizer的基础之上再进行了一层抽象，然后通过NonfairSync以及FairSync对Sync进行具体实现，分别实现了公平锁和非公平锁。然后ReentrantReadWriteLock进行初始化时同时初始化ReentrantReadWriteLock#sync，ReentrantReadWriteLock的相关操作都依赖sync。 ReentrantReadWriteLock#ReadLock与ReentrantReadWriteLock#WriteLock实现Lock接口定义了读锁和写锁的具体规范。 ReentrantReadWriteLock内部类的继承结构 读写锁状态的设计AQS的同步状态通过一个整形变量来维护，而ReentrantReadWriteLock需要在一个整形变量上维护多个读线程和一个写线程状态。读写锁对于同步状态的实现是在一个整形变量上通过“按位切割使用”：将变量切割成两部分，高16位表示读，低16位表示写。相关源码如下所示： 1234567891011121314151617181920abstract static class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = 6317671515068378041L; /* * Read vs write count extraction constants and functions. * Lock state is logically divided into two unsigned shorts: * The lower one representing the exclusive (writer) lock hold count, * and the upper the shared (reader) hold count. */ static final int SHARED_SHIFT = 16; static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT); static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1; static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1; /** Returns the number of shared holds represented in count */ static int sharedCount(int c) { return c &gt;&gt;&gt; SHARED_SHIFT; } /** Returns the number of exclusive holds represented in count */ static int exclusiveCount(int c) { return c &amp; EXCLUSIVE_MASK; } ...} 假设当前同步状态值为statu，那么相关操作如下所示： 获取写状态：S&amp;1111111111111111 获取读状态：S&gt;&gt;&gt;16 写状态加1：S+1 读状态加1：S+（1&lt;&lt;16） 在了解完读写锁状态的设计后，我们知道ReentrantReadWriteLock是如何保存读写锁的数量以及读写锁 读锁计数器的设计1234567891011121314151617abstract static class Sync extends AbstractQueuedSynchronizer { private transient ThreadLocalHoldCounter readHolds; private transient HoldCounter cachedHoldCounter; private transient Thread firstReader = null; private transient int firstReaderHoldCount; static final class HoldCounter { int count = 0; // Use id, not reference, to avoid garbage retention final long tid = getThreadId(Thread.currentThread()); } static final class ThreadLocalHoldCounter extends ThreadLocal&lt;HoldCounter&gt; { public HoldCounter initialValue() { return new HoldCounter(); } }} firstReader：记录首个读锁的线程。 firstReaderHoldCount：记录firstReader线程持有的读锁数量。 HoldCounter：用于记录当前线程重入读锁的次数，存储着读锁的重入次数以及线程ID。 ThreadLocalHoldCounter：ThreadLocalHoldCounter继承ThreadLocal，那么该类型的变量是每个线程各自保存一份，保存的内容则是HoldCounter，里面存储了读锁的重入次数以及线程ID。 readHolds：readHolds保存着每个读线程的重入次数，每个线程都会保存一份副本。 cachedHoldCounter：用于保存最近获取读锁线程的重入次数。（由名称可知该变量是一个缓存，为了加快代码执行的速度。因为往往释放读锁的线程都是最近获取读锁的线程，虽然每个线程的重入次数都会使用readHolds进行保存，但是readHolds会设计到ThreadLocal内部的查找，这是存在一定开销的。通过cachedHoldCounter缓存字段，不用每次都在ThreadLocal的内部进行查找，从而加快代码的执行速度）。 读锁与写锁的核心释放逻辑读锁释放锁读锁释放锁demo实现如下所示： 12345public static void main(String[] args) { ReentrantReadWriteLock.ReadLock readLock = lock.readLock(); readLock.lock(); readLock.unlock(); } ReentrantReadWriteLock.ReadLock通过unlock方法对读锁进行释放 123456public static class ReadLock implements Lock, java.io.Serializable { private final Sync sync; public void unlock() { sync.releaseShared(1); }} unlock方法它依托Sync对读锁（共享锁）进行释放，Sync继承于AQS，AQS提供看了对共享锁释放的抽象实现，源码如下所示： 1234567891011public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false; }} AQS对共享锁的释放，依赖于tryReleaseShared和doReleaseShared方法， 1234567891011121314151617181920212223242526272829303132333435363738abstract static class Sync extends AbstractQueuedSynchronizer { protected final boolean tryReleaseShared(int unused) { Thread current = Thread.currentThread(); if (firstReader == current) { // 判断是否是第一个获取读锁的线程，如果是则需要对firstReader和firstReaderHoldCount进行维护 // assert firstReaderHoldCount &gt; 0; if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; } else { // 一般释放锁的线程都是最近获取锁的那个线程 HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) // 如果不是才使用readHolds进行查找 rh = readHolds.get(); // 如果count小于等于1则将readHolds保存的HoldCounter进行移除 int count = rh.count; if (count &lt;= 1) { readHolds.remove(); // 如果count小于等于0，则抛出异常 if (count &lt;= 0) throw unmatchedUnlockException(); } // 对HoldCounter.count执行减1操作 --rh.count; } // 执行CAS操作修改AQS的状态 for (;;) { int c = getState(); int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) // Releasing the read lock has no effect on readers, // but it may allow waiting writers to proceed if // both read and write locks are now free. return nextc == 0; } }} 上述讲解了Sync.tryReleaseShared方法的实现，关于doReleaseShared大致思路就是当前节点已经释放锁，通知后继节点可以尝试去获取锁，因为它属于AQS的范畴中，所以这里不进行详细讲解。 写锁释放锁写锁释放锁demo实现如下所示： 123456public static void main(String[] args) { ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); ReentrantReadWriteLock.WriteLock writeLock = lock.writeLock(); writeLock.lock(); writeLock.unlock();} ReentrantReadWriteLock.writeLock通过unlock对写锁进行释放： 123456public static class WriteLock implements Lock, java.io.Serializable { private final Sync sync; public void unlock() { sync.release(1); }} ReentrantReadWriteLock.WriteLock.unlock依托sync.release方法，Sync继承于AQS，AQS提供看了对独占锁释放的抽象实现： 12345678910111213public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable { public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; }} release方法依托tryRelease方法和unparkSuccessor方法，tryRelease方法AQS提供了抽象，具体的实现在AQS的子类Sync中： 1234567891011121314abstract static class Sync extends AbstractQueuedSynchronizer { protected final boolean tryRelease(int releases) { // 如果释放锁的线程不是持有锁的线程则抛出异常 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 如果释放锁之后独占锁的状态为0了，则设置持有当前独占锁的线程为null，并且更新AQS的状态 int nextc = getState() - releases; boolean free = exclusiveCount(nextc) == 0; if (free) setExclusiveOwnerThread(null); setState(nextc); return free; }} 关于unparkSuccessor属于AQS的知识范畴，这里则不进行详细讲解，大致思路就是唤醒后继节点。 公平锁与非公平锁的核心逻辑公平锁概念公平锁是按照线程请求锁的顺序来获取锁，即先到先得，等待时间最长的线程会先获得锁。在公平锁中，线程会先尝试获取锁，如果获取不到，就会进入等待队列中，等待队列中的线程会按照先来先服务的原则获取锁。 非公平锁概念非公平锁则是无序地获取锁，即没有任何先后顺序，线程可以直接尝试获取锁，如果获取不到，也不一定要进入等待队列，而是可以一直自旋尝试获取锁，如果锁被其他线程释放，就可以直接获取锁。非公平锁相对于公平锁，可以减少线程上下文切换的次数，从而提高系统的吞吐量。 公平锁和非公平锁的区别在了解了公平锁和非公平锁之后，其实他们本质的区别就是在获取锁时是否需要进行阻塞。 公平锁：获取锁之前如果队列中有其他排队的线程则阻塞 非公平锁：无论队列中是否有其他排队的线程，都可以尝试获取锁 公平锁的源码实现123456789static final class FairSync extends Sync { private static final long serialVersionUID = -2274990926593161451L; final boolean writerShouldBlock() { return hasQueuedPredecessors(); } final boolean readerShouldBlock() { return hasQueuedPredecessors(); }} 这里则提供了两个方法writerShouldBlock、readerShouldBlock分别实在获取读锁和写锁的时候进行判断队列里面有没有前置节点，如果有则需要进行阻塞。 非公平锁的源码实现12345678910111213141516static final class NonfairSync extends Sync { private static final long serialVersionUID = -8159625535654395037L; final boolean writerShouldBlock() { return false; // writers can always barge } final boolean readerShouldBlock() { /* As a heuristic to avoid indefinite writer starvation, * block if the thread that momentarily appears to be head * of queue, if one exists, is a waiting writer. This is * only a probabilistic effect since a new reader will not * block if there is a waiting writer behind other enabled * readers that have not yet drained from the queue. */ return apparentlyFirstQueuedIsExclusive(); }} 同样的这里也是提供了两个方法，writerShouldBlock和readerShouldBlock方法，理论上都应该直接返回false，但是readerShouldBlock为了防止获取写锁的线程饥饿，则如果队列中有写锁，那就要写锁先执行。","link":"/2023/03/17/2023-03-16-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%B3%BB%E5%88%97%E4%B9%8BReentrantReadWriteLock%E8%AF%A6%E8%A7%A3/"},{"title":"并发编程系列之并发队列详解","text":"JDK中提供了一系列场景的并发安全队列。按照实现方式进行划分，分为： 阻塞队列 非阻塞队列 前者使用同步锁进行实现，后置利用CAS非阻塞式算法进行实现。 ConcurrentLinkedQueueConcurrentLinkedQueue底层采用单向链表进行实现，单向链表的每个节点都抽象成ConcurrentLinkedQueue.Node，以下是它的源码实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546private static class Node&lt;E&gt; { volatile E item; volatile ConcurrentLinkedQueue.Node&lt;E&gt; next; /** * Constructs a new node. Uses relaxed write because item can * only be seen after publication via casNext. */ Node(E item) { UNSAFE.putObject(this, itemOffset, item); } boolean casItem(E cmp, E val) { return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val); } void lazySetNext(ConcurrentLinkedQueue.Node&lt;E&gt; val) { UNSAFE.putOrderedObject(this, nextOffset, val); } boolean casNext(ConcurrentLinkedQueue.Node&lt;E&gt; cmp, ConcurrentLinkedQueue.Node&lt;E&gt; val) { return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val); } // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long itemOffset; private static final long nextOffset; static { try { Class&lt;?&gt; unsafeClass = Class.forName(&quot;sun.misc.Unsafe&quot;); Field field = unsafeClass.getDeclaredField(&quot;theUnsafe&quot;); field.setAccessible(true); UNSAFE = (Unsafe) field.get(null); Class&lt;?&gt; k = ConcurrentLinkedQueue.Node.class; itemOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;item&quot;)); nextOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;next&quot;)); } catch (Exception e) { throw new Error(e); } }} 从源码中可知每个Node节点拥有两个属性： item：节点存储的数据 next：下一个节点 其余的一些方法则是采用CAS算法对item属性和next属性进行修改。 接下来看ConcurrentLinkedQueue的关键属性和方法的一些相关源码： 12345678public class ConcurrentLinkedQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements Queue&lt;E&gt;, java.io.Serializable { private transient volatile ConcurrentLinkedQueue.Node&lt;E&gt; head; private transient volatile ConcurrentLinkedQueue.Node&lt;E&gt; tail; public ConcurrentLinkedQueue() { head = tail = new ConcurrentLinkedQueue.Node&lt;E&gt;(null); }} 从ConcurrentLinkedQueue的构造方法可知当初始化Queue时，将会创建一个Node节点并且将head和tail都指向这个节点。ConcurrentLinkedQueue中包含head和tail属性，分别代表头节点和尾节点，一条完整的队列的数据结构如图所示： 接下来则是一些常用方法介绍，他们的实现原理无非是采用CAS的方法新增节点或者删除节点，所以这里只进行大致介绍不进行详细讲解： add(E e)：添加元素到队列尾部。（它依托offer实现） offer(E e)：添加元素到队列尾部，由于ConcurrentLinkedQueue是无界的所以此方法永远会成功。 poll()：弹出队列头部元素，如果队列为空，则返回null。 peek()：获取队列头部元素，但不弹出该元素，如果队列为空，则返回null。 isEmpty()：判断队列是否为空，如果为空返回true，否则返回false。 size()：获取队列中元素的个数，由于CAS并没有加锁，所以使用size方法到返回结果期间可能会有元素的增删，从而导致元素个数的不精准。 remove(Object o)：移除队列中的指定元素，如果成功返回true，否则返回false，此方法和size方法一样结果也不是那么精确，同理。 contains(Object o)：判断队列中是否包含指定元素，如果包含返回true，否则返回false。 LinkedBlokingQueue上面介绍了基于CAS算法实现的非阻塞队列CurrentBlokingQueue，下面来介绍一下LinkedBlokingQueue。 LinkedBlokingQueue类图结构 LinkedBlokingQueue也是使用单向链表实现的，链表中的每个节点都对应一个内部类Node对象。 关节的一些属性： head：头节点 last：尾节点 count：链表元素的个数，关于count的操作都是原子性的，对比ConcurrentLinkedQueue的size方法，此方法是线程安全的。 putLock：控制入队的原子性，当执行put、offer等操作时需要获取putLock锁，从而保证同时只有一个线程可以操作链表尾节点。 takeLock：控制出队的原子性，当执行take、poll等操作时需要获取到takeLock锁，从而保证同时只有一个线程可以操作链表头节点。 notEmpty：当队列为空时，执行出队操作的线程将会被放入这个条件队列进行阻塞 notFull：当队列满时，执行入队操作的线程将会被放入这个条件队列进行阻塞 ArrayBlockingQueue本节主要讲解下面ArrayBlockingQueue的具体实现，在了解过LinkedBlockingQueue的实现之后学习ArrayBlockingQueue会觉得后者的实现简单了许多。","link":"/2023/03/17/2023-04-04-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%B3%BB%E5%88%97%E4%B9%8B%E5%B9%B6%E5%8F%91%E9%98%9F%E5%88%97%E8%AF%A6%E8%A7%A3/"},{"title":"JVM之新一代垃圾回收器ZGC","text":"新一代垃圾回收ZGC垃圾回收器介绍垃圾回收器组合 垃圾收集器组合相信很多人都看到过上面这张图，这就是垃圾回收器的组合使用的方案。（来自《深入理解Java虚拟机：JVM高级特性与最佳实践》） Serial与Serial Old垃圾回收器介绍简介 Serial Serial Old 简介 HotSpot中Client模式下的默认新生代垃圾收集器 Client模式下的默认老年代垃圾收集器 回收方式 采用复制算法、串行回收和”Stop-the-world”机制的方式执行内存回收 标记-压缩算法、串行回收和”Stop-the-world”机制 回收区域 新生代 老年代 串行回收：同一时间段内只允许有一个CPU用于执行垃圾回收操作，此时工作线程被暂停，直至垃圾收集工作结束 Serial是单线程的收集器，但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束（Stop The World） 设置在HotSpot虚拟机中，使用-XX:+UseSerialGC参数可以指定年轻代和老年代都使用串行收集器也就是新生代使用Serial GC其老年代使用Serial Old GC。 总结 在限定单个CPU的环境下，Serial收集器没有线程交互的开销，是个不错的选择，可以获得最高的单线程收集效率 对于交互较强的应用而言，Serial收集器是不能接受的 现在已经不用串行的了 Serial/SerialOld和PS垃圾回收器对比 单线程Serial/SerialOld：无论新生代和老年代的垃圾回收都是采用单线程进行回收，并且会阻塞应用线程，发生STW。 Parallel Scavenge/Parallel Old（PS）：吞吐量优先，新生代和老年代的回收采用多线程，但是会阻塞应用线程，发生STW。它也是JDK8中默认的垃圾回收组合。 CMS垃圾回收器（只回收老年代）CMS回收过程CMS的垃圾回收过程可以分为初始标记、并发标记、重新标记、和并发清理。 初始标记：标记和根对象有直接关联的对象，会STW，因为与根直接关联的对象比较少，所以暂停时间比较短。 并发标记：并发标记是标记所有的对象，往往耗时会比较长，但是发送并发标记时，GC线程和应用线程可以同时进行所以不会发生STW 重新标记：因为并发标记时，因为应用线程未停止，所以会发生误标记的情况，所以需要进行重新标记，将误标记进行修复，但是重新标记将会发生STW，但是往往耗时较短。 并发清理：当发生并发清理时，GC线程和应用线程也是并发执行，因为CMS采用标记清除算法，不需要暂停程序。 缺点内存碎片问题：当出现内存碎片无法分配大的对象时，CMS垃圾回收期会降级成Serial Old垃圾回收器。当出现这种情况时，服务端会产生很长的停顿时间。 ZGC垃圾回收器 JDK推出的一款低延迟垃圾回收器 支持4TB级别的堆（JDK13已支持到了16TB） 停顿时间不会超过10ms，且不会随着堆的大小增加而增加 TODO","link":"/2023/04/08/2023-04-08-JVM%E4%B9%8B%E6%96%B0%E4%B8%80%E4%BB%A3%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8ZGC/"},{"title":"分布式理论——2PC和3PC","text":"为了解决分布式系统的一致性问题，在长期的研究探索过程中，业内涌现出了一大批经典的一致性协议和算法，其中比较著名的有二阶段提交协议（2PC），三阶段提交协议（3PC）和 Paxos 、Raft、Zab等算法。 两类一致性算法： 2PC 3PC 协议用于保证属于多个数据分片上的操作的原子性。这些数据分片可能分布在不同的服务器上，2PC 协议保证多台服务器上的操作要么全部成功，要么全部失败。 Paxos Raft Zab 协议用于保证同一个数据分片的多个副本之间的数据一致性。当这些副本分布到不同的数据中心时，这个需求尤其强烈。 2PC3PC","link":"/2023/05/05/2023-05-05_%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA%E2%80%94%E2%80%942PC%E5%92%8C3PC/"},{"title":"并发编程系列之Java内存模型","text":"背景在并发编程中，有两个关键的问题： 线程之间如何通信 线程之间如何同步 线程通讯通常有两种解决方法： 共享内存：线程之间有公共状态，通过写-读内存中的公共状态进行隐式通讯。 消息传递：线程之间必须通过发送消息来显式通讯。 线程同步在共享内存并发模型中同步是显式进行的，程序员必须显式指定某个方法或者某段代码需要线程之间互斥执行。 而在消息传递的并发模型中，由于消息的发送必须在消息接收之前，所以同步时隐式进行的。 Java的内存模型采用的是共享内存模型，线程之间是隐式通讯，整个通讯过程对程序员是隐藏的，如果不理解隐式的通信机制，很有可能会遇到各种内存可见性问题。 重排序在执行程序时，为了提高性能，编译器和处理器通常会对指令进行排序。 JMMCPU和DISK之前处理效率存在很大的差距，所以引入了高速缓冲区，CPU直接操作高速缓冲区，然后高速缓冲区批次将操作同步到Disk中，这样如果多核CPU就会存在内存一致性问题，操作系统通过MESI类型的协议解决此问题。 像c、c++类似编程语言是直接面向操作系统的语言，所以直接对底层内存进行操作，所以直接复用上述解决方案。 而Java因为是跨平台的的语言，所以在不同的操作系统之上抽象了一层JMM进行内存管理。 JMM其实是一种并发编程的规范，抽象了线程于主内存之间的关系。 。。。 Happens-beforeJMM中有happens-before关系，其实就是说如果满足 a happens-before b关系，那么a的操作对b一定是可见的，不满足happens-before关系，编译器以及操作系统会对它的指令进行重排序。 虽然说就算满足happens-before也会进行重排序，但是只有不影响最终结果时才会进行重排序。 as-if-serial不管怎么重排序，单线程的执行结果都不能被改变，编译器、处理器都必须遵守as-if-serial语义。","link":"/2023/05/01/2023-05-01_%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%B3%BB%E5%88%97%E4%B9%8BJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"},{"title":"CAP原理","text":"CAP原理笔记 CAP原理是分布式领域的基石。 C:Consistent 一致性指强一致性，分布式系统中的所有节点在同一时刻具有同样的值、都是最新的数据副本，一致性保证了不管向哪台服务器写入数据，其他的服务器能实时获取到数据。A:Availability 可用性可用性就是无论何时都能提供服务，不会因为故障而停止服务。P:Partition tolerance 分区容忍性一个分布式系统里面，可能因为一些故障，使得节点之间网络断开，此时网络就分为了多块区域，数据则散布在了这些不连通的区域中，这就叫网络分区。而分区容忍性就是说分布式系统中，能够接受网络分区的情况发生。 实际上就在尽可能保证P的基础之上，保证C或A的其中一个，所以CAP实际上只有AP和CP两种选项。","link":"/2023/06/01/2023-04-15_CAP%E5%8E%9F%E7%90%86/"},{"title":"如何阅读源码","text":"分享一些阅读源码的一些经验… 为什么我们要阅读源码？TODO 如何阅读源码？我平常工作中对一些开源项目二开以及业余时间对中间件的学习，对于如何阅读源码相对来说还是有一定的经验，也有一套个人的方法论，在早期看源码基本上都是参考网上的一些博客文章一行一行的硬啃，网上源码分析相关的文章多不胜数，但是对于如何阅读源码的技巧确实少之又少，所以我在这里分享一下个人阅读源码的一些小技巧。 预研背景知识当我们要阅读一个复杂工程的源码时，我觉得我们首先要了解这个工程的业务背景，即明确它旨在解决何种具体问题及其应用场景。这是因为业务背景决定了工程的整体目标和功能需求，这对于正确解读源码的实际意义至关重要。 了解整体架构按层次阅读然后在理解它的大体架构与基本流程。我早期看源码其实直接就是对着一个功能点硬啃，然后一行一行写注释，其实这种方式乏味又低效，因为你没有一个整体的全局观，有些操作你觉得你懂了，其实你并没懂，你懂的是这行代码是干什么的，但是并不理解这行代码对于整体工程的影响，并且以这种方式阅读代码时，过不了几个月你又忘了，回头来看又得重新开始，如果你在理解大体架构与基础流程的基础之上来阅读源码，一个是会加深你的记忆的，第二个是就算忘记，你也能大致猜出这块代码是干什么的。 结合上下文借助外部工具互动交流适当跳读动手实践总结一下对于能看懂的源码无非是： 当理解这个功能的需求背景以及技术背景后，基本上脑海已经对改功能点有一个大致的实现方案，然后再去看源码，其实是对自身内心的实现方案的一个验证，而不是毫无头绪的瞎串，并且当我们自身内心有一个大致的实现方案之后，看到一些较为复杂的逻辑时，由于我们内心对此逻辑有一个大致的推测，我们便可将该逻辑当作一个黑盒，从而不会被错综复杂的分支搅乱了头脑。 例如我在阅读opennms通过lldp协议去生成网络拓扑图时，其实代码并不复杂，但是因为我对于lldp协议的不了解，导致我并不知道作者这样做的真正意图，被代码绕昏了头，后续当我了解了相关技术背景之后，一切便迎刃而解。 就算理解了相关功能背景之后，由于自身对它不是十分熟悉，所以在阅读源码时难免还是会遇到不懂的地方。 我常用的几种方式: 首先看官网，看官网，看官网，重要的事情说三次，看有没有相关功能的说明 看此commit log，往往关联了相应的issue，我们可以从issue中了解作者的真正意图 可以在仓库提issue向开发者提问，说出你的猜想以及你的疑问 对于国内开发的开源项目，往往提供了钉钉群之类的交流渠道，我们也可以去这些地方提问 如果还不行的话，老哥先跳过这一段把-。-！，咱先不管他。 例如我看Dubbo 3.0的负载均衡算法时，发现这个一致性哈希算法中的实现，和我内心预期不一致，官网也没找到特别的说明，后续我时通过commit log找到了对应的issue，发现Dubbo已经把强一致性哈希算法调整为有界负载的一致性哈希算法，当我了解有界负载的一致性哈希算法后，再来看代码，too easy~ 对上述知识进行总结：","link":"/2023/05/14/2023-05-14_%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E6%BA%90%E7%A0%81/"},{"title":"2023-04-03_Comparable和Comparator的区别.md","text":"最近再看阻塞队列，看到PriorityBlockingQueue发现Comparable 和 Comparator我竟然忘记了有什么区别… 所以写篇文章记录下~ 一、Comparable简介 Comparable是排序接口。若一个类实现了Comparable接口，就意味着该类支持排序。实现了Comparable接口的类的对象的列表或数组可以通过Collections.sort或Arrays.sort进行自动排序。 此外，实现此接口的对象可以用作有序映射中的键或有序集合中的集合，无需指定比较器。该接口定义如下： 123456package java.lang;import java.util.*;public interface Comparable&lt;T&gt; { public int compareTo(T o);} 此接口只有一个方法compare，比较此对象与指定对象的顺序，如果该对象小于、等于或大于指定对象，则分别返回负整数、零或正整数。 现在我们假设一个Person类，代码如下： 1234567@NoArgsConstructor@AllArgsConstructor@Datapublic class Person { private String name; private int age;} 现在有两个Person类的对象，我们如何来比较二者的大小呢？我们可以通过让Person实现Comparable接口： 123456789101112131415161718192021222324252627@NoArgsConstructor@AllArgsConstructor@Datapublic class Person implements Comparable&lt;Person&gt; { private String name; private int age; @Override public int compareTo(Person o) { return this.age - o.age; } public static void main(String[] args) { Person[] people = new Person[] {new Person(&quot;xujian&quot;, 20), new Person(&quot;xiewei&quot;, 10)}; System.out.println(&quot;排序前&quot;); for (Person person : people) { System.out.print(person.getName() + &quot;:&quot; + person.getAge() + &quot;\\n&quot;); } Arrays.sort(people); System.out.println(&quot;\\n排序后&quot;); for (Person person : people) { System.out.print(person.getName() + &quot;:&quot; + person.getAge() + &quot;\\n&quot;); } }} 程序执行结果为： 二、Comparator简介 Comparator是比较接口，我们如果需要控制某个类的次序，而该类本身不支持排序(即没有实现Comparable接口)，那么我们就可以建立一个“该类的比较器”来进行排序，这个“比较器”只需要实现Comparator接口即可。也就是说，我们可以通过实现Comparator来新建一个比较器，然后通过这个比较器对类进行排序。该接口定义如下： 123456package java.util;public interface Comparator&lt;T&gt; { int compare(T o1, T o2); boolean equals(Object obj); } 注意： 若一个类要实现Comparator接口：它一定要实现compare(T o1, T o2) 函数，但可以不实现 equals(Object obj) 函数。 int compare(T o1, T o2) 是“比较o1和o2的大小”。返回“负数”，意味着“o1比o2小”；返回“零”，意味着“o1等于o2”；返回“正数”，意味着“o1大于o2”。 现在一个User类没有实现Comparable接口，该如何比较大小呢？我们可以新建一个类，让其实现Comparator接口，从而构造一个“比较器”。 123456public class UserComparator implements Comparator&lt;User&gt; { @Override public int compare(User o1, User o2) { return o1.getAge() - o2.getAge(); }} 现在我们就可以利用这个比较器来对其进行排序： 1234567891011121314151617181920212223@NoArgsConstructor@AllArgsConstructor@Datapublic class User { private String name; private int age; public static void main(String[] args) { User[] users = new User[] {new User(&quot;xujian&quot;, 20), new User(&quot;xiewei&quot;, 10)}; System.out.println(&quot;排序前&quot;); for (User user : users) { System.out.print(user.getName() + &quot;:&quot; + user.getAge() + &quot;\\n&quot;); } Arrays.sort(users, new UserComparator()); System.out.println(&quot;\\n排序后&quot;); for (User user : users) { System.out.print(user.getName() + &quot;:&quot; + user.getAge() + &quot;\\n&quot;); } }} 程序运行结果为： 三、Comparable和Comparator区别比较Comparable接口是一种内置排序机制，它的名称以”-able”结尾，意味着实现此接口的类具有自我排序的能力。当一个类实现Comparable接口时，表明这个类的实例之间可以进行自然排序。 相比之下，Comparator接口以”-or”结尾，表示其扮演的是比较过程中的参与者角色，即比较器。通过实现Comparator接口，我们可以创建一个自定义的比较器来控制特定类实例的排序方式，无需修改类的源代码。 总结来说： Comparable接口就像是“内建比较器”，适用于那些本身具备固有排序规则的对象，实现简单，但要求修改原始类代码。 Comparator接口则是“外部比较器”，提供了一种灵活的方式，在不修改原有类结构的前提下为对象定义排序规则。这种方式尤其适用于需要复杂或特定排序逻辑的情况，可以避免重复编码，提高代码复用性。","link":"/2023/04/03/2023-08-03_Comparable%E5%92%8CComparator%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"并发编程之阻塞队列","text":"讲解并发编程常见的阻塞队列 队列队列（Queue）是一种经常使用的集合，它实际上是实现了一个先进先出（FIFO：First In First Out）的有序列表。它和List、Set同样都是继承Collection。 Queue与List的区别： List：可以在任意位置添加和删除元素。 Queue：只能在队头和队尾添加和删除元素。 Java中的有一个队列接口——Queue，它主要基于Collection的基础上定义队列基本的添加以及移除方法的定义。 阻塞队列阻塞队列，故名思意，首先它是一个队列，并且它在一定情况下阻塞。 例如上图，Thread1往阻塞队列添加元素，Thread2往阻塞队列移除元素。 当阻塞队列满时，添加元素操作将会阻塞。 当阻塞队列为空时，移除操作将会被阻塞 Java中内置阻塞队列接口——BlockingQueue ，它主要继承Queue，在Queue的基础之上定义了可阻塞添加、删除元素的方法，核心方法如下： 方法类型 抛出异常 返回特殊值 一直阻塞 超时退出 插入 add(e) offer(e) put(e) offer(e,time,unit) 移除（取出） remove() poll() take() poll(time,unit) 检查 element() peek() 不可用 不可用 BlockingQueue的类图如下所示： JDK常用的阻塞队列BlockingQueue 是个接口，需要使用它的实现之一来使用 BlockingQueue，java.util.concurrent 包下具有以下 BlockingQueue 接口的实现类： JDK 提供了 7 个阻塞队列。分别是 ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列 LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列 PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列 DelayQueue：一个使用优先级队列实现的无界阻塞队列 SynchronousQueue：一个不存储元素的阻塞队列 LinkedTransferQueue：一个由链表结构组成的无界阻塞队列（实现了继承于 BlockingQueue 的 TransferQueue） LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列 ArrayBlockingQueueArrayBlockingQueue是一种基于数组实现的有界队列，遵循先进先出（FIFO）原则来排列存放的元素。默认情况下，该队列在处理线程访问时并不保证公平性，也就是说，当队列空闲时允许线程访问时，并不总是优先给予等待时间最长的线程访问权，导致的结果可能是先等待的线程反而后取得队列的访问。 为了让所有线程按照阻塞的先后顺序公平地访问队列，可以设置ArrayBlockingQueue为公平模式。在公平模式下，尽管能保证每个线程公平地排队等待，但可能会牺牲一定的并发效率。想要创建一个公平的ArrayBlockingQueue，可以采用特殊的构造函数实现，代码如下： 1ArrayBlockingQueue fairQueue = new ArrayBlockingQueue(1000,true); 它的公平性主要是依赖ReentrantLock实现的，源码如下： 12345678public ArrayBlockingQueue(int capacity, boolean fair) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition();} ArrayBlockingQueue主要利用ReentrantLock的条件锁来实现入队、出队阻塞的，主要核心就是一把锁，两个条件，源码如下： 123456789101112131415161718192021//数据元素数组final Object[] items;//下一个待取出元素索引int takeIndex;//下一个待添加元素索引int putIndex;//元素个数int count;//内部锁final ReentrantLock lock;//消费者private final Condition notEmpty;//生产者private final Condition notFull; public ArrayBlockingQueue(int capacity, boolean fair) { ... lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition();} notEmpty：消费者条件，如果不为空则可以进行取元素。 notFull：生产者条件，如果不为空，则可以存元素。 put操作1234567891011121314151617181920212223242526272829public void put(E e) throws InterruptedException { //检查是否为空 checkNotNull(e); final ReentrantLock lock = this.lock; //获取自选锁 lock.lockInterruptibly(); try { //阻塞队列已满，则将生产者挂起，等待消费者唤醒 while (count == items.length) notFull.await(); // 进入阻塞队列 enqueue(e); } finally { lock.unlock(); }} private void enqueue(E x) { // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; //将值放入队列 items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; //唤醒生产者 notEmpty.signal();} take总结1234567891011121314151617181920212223242526272829303132public E take() throws InterruptedException { final ReentrantLock lock = this.lock; //自选获取锁 lock.lockInterruptibly(); try { //如果队列为空，则消费者挂起 while (count == 0) notEmpty.await(); //获取队列值 return dequeue(); } finally { lock.unlock(); }}private E dequeue() { // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings(&quot;unchecked&quot;) //获取值 E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); //唤醒生产者 notFull.signal(); return x;} 总结对于ArrayBlockingQueue进行简单的总结 拿到线程竞争lock锁，拿到了lock锁的线程进入下一步，没有拿到lock锁的线程自旋竞争锁。 取元素，判断队列是否为空 如果为空，notEmpty挂起 如果不为空，则尝试获取元素，再唤醒notFull 存元素，判断队列是否满 如果满，则notFull挂起 如果不满，则元素入队，再唤起notEmpty LinkedBlockingQueueLinkedBlockingQueue是一个基于单向链表并且可设置容量的阻塞队列。LinkedBlockingQueue中的元素都是按照FIFO即先进先出的元素排列的，在队列头部的元素是在队列中停留时间最长的元素，相反在队列尾部的元素是则是在队列中停留时间最短的元素。元素是从队列尾部新增进入队列的，而获取元素是从队列头部开始获取的。 LinkedBlockingQueue是一个由链表实现的有界队列阻塞队列，但大小默认值为Integer.MAX_VALUE，所以我们在使用LinkedBlockingQueue时建议手动传值，为其提供我们所需的大小，避免队列过大造成机器负载或者内存爆满等情况。其构造函数如下 123public LinkedBlockingQueue() { this(Integer.MAX_VALUE);} 无参构造器调用的是另一个带容量参数的构造器，也就是说调用无参构造器返回的是一个容量为Integer.MAX_VALUE的队列，也就相当于一个无界队列。 12345public LinkedBlockingQueue(int capacity) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; last = head = new Node&lt;E&gt;(null);} 一般情况下建议使用这个带容量参数的队列来构造有界阻塞队列，因为如果往队列中新增元素的速度远远超过从队列中获取元素的速度，那么在使用无参构造器的情况下这个阻塞队列很有可能会在段时间内达到Integer.MAX_VALUE大小，就很有可能造成内存溢出。 12345678910111213141516171819public LinkedBlockingQueue(Collection&lt;? extends E&gt; c) { this(Integer.MAX_VALUE); final ReentrantLock putLock = this.putLock; putLock.lock(); // Never contended, but necessary for visibility try { int n = 0; for (E e : c) { if (e == null) throw new NullPointerException(); if (n == capacity) throw new IllegalStateException(&quot;Queue full&quot;); enqueue(new Node&lt;E&gt;(e)); ++n; } count.set(n); } finally { putLock.unlock(); }} 通过这个构造器默认情况下也是创建一个容量为Integer.MAX_VALUE的队列，利用循环向队列中添加指定集合中的元素。 12345678910111213141516171819202122232425262728293031323334353637383940/** * 默认构造方法，队列容量为Integer.MAX_VALUE */public LinkedBlockingQueue() { this(Integer.MAX_VALUE);}/** * 指定队列容量的构造方法 */public LinkedBlockingQueue(int capacity) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; // 初始化链表的头尾节点 last = head = new Node&lt;E&gt;(null);}/** * 基于集合构建队列，默认容量为Integer.MAX_VALUE */public LinkedBlockingQueue(Collection&lt;? extends E&gt; c) { this(Integer.MAX_VALUE); final ReentrantLock putLock = this.putLock; putLock.lock(); // Never contended, but necessary for visibility try { int n = 0; for (E e : c) { if (e == null) throw new NullPointerException(); if (n == capacity) throw new IllegalStateException(&quot;Queue full&quot;); enqueue(new Node&lt;E&gt;(e)); ++n; } count.set(n); } finally { putLock.unlock(); }} LinkedBlockingQueue内部是通过两把ReentrantLock锁来分别对新增、获取这种操作进行限制的。 1234567private final ReentrantLock takeLock = new ReentrantLock();private final Condition notEmpty = takeLock.newCondition();private final ReentrantLock putLock = new ReentrantLock();private final Condition notFull = putLock.newCondition(); takeLock代表的是在执行take, poll等获取操作时当前线程必须锁持有的锁 notEmpty代表的是如果在执行take, poll等获取操作时如果队列为空，那么当前线程应该阻塞在这个Condition上直到队列不为空为止 putLock代表的是在执行put, offer等新增操作时当前线程必须锁持有的锁 notFull代表的是如果在执行put, offer等新增操作时如果队列已经满了，那么当前线程应该阻塞在这个Condition上直到队列空间可用为止 put方法123456789101112131415161718192021222324252627282930313233343536373839404142public void put(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { // 如果队列满了则阻塞在此 while (count.get() == capacity) { notFull.await(); } // 元素入队 enqueue(node); // 当前元素数量自增加一，注意getAndIncrement方法返回的是自增前的值 c = count.getAndIncrement(); // c+1代表此时队列中的数量，如果还没有超过容量则 // 唤醒上一个因为队列已满而无法往队列新增元素导致阻塞在这个 // notFull上的线程 if (c + 1 &lt; capacity) notFull.signal(); } finally { // 真正的signal是在这一步发生的 putLock.unlock(); } // 走到这里如果c==0说明c = count.getAndIncrement(); // 这行代码执行成功了，也就是现在队列中至少有一个元素了， // 那么就通知获取元素的线程开始运行 if (c == 0) signalNotEmpty();}private void signalNotEmpty() { final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try { notEmpty.signal(); } finally { takeLock.unlock(); }} task总结1234567891011121314151617181920212223242526272829303132public E take() throws InterruptedException { E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try { while (count.get() == 0) { notEmpty.await(); } x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); } finally { takeLock.unlock(); } if (c == capacity) signalNotFull(); return x;}private E dequeue() { Node&lt;E&gt; h = head; Node&lt;E&gt; first = h.next; h.next = h; // help GC head = first; E x = first.item; first.item = null; return x;} 在理解了put方法的原理之后，take方法的原理也是大同小异，只不过是换了一把take锁而已。整个take方法的执行流程如下： take锁加锁 如果队列是空的则阻塞 调用出队方法dequeue 如果此时队列中至少还有一个元素则调用 notEmpty.signal();唤醒其它执行take方法阻塞的线程。注意getAndDecrement方法是先get再递减，返回的是递减前的值 take锁释放锁，唤醒阻塞线程其实是在这一步发生的，不懂的可以看我之前写的Condiotion文章。 c == capacity为true代表c = count.getAndDecrement();这行代码执行成功了，这里需要注意getAndDecrement方法是先获取再递减，所以返回值是这次take成功前队列中元素的数量。那为什么是take前队列已满的情况下再通知put线程呢？难道take前队列还未满就不用通知了吗？这是因为独占锁的原因，同一时刻只会有一个线程去put，而put线程被阻塞的条件是队列已满，如果这次take前队列未满就不会有put线程被阻塞了，所以只会在take前队列已满的情况下再去唤醒上一个被阻塞的put线程。 take方法的大体流程如上所示，与put方法没有什么太大的区别。我们只需要关注一下元素是如何出队的就可以了 LinkedBlockingQueue是一个基于单向链表并且可设置容量的阻塞队列。LinkedBlockingQueue中的元素都是按照FIFO即先进先出的元素排列的，在队列头部的元素是在队列中停留时间最长的元素，相反在队列尾部的元素是则是在队列中停留时间最短的元素。元素是从队列尾部新增进入队列的，而获取元素是从队列头部开始获取的。但是head节点本身是不持有元素的，他仅仅扮演了一个哨兵的角色。LinkedBlockingQueue中有两把ReentrantLock分别对应put和take这两个语义，这两种操作单独执行都是独占相应锁的，但是put和take方法相互间是可以并行执行的，即A线程执行put操作与B线程执行take操作是可以同时执行的。 PriorityBlockingQueuePriorityBlockingQueue是带优先级的无界阻塞队列，每次出队都返回优先级最高的元素，基于二叉树最小堆实现。 PriorityBlockingQueue 与其他阻塞队列最大的不同就是：它是一种优先级队列，也就是说元素并不是以 FIFO 的方式出/入队，而是以按照权重大小的顺序出队。 PriorityBlockingQueue 表面上看是无界队列，但其有最大容量的限制（Integer.MAX_VALUE - 8）。只是其在初始化时并不会限制其最大容量，而是在需要的时候自动扩容。 由于 PriorityBlockingQueue 是按照元素的权重进入排序，所以队列中的元素必须是可以比较的，也就是说元素必须实现 Comparable 接口。 由于 PriorityBlockingQueue 无界队列，所以插入元素永远不会阻塞线程。 二叉堆总结底层采用二叉堆来实现（默认最小堆），如果A&lt;B，那么A比较B小于0，那么A将会排在堆顶，最优先处理","link":"/2023/06/21/2023-06-21_%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%B3%BB%E5%88%97%E4%B9%8B%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97/"},{"title":"分布式理论系列","text":"分布式理论系列笔记","link":"/2023/06/01/2023-06-01_%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA%E7%B3%BB%E5%88%97/"},{"title":"RabbitMQ持久化机制","text":"持久化机制在各个中间件中都是举足轻重的一个功能点，持久化可以提高应用的可靠性，防止应用在重启、关闭、宕机情况下数据丢失。本文将会对RabbitMQ的持久化分为三个部分：分别是交换机、队列、消息的持久化。 交换机的持久化交换机的持久化是在声明交换机时通过durable（durable=true则持久化）参数进行设置的，如果交换机不设置持久化，那么在RabbitMQ服务重启后，相关交换机的元数据都会丢失。示例声明如下: 1234@Beanpublic DirectExchange directExchange() { return new DirectExchange(DIRECT_EXCHANGE, true, false);} 队列的持久化队列的持久化是通过在声明队列时通过durable（durable=true则持久化）参数进行设置的，如果队列不进行持久化，那么在RabbitMQ重启时，相关队列的元数据以及存储在队列里的消息将会丢失。示例声明如下： 1234@Beanpublic Queue directQueue() { return new Queue(DIRECT_QUEUE, true);} 消息的持久化队列的持久化能保证其本身的元数据不会因异常情况而丢失，但是并不能保证内部所存储的消息不会丢失。要确保消息不会丢失需要将其设置为持久化。通过将消息的投递模式设置为PERSISTENT，示例代码如下： 123456789101112@Testvoid sendPersistentMsg() { MessageProperties messageProperties = new MessageProperties(); // 设置持久化投递模式 messageProperties.setDeliveryMode(MessageDeliveryMode.PERSISTENT); Message rabbitMessage = MessageBuilder .withBody(&quot;发送一条消息&quot;.getBytes()) .andProperties(messageProperties) .build(); rabbitTemplate.send(RabbitConfig.DIRECT_EXCHANGE, RabbitConfig.DIRECT_ROUTING_KEY, rabbitMessage);} 当将投递模式设置为PERSISTENT时，重启RabbitMQ，消息依旧存在，如果单单只设置队列持久化，重启之后消息便会丢失，如果单单只对消息进行持久化，重启后队列则会消息，消息也会跟着丢失，所以如果要现实对消息的持久化那么队列和消息都要进行持久化。 注意：可以将所有的消息都设直为持久化，但是这样会严重影响 RabbitMQ 的性能(随机)。写入磁盘的速度比写入内存的速度慢得不只一点点。对于可靠性不是那么高的消息可以不采用持久化处理以提高整体的吞吐量。在选择是否要将消息持久化时，需要在可靠性和吐吞量之间做一个权衡。 那么如果将队列、消息都设置为持久化后，就能保证消息百分百的不丢失了嘛？ 答案是否定的，首先从消费者来说，如果在订阅消费队列时将 autoAck 参数设置为 true ，那么 当消费者接收到相关消息之后，还没来得及处理就看机了，这样也算数据丢失。这种情况很好解决，将autoAck 参数设置为 false 并进行手动确认。 其次，在持久化的消息正确存入 RabbitMQ 之后，还需要有一段时间(虽然很短，但是不可忽视〉才能存入磁盘之中。 RabbitMQ 并不会为每条消息都进行同步存盘(调用内核的 fsync方法)的处理，可能仅仅保存到操作系统缓存之中而不是物理磁盘之中。如果在这段时间内RabbitMQ 服务节点发生了岩机、重启等异常情况，消息保存还没来得及落盘，那么这些消息将会丢失。 那么这个问题到底应该怎么解决呢?这里可以引入 RabbitMQ 镜像队列机制，相当于配置了副本，如果主节点 master 在此特殊时间内挂掉，可以自动切换到从节点 slave ), 这样有效地保证了高可用性，除非整个集群都挂掉。虽然这样也不能完全保证 RabbitMQ 消息不丢失，但是配置了镜像队列要比没有配置镜像队列的可靠性要高很多，在实际生产环境中的关键业务队列一般都会设置镜像队列。","link":"/2023/07/08/2023-07-03-RabbitMQ%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/"},{"title":"Kubernetes","text":"Kubernetes笔记 Kubernetes架构api server：所有服务访问的统一入口 replication controller：管理副本的期望数量 scheduler：选择合适的节点进行任务分配 etcd：整个kubernetes的存储系统，一个分布式的键值存储服务 kubelet：kubelet和容器引擎进行交互，实现容器的生命周期管理 kube proxy：负责写入规则至iptables或ipvs实现服务映射访问（TODO不是十分理解！） kubectl：命令行工具 kubernetes重要组件coredns:可以为集群中的svc创建一个域名ip的对应解析 dashboard：给k8s提供一个b/s结构的访问体系 ingress controller：官方的只能实现4层代理，ingress可以实现7层代理 fedetation：提供一个可以跨集群中心多k8s的统一管理的功能 prometheus：提供k8s的集群监控能力 elk：提供k8s集群日志统一分析接入平台 pod的概念 自主性pod：不被k8s管理的pod 控制器管理的pod： 网络通讯方式 k8s的网络模型假定了所有Pod都在一个可以直接连通的扁平网络空间中，这在GCE中是现成的网络模型，k8s假定这个网络已经存在，而在私有云中搭建k8s集群，需要自己实现这个网络假设，将不同节点上的Docker容器之间的互相访问先打通，然后运行k8s。 资源清单名称空间级别 集群级别 元数据 Pod的生命周期安全认证 HTTP Token认证机制 HTTP Base认证机制 HTTPS的双向认证 鉴权RBACRBAC基于角色的访问控制，在kubernetes1.5版本引入，现已成为默认标准。它的优势如下： 覆盖集群中的资源和非资源属性 整个RBAC由几个对象完成，可以使用Kubectl和Api进行操作 可以在运行时调整 使用RBAC在启动api-server时将--authorization-mode资源设置为一个逗号分隔的列表并确保其包含RBAC。 1kube-apisever --authorization-mode=RBAC API对象RBAC中声明四种对象：Role、ClusterRole、RoleBinding、ClsterRoleBinding。 Role和ClusterRoleRBAC的Role和ClusterRol他们的权限是存粹累加的。 Role用来在某个命名空间中设置访问权限，在创建Pole时，你必须指定该Role所属的命名空间。 ClsterRole则是一个集群作用域的资源。ClusterRole可以用来: 定义对某命名空间域对象的访问权限，并将在个别命名空间内被赋予访问权限。 为命名空间作用域内的对象设置访问权限，并被授予跨所有命名空间的访问权限。 为集群作用域的资源定义访问权限 如果要在命名空间内定义角色，则应该使用Role，如果需要在集群范围定义角色， 则应该使用ClsterRole。 实践Kubernetes集群有两类用户：由kubernetes管理的账号和普通账号。 普通账号：是由与Kubernetes无关的服务进行管理的，Kubernetes并不包含用来代表普通用户账号的对象，普通用户的信息无法通过API调用添加到集群中，但是Kubernetes仍然认为能够提供由集群的证书机构签名的合法证书的用户是通过身份认证的用户。 创建一个用户只能管理dev空间 创建devuser-csr.json文件，内容如下： 12345678910111213141516171819{ &quot;CN&quot;:&quot;devuser&quot;, &quot;hosts&quot;:[ ], &quot;key&quot;:{ &quot;algo&quot;:&quot;rsa&quot;, &quot;size&quot;:2048 }, &quot;names&quot;:[ { &quot;C&quot;:&quot;CN&quot;, &quot;ST&quot;:&quot;BeiJing&quot;, &quot;L&quot;:&quot;BeiJing&quot;, &quot;O&quot;:&quot;k8s&quot;, &quot;OU&quot;:&quot;System&quot; } ]} 下载证书生成工具，放/user/local/bin路径下 123456wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64mv cfssl_linux-amd64 /usr/local/bin/cfsslwget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64mv cfssljson_linux-amd64 /usr/local/bin/cfssljsonwget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64mv cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfo 生成证书（在/etc/kubernetes/pki创建密钥信息，/etcc/kubernetes/pki中存储的都是密钥信息） 12## -ca指定私钥证书，-ca-key指定私钥 以及请求的文件 -bare指定输出的用户名cfssl gencert -ca=ca.crt -ca-key=ca.key -profile=kubernetes /root/devuser-csr.json | cfssljson -bare devuser 成功生成 ca.crt、ca.key、devuser.csr文件。（现在还不知道这些文件到底是干嘛的~~~~） 生成kubeconfig 1234567891011121314151617181920212223242526## 设置kubernetes的api server地址export KUBE_APISERVER=&quot;https://192.168.0.200:6443&quot;## 生成kubeconfig，并配置相关认证信息 (基本参数：证书、kubernetes apiserver、kubeconfig name)kubectl config set-cluster kubernetes \\--certificate-authority=/etc/kubernetes/pki/ca.crt \\--embed-certs=true \\--server=${KUBE_APISERVER} \\--kubeconfig=devuser.kubeconfig## 再配置相关认证信息kubectl config set-credentials devuser \\&gt; --client-certificate=/etc/kubernetes/pki/devuser.pem \\&gt; --client-key=/etc/kubernetes/pki/devuser-key.pem \\&gt; --embed-certs=true \\&gt; --kubeconfig=devuser.kubeconfig## 创建dev namespace（下面需要用到）kubectl create namespace dev## 配置kubernetes上下文kubectl config set-context kubernetes \\--cluster=kubernetes \\--user=devuser \\--namespace=dev \\--kubeconfig=devuser.kubeconfig 至此我们成功生成了devuser.kubeconfig。 kubernetes集群中创建对应rolebingding绑定clusterrole(admin是自带的)并且绑定user和namespace 1kubectl create rolebinding devuser-admin-binding --clusterrole=admin --user=devuser --namespace=dev devuser账户进行请求时，带上devuser.kubeconfig 1234567891011# 在devuser用户下创建.kube文件mkdir /home/devuser/.kube# 将devuser.kubeconfig拷贝到devuser用户的.kube路径下cp devuser.kubeconfig /home/devuser/.kube/.kubeconfig# 授权chown devuser:devuser /home/devuser/.kube/.kubeconfig # 切换到devuser用户su devuser## 配置上下文，相当于告诉kubectl，当我请求kubernetes时，使用.kubeconfig的认证信息kubectl config use-context kubernetes --kubeconfig=/home/devuser/.kube/.kubeconfig OK k8s部署dashboardServiceHelm三大概念 Chart代表Helm包。它包含在Kubernetes集群内部运行应用程序，工具或服务所需的所有资源定义。 Repository用来存放和共享Chart的地方。 Release是运行在Kubernetes集群中的Chart实例，对于一个Chart可以运行多次，每次都会生成一个新的Release和Release name。 Helm安装Charts到Kubernetes集群中，每次安装都会创建一个新的release，你可以在Helm的chart repositories中寻找新的charts。","link":"/2023/09/18/2023-09-18_Kubernetes/"},{"title":"Docker与Harbor","text":"Docker与Harbor笔记 DockerTODO Docker整体架构图 TODO Docker整体交互图 Dockerfile描述Dockerfile是Docker镜像的描述文件，Docker内部包含了一条条指令，每一条指令构建一层，因此每一层指令的内容，就是描述该层该如何构建。 命令EXPOSE该命令告诉容器监听连接的端口。 只有容器监听了端口，通过-P参数向外部暴漏的端口才真正生效!!! Docker安装1、安装须知安装Docker内核建议3.10版本以上。 查看Linux内核 12[root@localhost ~]# uname -r3.10.0-1160.el7.x86_64 2、更新yum包1[root@localhost ~]# yum -y update 3、卸载旧版本Docker(如果之前安装过)1[root@localhost ~]# yum remove docker docker-common docker-selinux docker-engine 4、安装Docker详细步骤4.1、安装需要的软件包 yum-util 提供yum-config-manager功能 device-mapper-persistent-data、lvm2是devicemapper驱动的依赖 1[root@localhost ~]# yum install -y yum-utils device-mapper-persistent-data lvm2 4.2、设置yum源 中央仓库源 阿里仓库源 123[root@localhost ~]# yum-config-manager --add-repo http://download.docker.com/linux/centos/docker-ce.repo[root@localhost ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 4.3、查询docker版本并安装 查询docker版本 123456789101112[root@localhost ~]# yum list docker-ce --showduplicates | sort -r已加载插件：fastestmirror可安装的软件包 * updates: mirrors.ustc.edu.cnLoading mirror speeds from cached hostfile * extras: mirrors.ustc.edu.cndocker-ce.x86_64 3:20.10.9-3.el7 docker-ce-stabledocker-ce.x86_64 3:20.10.8-3.el7 docker-ce-stabledocker-ce.x86_64 3:20.10.7-3.el7 docker-ce-stabledocker-ce.x86_64 3:20.10.6-3.el7 docker-ce-stabledocker-ce.x86_64 3:20.10.5-3.el7 docker-ce-stable... 选择一个版本并安装：yum install docker-ce-版本号 1[root@localhost ~]# yum -y install docker-ce-18.03.1.ce 4.4、启动Docker并设置Docker 开机自启12[root@localhost ~]# systemctl start docker[root@localhost ~]# systemctl enable docker Docker安装完成~~~ Docker Compose 安装1、下载docker-compose1$ sudo curl -L &quot;https://github.com/docker/compose/releases/download/v2.2.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 2、将docker-compose二进制文件赋予可执行权限1$ sudo chmod +x /usr/local/bin/docker-compose 3、创建软链：1$ sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose 4、测试是否安装完成12$ docker-compose versioncker-compose version 1.24.1, build 4667896b Harbor安装教程1、下载Harbor安装包进行解压12$ wget https://github.com/goharbor/harbor/releases/download/v2.6.1/harbor-offline-installer-v2.6.1.tgz$ tar -zxvf harbor-offline-installer-v2.6.1.tgz 2、配置先复制一份harbor.yml.tmpl文件命名为harbor.yml 12# copy harbor文件$ cp harbor.yml.tmpl harbor.yml 配置harbor.yml文件，注释掉https的配置内容，配置http相关的参数，主要是hostname（本机的IP地址），port（harbor后台管理页面暴漏的端口）。 配置文件相关改动如下： 12345678910111213141516# 本机IP设置为192.168.0.203hostname: 192.168.0.203# port改为8081# http related confighttp: # port for http, default is 80. If https enabled, this port will redirect to https port port: 8081# 注释https相关内容# https related config# https: # https port for harbor, default is 443 # port: 443 # The path of cert and key files for nginx # certificate: /your/certificate/path # private_key: /your/private/key/path 注意：还有一些其他的配置，如果有需要的可以去了解一下。 例如Harbor Web端的访问地址，默认为Harbor12345，如果需要调整的话，可以自行修改相关的配置。 3、安装12$ ./prepare$ ./install.sh 4、执行docker-compose.yml，启动harbor服务1$ docker-compose up -d 5、访问Harbor地址——192.168.0.203:8081 至此安装完成啦。","link":"/2023/10/04/2023-10-04_Docker%E4%B8%8EHarbor/"},{"title":"RabbitMQ之生产者提交确认","text":"前一篇文章我们说到，可以通过持久化机制解决消息重启、宕机而引发的消息丢失问题，除此之外我们还会遇到一个问题就是当生产者把消息发送出去之后，默认情况下RabbitMQ Server是不会返回任何信息给生产者的，也就是说在默认情况下我们生产者并不知道消息有没有成功到达RabbitMQ Server，所以当出现网络异常或者RabbitMQ Server宕机的情况下，我们生产者是不感知的，那么就会出现消息丢失的情况。 RabbitMQ针对这个问题提出了两种解决方案： 事务机制 生产者确认机制 事务机制在RabbitMQ中原生RabbitMQ SDK中于事务相关的方法有三个：channel.txSelect、channel.txCommit、channel.txRollback。 channel.txSelect：用于将当前的channel设置为事务模式 channel.txCommit：用于提交事务 channel.txRollback:用于回滚事务 在通过channel.txSelect方法开启事务之后，便可以发布消息给RabbitMQ了， 如果事务提交成功，则消息到达了RabbitMQ中，如果在事务提交执行之前由于RabbitMQ异常崩溃或者其他原因抛出异常，这个时候我们便可以将其捕获，进而通过执行channel.txRollback方法来实现事务回滚。 工作流程： 示例代码如下： 12345678try ( channel.txSelect() ; // 发布消息 channel . txCommit() ; ) catch (Exception e) ( e.printStackTrace(); channel . txRollback();} 在SpringBoot中我们之需要使用Transactional注解就可以了，事务的开启、提交以及回滚SpringBoot都帮我们做了。示例代码如下： 1 注意：RabbitMQ的事务机制是同步的，也就是说当我们提交事务之后我们需要等待RabbitMQ Server的一个回调，然后才能继续发送下一条消息。 事务机制的确能帮我们解决生产者和RabbitMQ之间消息确认的问题，但是事务机制会吸干RabbitMQ的性能，所以生产者确认机制就应运而生了。 生产者确认机制","link":"/2023/07/04/2023-07-04-RabbitMQ%E4%B9%8B%E7%94%9F%E4%BA%A7%E8%80%85%E6%8F%90%E4%BA%A4%E7%A1%AE%E8%AE%A4/"},{"title":"Java并发编程队列","text":"主要讲解了Queue、BlockingQueue相关的类设计结构，以及一些常见的并发安全Queue。 前言JDK中提供了一系列的现场安全队列，按照实现方式的不同，分为： 阻塞队列 非阻塞队列 前者采用锁进行实现，而后者采用CAS非阻塞算法进行实现。 类结构 Collection：作为集合层次结构中的根接口，定义了集合的基本方法。 AbstractCollection：对Collection定义的部分方法进行实现，部分实现依赖未实现的抽象方法，类似于设计模式中的模板模式。 contains：依赖iterator方法（抽象的方法）实现判断是否包含。 remove：依赖iterator方法（抽象的方法）实现移除功能。 isEmpty：依赖size方法判断集合是否为空。 Queue：队列属于集合，所以Queue继承Collection，并且在Collection上进行增强，定义Queue相关的方法，如： offer：向队列尾部提供一个元素。 poll：向队列头部拉取一个元素。 peek：检索队列头部的元素，不删除。 … AbstractQueue：对Queue中的部分抽象方法进行实现，类似于设计模式中的模板模式。 add：依赖add方法（抽象的方法）实现新增功能。 remove：依赖poll方法（抽象的方法）实现移除功能。 BlockingQueue Interface：BlockingQueue继承Queue，在Queue的基础之上进行增强，新增阻塞相关功能方法的定义，例如： boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException; E poll(long timeout, TimeUnit unit) throws InterruptedException; 队列实现原理ConcurrentLinkedQueueConcurrentLinkedQueue是一个线程安全的无界队列，底层是一个单向链表，主要通过CAS来完成入队和出队的线程安全，由于所有的操作都是使用CAS无阻塞算法，因此该方法不会阻塞挂起调用线程。 ConcurrentLinkedQueue包含了两个volatile类型的Node节点，分别为head、tail，因为是单向链表的缘故，所以只有一个next属性指向下一个节点。 123456789public ConcurrentLinkedQueue() { head = tail = new Node&lt;E&gt;(null);}private static class Node&lt;E&gt; { volatile E item; volatile Node&lt;E&gt; next; ...} 当初始化完成时，head、tail分别指向一个item为null的Node节点。 当新增节点时，整体的结构变为： 其实了解大致结构，基本的实现原理大概能理解了。 LinkedBlockingQueueLinkedBlockingQueue是一个线程安全的无界队列，先看看它的类图： 同样的它继承AbstractQueue并且实现BlockingQueue。 查看相关源代码： 123456789101112131415161718192021222324252627 /** * Head of linked list. * Invariant: head.item == null */ transient Node&lt;E&gt; head; /** * Tail of linked list. * Invariant: last.next == null */ private transient Node&lt;E&gt; last; /** * Linked list node class */ static class Node&lt;E&gt; { E item; /** * One of: * - the real successor Node * - this Node, meaning the successor is head.next * - null, meaning there is no successor (this is the last node) */ Node&lt;E&gt; next; Node(E x) { item = x; } } 它拥有Node类型的head、last两个元素，底层是一个单向链表。 查看offer相关代码： 1234567891011121314151617181920212223242526272829303132333435/** * Inserts the specified element at the tail of this queue, waiting if * necessary up to the specified wait time for space to become available. * * @return {@code true} if successful, or {@code false} if * the specified waiting time elapses before space is available * @throws InterruptedException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException { if (e == null) throw new NullPointerException(); long nanos = unit.toNanos(timeout); int c = -1; final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { while (count.get() == capacity) { if (nanos &lt;= 0) return false; nanos = notFull.awaitNanos(nanos); } enqueue(new Node&lt;E&gt;(e)); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); } finally { putLock.unlock(); } if (c == 0) signalNotEmpty(); return true;} 我们可以发现，它是通过ReentrantLock保证入队和出队的线程安全。 ArrayBlockingQueue ArrayBlockingQueue实现AbstractQueue和BlockingQueue，从它的继承结构可以得知，它是一个阻塞队列，我们来看看它的内部结构： 123456789101112131415161718192021222324/** The queued items */final Object[] items;/** items index for next take, poll, peek or remove */int takeIndex;/** items index for next put, offer, or add */int putIndex;/** Number of elements in the queue */int count;/** Main lock guarding all access */final ReentrantLock lock;/** Condition for waiting takes */private final Condition notEmpty;/** Condition for waiting puts */private final Condition notFull;public ArrayBlockingQueue(int capacity) { this(capacity, false);} 内部通过一个items数组进行储存元素，putIndex标识入队元素下标，taskIndex是出队元素下标，count统计元素的个数，主要通过lock来保证出、入队操作的原子性，另外notEmpty、notFull这些条件变量来进行出、入队同步的控制。 因为ArrayBlockingQueue是一个有界队列，所以构造函数必须传入队列大小参数。 来看看它的offer方法： 12345678910111213141516171819202122 public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException {// 1、check元素不能为空 checkNotNull(e); long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; // 2、获取独占锁 lock.lockInterruptibly(); try { // 3、如果队列满了，则插入失败 while (count == items.length) { if (nanos &lt;= 0) return false; nanos = notFull.awaitNanos(nanos); } // 4、否则插入队列 enqueue(e); return true; } finally { lock.unlock(); } } 基本上从offer方法我们就可以得知它的基本实现，总结一下： ArrayBlockingQueue主要是继承AbstractQueue和BlockingQueue实现的一个有界阻塞队列，内部通过items存储相关元素，并且通过ReentrantLock保证并发安全。 PriorityBlockingQueuePriorityBlockingQueue是一个无界的基于数组的优先级阻塞队列，","link":"/2023/09/08/2023-09-08_Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E9%98%9F%E5%88%97_%E5%BE%85%E5%AE%8C%E5%96%84/"},{"title":"Docker部署GitLab CI_CD","text":"Docker与GitLab CI/CD Docker部署GitLab CI/CD 前置条件：安装Docker环境 修改sshd默认端口 1vim /etc/ssh/sshd_config 将#Port 22改为Port 9998. 重启sshd服务 1systemctl restart sshd 出现异常:Bind to port 9998 on :: failed: Permission denied. 解决方案:https://blog.csdn.net/default7/article/details/103592139 启动gitlab容器 1234567891011docker run -d \\--hostname gitlab.example.com \\-p 443:443 \\-p 80:80 \\-p 22:22 \\--name gitlab \\--restart always \\-v $GITLAB_HOME/config:/etc/gitlab \\-v $GITLAB_HOME/logs:/var/log/gitlab \\-v $GITLAB_HOME/data:/var/opt/gitlab \\gitlab/gitlab-ce:latest 登入gitlab gitlab初始化密码在容器文件/etc/gitlab/initial_root_password此文件在初次安装gitlab24小时之后会是删除!!! GitLab Runner部署1234docker run -d --name gitlab-runner-docker \\--restart always -v $PWD:/etc/gitlab-runner \\-v /var/run/docker.sock:/var/run/docker.sock \\gitlab/gitlab-runner:latest http://192.168.0.212/","link":"/2023/12/12/2023-12-11_Docker%E9%83%A8%E7%BD%B2GitLab%20CI%20CD/"},{"title":"基于TUN&amp;TAP实现多个局域网设备之间的通讯","text":"讲解基于TUN&amp;TAP实现多个局域网设备之间的通讯的基本原理 目标本文会对tun/tap的原理进行基本说明，然后基于tun/tap实现多个局域网设备之间的通讯，实现跨网络通信。 例如：实现局域网A中的主机和局域网B中的主机进行通信。 原理简要说明物理网卡的工作流程在了解tun/tap之前，先简要说明物理网卡的工作流程。 网卡处于网络协议栈和物理网卡之间，一端连着网络协议栈，一端连着物理网络 当发送数据时：将接收网络协议栈的数据，并将数据封装成帧，并通过网线（对无线网络来说就是电磁波）将数据发送到网络中。 当接收数据时：接收网络上其他设备传过来的帧，并将帧进行解码，然后传递到网络协议栈中。 TUN、TAP基本原理目前主流的虚拟网卡方案有tun/tap和veth两种，在时间上tun/tap出现得更早，它是一组通用的虚拟驱动程序包，里面包含了两个设备，分别是用于网络数据包处理的虚拟网卡驱动，以及用于内核空间与用户空间交互的字符设备（Character Devices，这里具体指/dev/net/tun）驱动。大概在 2000 年左右，Solaris系统为了实现隧道协议（Tunneling Protocol）开发了这套驱动，从 Linux Kernel 2.1 版开始移植到Linux内核中，当时是源码中的可选模块，2.4 版之后发布的内核都会默认编译 tun/tap 的驱动。 tun 和 tap 是两个相对独立的虚拟网络设备，其中 tap 模拟了以太网设备，具备操作二层数据包（以太帧）的能力，tun 则模拟了网络层设备，具备操作三层数据包（IP 报文）的能力。使用 tun/tap 设备的目的是实现把来自协议栈的数据包先交由某个打开了/dev/net/tun字符设备的用户进程处理后，再把数据包重新发回到链路中，你可以通俗地将它理解为这块虚拟化网卡一端连接着网络协议栈，另一端连接着用户态程序，只要协议栈中的数据包能被用户态程序截获并加工处理，程序员就有足够的舞台空间去玩出各种花样，譬如数据压缩、流量加密、透明代理等功能都能够以此为基础来实现。 就以我们此次要实现的应用程序为例，当程序发送给tun设备数据包时，整个工作流程如图所示： 实现思路要实现局域网A中的主机和局域网B中的主机进行通信，我们需要有三端，分别为客户端A、客户端B、服务端C，其中服务端C部署在公有云上，它和客户端A、和客户端B的网络是通的。 分别启动服务端C客户端A、B，并且服务端C分别和客户端A、B建立TCP链接。 客户端A创建tun网卡，再对这个网卡配置IP以及子网掩码并且激活tun网卡，那么Linux会自动加上这个网段路由规则。 客户端B创建tun网卡，再对这个网卡配置IP以及子网掩码并且激活tun网卡，那么Linux会自动加上这个网段路由规则。 客户端A、B设置IP，需要在同一个网段，并且不与已有的网络冲突，例如：10.10.10.1/24、10.10.10.2/24。 客户端A向客户端B的IP（10.10.10.2）发起请求，通过路由规则的计算，将会路由到tun网卡，然后通过用户程序对tun网卡进行监听，将tun网卡的数据通过客户端A与服务端C建立的TCP连接发送出去（这里走的就是物理网卡）。 当C端接收到请求数据之后，向所有和它建立TCP链接的客户端发起广播请求（除了A端这个最初的发送端除外），如果是目的地IP，将会响应给服务端，否则将会丢弃，当服务端收到响应之后，再同理的将响应数据广播给最初的发送端。 在服务端和客户端的TCP交互过程中，我们要注意处理TCP的粘包问题。 我们前期设置tun网卡的IP和激活tun网卡，可以先手动操作，需要注意的一点就是，tun网卡它是通过用户程序进行创建的，将用户程序结束之后，tun网卡将会自动删除，所以我们需要每次维护它的IP并且手动激活它。 至此，这个程序的大致实现思路就结束了。 这里就没代码的具体实现了，主要讲讲思路，如果对代码有兴趣的话。easy-tun，注释比较细，应该很容易能够看懂。 测试这里的测试主要是对easy-tun的代码进行测试。 前提GO环境 启动服务端123456# 设置go拉取依赖的地址root@vultr:~/goWorkspace# go env -w GOPROXY=https://goproxy.cn,direct# 拉取依赖root@vultr:~/goWorkspace# go get# 启动服务端root@vultr:~/goWorkspace# go run Server.go 启动客户端并且设置IP 启动客户端A 12345678910111213# 设置go拉取依赖的地址root@vultr:~/goWorkspace# go env -w GOPROXY=https://goproxy.cn,direct# 拉取依赖root@vultr:~/goWorkspace# go get# 通过-ser指定服务端的IP地址，这里填你服务端的IP[root@localhost goworkspace]# go run Client.go -ser xxx.xxx.xxx.xxxserver address :xxx.xxx.xxx.xxxlocal tun device name :gtunconnect server succeed.# 对指定网卡设置IP，gtun为你网卡的名称，如果你的tun网卡名称不是gtun，自行调整[root@localhost goworkspace]# sudo ip addr add 10.10.10.1/24 dev gtun# 将gtun网卡激活,如果你的tun网卡名称不是gtun，自行调整[root@localhost goworkspace]# sudo ip link set gtun up 启动客户端B 12345678910111213# 设置go拉取依赖的地址root@vultr:~/goWorkspace# go env -w GOPROXY=https://goproxy.cn,direct# 拉取依赖root@vultr:~/goWorkspace# go get# 通过-ser指定服务端的IP地址，这里填你服务端的IP[root@localhost goworkspace]# go run Client.go -ser xxx.xxx.xxx.xxxserver address :xxx.xxx.xxx.xxxlocal tun device name :gtunconnect server succeed.# 对指定网卡设置IP，gtun为你网卡的名称，如果你的tun网卡名称不是gtun，自行调整[root@localhost goworkspace]# sudo ip addr add 10.10.10.2/24 dev gtun# 将gtun网卡激活,如果你的tun网卡名称不是gtun，自行调整[root@localhost goworkspace]# sudo ip link set gtun up 在客户端Aping客户端B12345678[root@localhost goworkspace]# ping 10.10.10.2PING 10.10.10.2 (10.10.10.2) 56(84) bytes of data.64 bytes from 10.10.10.2: icmp_seq=1 ttl=64 time=355 ms64 bytes from 10.10.10.2: icmp_seq=2 ttl=64 time=671 ms64 bytes from 10.10.10.2: icmp_seq=3 ttl=64 time=363 ms64 bytes from 10.10.10.2: icmp_seq=4 ttl=64 time=356 ms64 bytes from 10.10.10.2: icmp_seq=5 ttl=64 time=1473 ms64 bytes from 10.10.10.2: icmp_seq=6 ttl=64 time=592 ms 至此，我们实现了不在同一个局域网的两台机器，像访问局域网一样进行通讯。 参考 &lt;&lt;凤凰架构&gt;&gt;","link":"/2023/12/27/2023-12-27_%E5%9F%BA%E4%BA%8ETUN&TAP%E5%AE%9E%E7%8E%B0%E5%A4%9A%E4%B8%AA%E5%B1%80%E5%9F%9F%E7%BD%91%E8%AE%BE%E5%A4%87%E4%B9%8B%E9%97%B4%E7%9A%84%E9%80%9A%E8%AE%AF/"},{"title":"常见的限流算法","text":"简述常见的几种限流算法的原理，包括滑动窗口限流算法、固定窗口限流算法、漏桶算法、令牌桶算法。 固定窗口限流算法固定窗口限流算法是一种最简单的限流算法，其原理是在固定时间窗口内限制请求的数量。 具体是将一个整体的时间分成固定的窗口，并且在每个窗口内限制请求的数量，如果在对应的窗口内请求的数量超出了限制，则拒绝请求。 假设单位时间(固定时间窗口)是1秒，限流阀值为3。在单位时间1秒内，每来一个请求,计数器就加1，如果计数器累加的次数超过限流阀值3，后续的请求全部拒绝。等到1s结束后，计数器清0，重新开始计数。如下图： 优点 固定窗口算法非常简单，易于实现和理解。 缺点 存在明显的临界问题。 假设限流阈值为5个请求，单位时间窗口是1s，如果我们在前0.8-1s和 1-1.2s分别发送5个请求，虽然都没有超过阈值，但是其实0.8s~1.2s并发数已经高达10，已经超过单位时间内1s不超过5阈值的定义了。 滑动窗口限流算法滑动窗口限流算法是一种常用的限流算法，用于控制系统对外提供服务的速率，防止系统被过多的请求压垮。它将单位时间周期分为n个小周期，分别记录每个小周期内接口的访问次数，并且根据时间滑动删除过期的小周期。它可以解决固定窗口临界值的问题。 假设单位时间还是1s，滑动窗口算法把它划分为5个小周期，也就是滑动窗口（单位时间）被划分为5个小格子。每格表示0.2s。每过0.2s，时间窗口就会往右滑动一格。然后呢，每个小周期，都有自己独立的计数器，如果请求是0.83s到达的，0.8~1.0s对应的计数器就会加1。 我们来看下，滑动窗口,去解决固定窗口限流算法的临界问题，思想是怎样 假设我们1s内的限流阀值还是5个请求，0.8~1.0s内（比如0.9s的时候）来了5个请求，落在黄色格子里。时间过了1.0s这个点之后，又来5个请求，落在紫色格子里。如果是固定窗口算法，是不会被限流的，但是滑动窗口的话，每过一个小周期，它会右移一个小格。过了1.0s这个点后，会右移一小格，当前的单位时间段是0.2~1.2s，这个区域的请求已经超过限定的5了，已触发限流啦，实际上，紫色格子的请求都被拒绝啦。 当滑动窗口的格子周期划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。 优点 简单易懂 精确度高 可扩展性强（可以很容易的与其他限流算法结合使用） 缺点 突发流量无法处理（无法应对短时间内的大量请求，但是一旦到达限流后，请求都会直接暴力被拒绝。酱紫我们会损失一部分请求，这其实对于产品来说，并不太友好），需要合理调整时间窗口大小。 漏桶限流算法漏桶限流算法（Leaky Bucket Algorithm）是一种流量控制算法，用于控制流入网络的数据速率，以防止网络拥塞。它的思想是将数据包看作是水滴，漏桶看作是一个固定容量的水桶，数据包像水滴一样从桶的顶部流入桶中，并通过桶底的一个小孔以一定的速度流出，从而限制了数据包的流量。 漏桶限流算法的基本工作原理是：对于每个到来的数据包，都将其加入到漏桶中，并检查漏桶中当前的水量是否超过了漏桶的容量。如果超过了容量，就将多余的数据包丢弃。如果漏桶中还有水，就以一定的速率从桶底输出数据包，保证输出的速率不超过预设的速率，从而达到限流的目的。 流入的水滴看作访问系统的请求，这个流入速率是不确定的。 桶的容量代表系统所能处理的请求数。 如果桶的容量满了，就打到了限流的阈值，就会丢弃水滴。 流出的水滴，是恒定的，对应服务按照固定的速率处理请求。 优点 可以平滑限制请求的处理速度，避免瞬间请求过多导致系统崩溃或者雪崩。 可以控制请求的处理速度，使得系统可以适应不同的流量需求，避免过载或者过度闲置。 可以通过调整桶的大小和漏出速率来满足不同的限流需求，可以灵活地适应不同的场景。 缺点 需要对请求进行缓存，会增加服务器的内存消耗。 对于流量波动比较大的场景，需要较为灵活的参数配置才能达到较好的效果。 但是面对突发流量的时候，漏桶算法还是循规蹈矩地处理请求，这不是我们想看到的啦。流量变突发时，我们肯定希望系统尽量快点处理请求，提升用户体验嘛。 令牌桶限流算法令牌桶算法是一种常用的限流算法，可以用于限制单位时间内请求的数量。该算法维护一个固定容量的令牌桶，每秒钟会向令牌桶中放入一定数量的令牌。当有请求到来时，如果令牌桶中有足够的令牌，则请求被允许通过并从令牌桶中消耗一个令牌，否则请求被拒绝。 优点： 稳定性高：令牌桶算法可以控制请求的处理速度，可以使系统的负载变得稳定。 精度高：令牌桶算法可以根据实际情况动态调整生成令牌的速率，可以实现较高精度的限流。 弹性好：令牌桶算法可以处理突发流量，可以在短时间内提供更多的处理能力，以处理突发流量。 Guava的RateLimiter限流组件，就是基于令牌桶算法实现的。 缺点： 实现复杂：相对于固定窗口算法等其他限流算法，令牌桶算法的实现较为复杂。对短时请求难以处理：在短时间内有大量请求到来时，可能会导致令牌桶中的令牌被快速消耗完，从而限流。这种情况下，可以考虑使用漏桶算法。 时间精度要求高：令牌桶算法需要在固定的时间间隔内生成令牌，因此要求时间精度较高，如果系统时间不准确，可能会导致限流效果不理想。","link":"/2024/02/02/2024-03-08_%E5%B8%B8%E8%A7%81%E7%9A%84%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95/"},{"title":"我想成为一个怎样的人？","text":"我想成为一个怎样的人？ 2024年3月17日 今天周末，已经凌晨一点了，看着微弱的灯光，听起了音乐，歌词有一句”怎么偶尔听到老歌时，忽然也慌了声”，万般情绪在这一刻涌来，突然想起“我想成为怎样的人？”。 好比童年时代，大多都写过一篇作文“20年后的自己”，转眼间就到了少年时代脑海中的年纪，我也不知道现在是否实现了少年时代的想法，因为早就忘得一干二净，我现在又突发奇想“5年后的自己会是怎样”。 todo","link":"/2024/03/17/2024-03-17_%E6%88%91%E6%83%B3%E6%88%90%E4%B8%BA%E6%80%8E%E6%A0%B7%E7%9A%84%E4%BA%BA/"},{"title":"Config a fuzzy listen scheme（配置模糊监听方案）","text":"Config a fuzzy listen scheme（配置模糊监听方案） 1. 背景与需求在用户的应用场景中，存在对配置批次监听的需求，例如需要监听同一个 group 下的部分或所有的配置变化。目前，用户只能通过精确监听单个配置。 为了解决这一问题，引入了模糊监听的概念，允许用户监听符合Pattern的配置变化（新增、删除、不包含更新）。通过模糊监听，用户可以获取到符合指定Pattern的配置元数据，再结合精确监听，可以更加灵活地实现配置变化的监听与处理。 因此，用户可以通过以下方式实现对指定 group 下配置的监听： 使用模糊监听，监听符合指定Pattern的配置变化（新增、删除、不包含更新），例如匹配某个 group 下所有配置的模式。结合精确监听，对特定的配置进行精确监听（新增、删除、更新），以获取对单个配置变化的实时通知。从而实现整个配置的模糊监听。 2. 实现方案2.1. 整体流程图 2.2. Pattern存储规则使用Pattern实现在特定命名空间和组中对一组具有特定前缀的配置进行监听，这使得配置中心能够更灵活地处理不同场景下的配置需求。 Pattern存储规则图： 由于客户端的ConfigServer与namespace绑定，而服务端可能接收到不同namespace客户端的模糊订阅请求，所以服务端存储需要带上namespace，而客户端对namespace不进行存储。 上图中的通配符，匹配规则如下： 订阅namespace= public，group = group下dataId前缀为test的所有配置 2.3. 客户端模糊监听上下文实体说明FuzzyListenContext：模糊监听上下文实体（后续该实体均用“上下文”描述。），与模糊监听配置表达式一对一关联关系，并且包含了以下属性： envName：环境名称，表示监听配置所在的环境。 taskId：任务编号，主要用于分片处理，将模糊监听上下文分配给不同的任务。 dataIdPattern：模糊监听表达式。 group：配置的分组信息。 tenant：租户信息，用于区分不同租户的配置。 isConsistentWithServer：是否与服务端同步，表示此模糊监听表达式是否已同步到服务端。 isInitializing：是否正在初始化模糊监听上下文列表。 isDiscard：是否丢弃，当listeners为空时，isDiscard = true，表示此模糊监听上下文可以丢弃，即通知服务端取消对该上下文的监听。 dataIds：此上下文所匹配的配置数据ID列表。 listeners：监听器列表，用于存储与此上下文关联的监听器。 该实体描述了客户端中上下文的各种属性和状态，以及与之关联的配置数据ID列表和监听器列表。 2.4. 客户端初始化模糊监听上下文SDK端需要存储当前ClientWorker中所有的Context，并且提供&lt;KepPattern, Context&gt;的Map映射关系，主要是方便索引，所以ClientWorker中新增AtomicReference&lt;Map&lt;String, FuzzyListenContext&gt;&gt; fuzzyListenContextMap。 客户端初始化模糊监听上下文流程图： 当新增FuzzyListrener时，将会通过Pattern判断是否存在上下文，其实就是判断是否重复监听，如果是监听，则直接获取到Context中的配置回调Listener即可。 注意：当重复监听时，这里直接回调Listener，但是不能回调所有的Listener，所以Listener需要UUID标识 2.5. 客户端执行模糊监听上下文在 ClientWorker 中新增了 fuzzyListenContextMap，该 Map 包含了所有的上下文。 执行配置模糊监听的流程图： 说明： 客户端定时（每5秒）执行配置模糊监听，或者新增上下文。 根据所有的上下文，判断是否需要进行同步，具体判断逻辑包括模糊监听上下文的同步标识以及是否达到全量同步的条件。 根据丢弃标识判断出上下文是需要创建模糊监听还是取消模糊监听，分别构造批次模糊监听请求。 发起批次模糊监听请求。 2.5.1. 批次模糊监听请求字段 ConfigBatchFuzzyListenRequest：配置批次模糊监听请求对象，包含以下字段： contexts：上下文集合，每个上下文包含以下字段： tenant：租户信息，用于区分不同租户的配置。 group：配置的分组信息。 dataIdPattern：数据ID模式，用于匹配配置的数据ID。 dataIds：客户端已有的配置数据ID集合，用于与服务端已有的配置进行匹配。 listen：指示是创建监听还是取消监听。 isInitializing：是否初始化中，用于区分上下文是否第一次执行模糊监听。该字段在通知客户端时，分别对应 LISTEN_INIT 和 ADD_CONFIG 事件，目前并没有实际区别，但为了方便扩展，在后续可能需要对第一次执行模糊监听进行特殊处理时，可以通过该字段来实现。 2.5.2. 模糊监听上下文发送分批模糊监听上下文分批，主要沿用精确监听的分批实现，实现如下： 通过PER_TASK_CONTEXT_SIZE_KEY配置指定每个Task所能容纳的上下文大小，上下文中存在taskId字段，每初始化上下文时，计算该配置属于哪个Task。 针对属于同一个Task的模糊监听上下文，将其进行分批合并。合并后的批次包含指定数量的上下文，根据需要将批次发送给服务端。 2.6. 服务端处理批次模糊监听上下文服务端处理批次模糊监听流程图： 说明： 服务端处理 ConfigBatchFuzzyListenRequest 的流程分为两步，通过事件 ConfigBatchFuzzyListenEvent 进行解耦： 维护 ConfigChangeListenContext#keyPatternContext：服务端维护 ConfigChangeListenContext 中的 keyPatternContext，用于存储模糊监听表达式和其对应的Connection的映射关系。 计算变更的配置并推送至客户端：根据客户端已有的配置和服务端Cache的配置，计算出变更的配置，并将变更的配置推送至客户端。 2.6.1. 模糊监听通知请求字段 FuzzyListenNotifyDiffRequest：用于通知配置差异的模糊监听请求对象，包含以下字段： groupKeyPattern：用于匹配配置组键的模式字符串。 contexts：包含配置信息的上下文集合，每个上下文包含以下字段： tenant：与配置关联的租户。 group：与配置关联的组。 dataId：配置的数据ID。 type：配置变更事件的类型。 2.6.2. 分批通知为了有效处理同一模糊监听下的大量配置，我们采用了分批通知的策略。具体流程如下： 批次大小配置： 我们通过配置项 nacos.config.push.batchSize 来指定每个批次的大小。这个配置决定了每次通知中处理的配置数量。 分批处理： 当需要发送通知时，我们将大量配置按照指定的批次大小进行划分。每个批次中包含的配置数量不会超过配置的批次大小。 发送通知： 对于每个批次的配置通知，我们将它们分别发送给客户端。在完成每个批次的通知后，会发送一个特殊的完成请求，通知客户端该批次的处理已经完成。 2.7. 服务端关于配置变更的推送服务端关于配置变更的推送流程图： 说明：当服务端发生配置变更时，即发布了 LocalDataChangeEvent 事件。处理过程如下： 根据变更的配置的唯一标识 GroupKey，与服务端的缓存进行匹配，确定该配置是否存在于服务端的缓存中。 如果配置存在于缓存中，则通知客户端进行相应的处理。 2.7.1. 模糊监听变更通知字段说明 FuzzyListenNotifyChangeRequest：用于通知模糊监听配置变更的请求对象，包含以下字段： tenant：配置变更的租户信息。 group：配置变更的组信息。 dataId：配置变更的数据ID。 isExist：指示配置是否存在的布尔值。 2.8 客户端接收配置变更与差异通知当服务端发生配置变更时，或者有配置差异需要通知客户端时，客户端接收通知并处理的流程如下： 服务端向客户端发送相应的请求（FuzzyListenNotifyChangeRequest 或 FuzzyListenNotifyDiffRequest）。 客户端根据接收到的请求以及当前已存在的配置信息，计算出需要添加或删除的配置，并相应地发布事件（如 FuzzyListenNotifyEvent）。 FuzzyListenNotifyEvent的订阅者接收事件去回调Listener。 3.0 问题3.0.1 模糊监听是否需要监听配置内容的变更？@hujun-w-2 提出以这种方案实现，真正的监听逻辑还是依赖精确监听实现的，在监听配置过多时，客户端启动、长连接断开时，会对服务端造成较大消耗，模糊监听应该支持配置内容变更的监听。","link":"/2024/04/18/2024-04-18_Config%20a%20fuzzy%20listen%20scheme%EF%BC%88%E9%85%8D%E7%BD%AE%E6%A8%A1%E7%B3%8A%E7%9B%91%E5%90%AC%E6%96%B9%E6%A1%88%EF%BC%89/"},{"title":"理解MySQL的Select语句的执行顺序","text":"了解一下MySQL的Select语句的执行顺序 在深入学习数据库过程中，全面掌握MySQL的SELECT查询执行顺序是至关重要的。它不仅关系到查询效率的优化，还直接指导着逻辑构建、问题排查及资源管理策略。所以这篇文章就是梳理这一核心概念。（PS：近几年没有怎么写SQL都忘记了） 这篇主要讲解： SELECT查询的执行流程概览 SELECT查询处理步骤 SELECT查询逻辑的虚拟表 Mysql的Select与大多编程语言并不一致，并非以编码的顺序进行执行，而是遵循一套特定的逻辑步骤。 SELECT查询的执行流程概览 数据源组装 (FROM子句)：首先，系统从指定的数据表中提取数据，若涉及多表联接，则执行笛卡尔积生成基础数据集。 行级筛选 (WHERE子句)：基于条件表达式，对初步组装的数据集进行行级别的筛选，剔除不符合条件的记录。 数据分组 (GROUP BY子句)：将筛选后的数据依据指定列进行分组，为聚合操作做准备。 聚合计算：对每个分组应用聚合函数（如SUM, AVG, COUNT等）进行计算。 分组筛选 (HAVING子句)：进一步基于分组后的结果，使用HAVING过滤不符合条件的分组。 表达式计算(SELECT 表达式子句)：处理SELECT列表中非聚合的表达式和列值。 列选择(SELECT子句)：确定最终查询结果集中展示的列。 结果排序 (ORDER BY子句)：根据指定列对查询结果进行排序。 SELECT查询处理步骤 FROM JOIN ON WHERE GROUP BY WITH {CUBE | ROLLUP} HAVING SELECT DISTINCT ORDER BY SELECT查询逻辑的虚拟表SELECT查询处理步骤中每个步骤都会产生一个虚拟表，该虚拟表被用作下一个步骤的输入。这些虚拟表对调用者(客户端应用程序或者外部查询)不可用。只有最后一步生成的表才会会给调用者。如果没有在查询中指定某一个子句，将跳过相应的步骤。 FROM：对FROM子句中的前两个表执行笛卡尔积(交叉联接)，生成虚拟表VT1。 ON：对VT1应用ON筛选器，只有那些使为真才被插入到TV2。 OUTER(JOIN)：如果指定了OUTER JOIN(相对于CROSS JOIN或INNER JOIN)，保留表中未找到匹配的行将作为外部行添加到VT2，生成TV3。如果FROM子句包含两个以上的表，则对上一个联接生成的结果表和下一个表重复执行步骤1到步骤3，直到处理完所有的表位置。 WHERE：对TV3应用WHERE筛选器，只有使为true的行才插入TV4。 GROUP BY：按GROUP BY子句中的列列表对TV4中的行进行分组，生成TV5。 CUTE|ROLLUP：把超组插入VT5，生成VT6。 HAVING：对VT6应用HAVING筛选器，只有使为true的组插入到VT7。 SELECT：处理SELECT列表，产生VT8。 DISTINCT：将重复的行从VT8中删除，产品VT9。 ORDER BY：将VT9中的行按ORDER BY子句中的列列表顺序，生成一个游标(VC10)。 TOP：从VC10的开始处选择指定数量或比例的行，生成表TV11，并返回给调用者。","link":"/2024/04/26/2024-04-26_Mysql%E7%9A%84Select%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F/"},{"title":"Redis数据结构——快速列表(quicklist).md","text":"主要讲解了quicklist产生的背景，以及quicklist的原理。 背景在Redis3.2版本之前链表结构是采用ziplist和linkedlist，当列表元素过少时，采用ziplist，当列表元素过多时，采用linkedlist。 但是考虑到链表的附加空间相对太高，每个节点都有pre和next需要占用16个字节(64bit系统指针是8个字节)，并且每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率。 所以在Redis 3.2版本开始对列表数据结构进行了改造，使用quicklist代替ziplist和linkedlist。 结构linkedlist和ziplist的结构分别如下所示： quicklist实际上是linkedlist和ziplist的结合体，linkedlist每一个节点都是一个ziplist。如图所示：","link":"/2024/01/30/2024-01-30_Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E2%80%94%E2%80%94%E5%BF%AB%E9%80%9F%E5%88%97%E8%A1%A8(quicklist)/"},{"title":"鲜花","text":"鲜花歌词，无聊写写。 我记得在那便利店买的酒可是我不敢一个人喝车子又经过了山我妄想开着我的烂摩托去转一转可是我 可是我可惜我把车卖了 我的心啊我的心整栋出租处处都给你种好的鲜花 治愈你的白发别害怕 别害怕有我在的地方啊永远开满了鲜花 治愈你的白发别害怕永远开满了鲜花 治愈你的白发别害怕永远开满了鲜花 治愈你的白发永远开满永远开满永远开满 我的心啊我的心整栋出租处处都给你种好的鲜花 治愈你的白发别害怕 别害怕有我在的地方啊永远开满了鲜花 治愈你的白发永远开满永远开满永远开满 鲜花","link":"/2024/02/02/2024-02-02_%E9%B2%9C%E8%8A%B1/"}],"tags":[{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"JUC","slug":"JUC","link":"/tags/JUC/"},{"name":"并发编程","slug":"并发编程","link":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"Nacos","slug":"Nacos","link":"/tags/Nacos/"},{"name":"感情","slug":"感情","link":"/tags/%E6%84%9F%E6%83%85/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"跑步","slug":"跑步","link":"/tags/%E8%B7%91%E6%AD%A5/"},{"name":"Kubernetes","slug":"Kubernetes","link":"/tags/Kubernetes/"},{"name":"Network","slug":"Network","link":"/tags/Network/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Github","slug":"Github","link":"/tags/Github/"},{"name":"Seata","slug":"Seata","link":"/tags/Seata/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"CI&amp;CD","slug":"CI-CD","link":"/tags/CI-CD/"},{"name":"Gitlab","slug":"Gitlab","link":"/tags/Gitlab/"},{"name":"Zookeeper","slug":"Zookeeper","link":"/tags/Zookeeper/"},{"name":"RabbitMQ","slug":"RabbitMQ","link":"/tags/RabbitMQ/"},{"name":"SpringCloud","slug":"SpringCloud","link":"/tags/SpringCloud/"},{"name":"随意写写","slug":"随意写写","link":"/tags/%E9%9A%8F%E6%84%8F%E5%86%99%E5%86%99/"},{"name":"分布式事务","slug":"分布式事务","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"分布式理论","slug":"分布式理论","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/"},{"name":"源码","slug":"源码","link":"/tags/%E6%BA%90%E7%A0%81/"},{"name":"Java基础","slug":"Java基础","link":"/tags/Java%E5%9F%BA%E7%A1%80/"},{"name":"GitLab","slug":"GitLab","link":"/tags/GitLab/"},{"name":"CI_CD","slug":"CI-CD","link":"/tags/CI-CD/"},{"name":"Golang","slug":"Golang","link":"/tags/Golang/"},{"name":"啥呢","slug":"啥呢","link":"/tags/%E5%95%A5%E5%91%A2/"},{"name":"随笔","slug":"随笔","link":"/tags/%E9%9A%8F%E7%AC%94/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"}],"categories":[{"name":"技术","slug":"技术","link":"/categories/%E6%8A%80%E6%9C%AF/"},{"name":"杂记","slug":"杂记","link":"/categories/%E6%9D%82%E8%AE%B0/"}],"pages":[{"title":"","text":"关于我我是一枚98年的程序员。在技术方面的话，我比较熟悉Java语言，同时对Golang有一定了解。在生活方面的话，我平常喜欢研究做菜，但是这和我做的难吃并不冲突，然后呢，我平时比较喜欢运动，不过这和我宅并不矛盾，哈哈哈，不过呢，以后我还是打算到处去去看看，不打算宅了。这个博客就是为了在无聊的时候记录一些琐事以及学习了解的一些技术。","link":"/about/index.html"}]}